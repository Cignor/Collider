
================================================================================
FILE: juce\\Source\\audio\\modules\\VideoFileLoaderModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/videoio.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>

/**
 * Source node that loads a video file and publishes frames to VideoFrameManager.
 * Outputs its own logical ID as a CV signal for routing to processing nodes.
 */
class VideoFileLoaderModule : public ModuleProcessor, private juce::Thread
{
public:
    VideoFileLoaderModule();
    ~VideoFileLoaderModule() override;

    const juce::String getName() const override { return "video_file_loader"; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    void setTimingInfo(const TransportState& state) override { lastTransportPlaying.store(state.isPlaying); if (syncToTransport.load()) playing.store(state.isPlaying); }
    
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }
    
    // State management for saving/loading video file path
    juce::ValueTree getExtraStateTree() const override;
    void setExtraStateTree(const juce::ValueTree& state) override;

    // For UI
    juce::Image getLatestFrame();
    void chooseVideoFile();

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    
    // Override to specify custom node width. Height is calculated dynamically based on video aspect ratio.
    // Width changes based on zoom level (Small=240px, Normal=480px, Large=960px).
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;
    
    std::atomic<float>* loopParam = nullptr;
    // 0 = Small (240), 1 = Normal (480), 2 = Large (960)
    std::atomic<float>* zoomLevelParam = nullptr;
    // Playback controls
    std::atomic<float>* speedParam = nullptr;   // 0.25 .. 4.0 (1.0 default)
    std::atomic<float>* inNormParam = nullptr;  // 0..1
    std::atomic<float>* outNormParam = nullptr; // 0..1
    std::atomic<float>* syncParam = nullptr; // bool as float
    std::atomic<bool> playing { true };
    std::atomic<bool> syncToTransport { true };
    std::atomic<bool> lastTransportPlaying { false };
    std::atomic<bool> needPreviewFrame { false };
    std::atomic<bool> lastPlaying { false }; // for play-edge detection
    std::atomic<int> lastFourcc { 0 }; // cached FOURCC
    std::atomic<int> pendingSeekFrame { -1 };
    std::atomic<int> lastPosFrame { 0 };
    // Normalized pending requests (used when totalFrames not ready yet)
    std::atomic<float> pendingSeekNorm { -1.0f };
    std::atomic<float> pendingStartNorm { -1.0f };
    std::atomic<double> totalDurationMs { 0.0 };
    
    cv::VideoCapture videoCapture;
    juce::CriticalSection captureLock;

    static juce::String fourccToString(int fourcc)
    {
        if (fourcc == 0) return "unknown";
        char c[5];
        c[0] = (char)(fourcc & 0xFF);
        c[1] = (char)((fourcc >> 8) & 0xFF);
        c[2] = (char)((fourcc >> 16) & 0xFF);
        c[3] = (char)((fourcc >> 24) & 0xFF);
        c[4] = '\0';
        return juce::String(c);
    }

    static juce::String fourccFriendlyName(const juce::String& code)
    {
        const juce::String c = code.toLowerCase();
        if (c == "avc1" || c == "h264") return "H.264";
        if (c == "hvc1" || c == "hevc" || c == "hev1") return "H.265/HEVC";
        if (c == "mp4v" || c == "m4v") return "MPEG-4 Part 2";
        if (c == "mjpg" || c == "mjpa" || c == "jpeg") return "Motion JPEG";
        if (c == "xvid" ) return "MPEG-4 ASP (Xvid)";
        if (c == "vp09") return "VP9";
        if (c == "av01") return "AV1";
        if (c == "wmv3" || c == "wvc1") return "VC-1";
        if (c == "h263") return "H.263";
        return "unknown";
    }
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
    
    juce::File videoFileToLoad;
    juce::File currentVideoFile;
    std::unique_ptr<juce::FileChooser> fileChooser;

    // Cached metadata (atomic for cross-thread visibility)
    std::atomic<int> totalFrames { 0 };
};



================================================================================
FILE: juce\\Source\\audio\\modules\\VideoFileLoaderModule.cpp
================================================================================


#include "VideoFileLoaderModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

juce::AudioProcessorValueTreeState::ParameterLayout VideoFileLoaderModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    
    params.push_back(std::make_unique<juce::AudioParameterBool>("loop", "Loop", true));
    params.push_back(std::make_unique<juce::AudioParameterBool>("sync", "Sync to Transport", true));
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    // Playback controls
    params.push_back(std::make_unique<juce::AudioParameterFloat>(
        "speed", "Speed", juce::NormalisableRange<float>(0.25f, 4.0f, 0.01f), 1.0f));
    params.push_back(std::make_unique<juce::AudioParameterFloat>(
        "in", "Start", 0.0f, 1.0f, 0.0f));
    params.push_back(std::make_unique<juce::AudioParameterFloat>(
        "out", "End", 0.0f, 1.0f, 1.0f));
    
    return { params.begin(), params.end() };
}

VideoFileLoaderModule::VideoFileLoaderModule()
    : ModuleProcessor(BusesProperties()
                     .withOutput("Output", juce::AudioChannelSet::mono(), true)),
      juce::Thread("Video File Loader Thread"),
      apvts(*this, nullptr, "VideoFileLoaderParams", createParameterLayout())
{
    loopParam = apvts.getRawParameterValue("loop");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    speedParam = apvts.getRawParameterValue("speed");
    inNormParam = apvts.getRawParameterValue("in");
    outNormParam = apvts.getRawParameterValue("out");
    syncParam = apvts.getRawParameterValue("sync");
    syncToTransport.store(syncParam && (*syncParam > 0.5f));
}

VideoFileLoaderModule::~VideoFileLoaderModule()
{
    stopThread(5000);
    VideoFrameManager::getInstance().removeSource(getLogicalId());
}

void VideoFileLoaderModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    startThread(juce::Thread::Priority::normal);
    // If we already had a file open previously, request re-open on thread start
    if (currentVideoFile.existsAsFile())
        videoFileToLoad = currentVideoFile;
}

void VideoFileLoaderModule::releaseResources()
{
    signalThreadShouldExit();
    stopThread(5000);
}

void VideoFileLoaderModule::chooseVideoFile()
{
    fileChooser = std::make_unique<juce::FileChooser>("Select a video file...", 
                                                       juce::File{}, 
                                                       "*.mp4;*.mov;*.avi;*.mkv;*.wmv");
    auto chooserFlags = juce::FileBrowserComponent::openMode | juce::FileBrowserComponent::canSelectFiles;
    
    fileChooser->launchAsync(chooserFlags, [this](const juce::FileChooser& fc)
    {
        auto file = fc.getResult();
        if (file.existsAsFile())
        {
            videoFileToLoad = file;
        }
    });
}

void VideoFileLoaderModule::run()
{
    // One-time OpenCV build summary: detect if FFMPEG is integrated
    {
        static std::atomic<bool> buildInfoLogged { false };
        if (!buildInfoLogged.exchange(true))
        {
            juce::String info(cv::getBuildInformation().c_str());
            bool ffmpegYes = false;
            juce::String ffmpegLine;
            {
                juce::StringArray lines;
                lines.addLines(info);
                for (const auto& ln : lines)
                {
                    if (ln.containsIgnoreCase("FFMPEG:"))
                    {
                        ffmpegLine = ln.trim();
                        if (ln.containsIgnoreCase("YES")) ffmpegYes = true;
                        break;
                    }
                }
            }
            juce::Logger::writeToLog("[OpenCV Build] FFMPEG integrated: " + juce::String(ffmpegYes ? "YES" : "NO") +
                                     (ffmpegLine.isNotEmpty() ? juce::String(" | ") + ffmpegLine : juce::String()));
        }
    }

    bool sourceIsOpen = false;
    double videoFps = 30.0; // Default FPS
    double frameDurationMs = 33.0; // Default to ~30fps
    
    while (!threadShouldExit())
    {
        // Check if user requested a new file OR we need to (re)open the same file after restart
        if (videoFileToLoad.existsAsFile() && (!videoCapture.isOpened() || videoFileToLoad != currentVideoFile))
        {
            if (videoCapture.isOpened())
            {
                videoCapture.release();
            }
            
            bool opened = videoCapture.open(videoFileToLoad.getFullPathName().toStdString(), cv::CAP_FFMPEG);
            if (!opened)
            {
                juce::Logger::writeToLog("[VideoFileLoader] FFmpeg backend open failed, retrying default backend: " + videoFileToLoad.getFullPathName());
                opened = videoCapture.open(videoFileToLoad.getFullPathName().toStdString());
            }
            if (opened)
            {
                currentVideoFile = videoFileToLoad;
                videoFileToLoad = juce::File{}; // Clear request immediately after processing
                sourceIsOpen = true;
                needPreviewFrame.store(true);
                // Log backend name (helps diagnose FFmpeg vs MSMF at runtime)
               #if (CV_VERSION_MAJOR >= 4)
                juce::String backendName = videoCapture.getBackendName().c_str();
                juce::Logger::writeToLog("[VideoFileLoader] Backend: " + backendName);
               #endif
                // Reset state for new media, but keep user-defined in/out ranges
                totalFrames.store(0); // force re-evaluation
                lastPosFrame.store(0);
                pendingSeekFrame.store(0);
                
                // Get the video's native FPS and codec
                videoFps = videoCapture.get(cv::CAP_PROP_FPS);
                lastFourcc.store((int) videoCapture.get(cv::CAP_PROP_FOURCC));
                {
                    // Backend and raw FOURCC diagnostics
                    #if CV_VERSION_MAJOR >= 4
                    const std::string backendName = videoCapture.getBackendName();
                    juce::Logger::writeToLog("[VideoFileLoader] Backend: " + juce::String(backendName.c_str()));
                    #endif
                    const int fourccRaw = lastFourcc.load();
                    juce::Logger::writeToLog("[VideoFileLoader] Metadata: FPS=" + juce::String(videoFps,2) +
                                             ", Raw FOURCC=" + juce::String(fourccRaw) +
                                             " ('" + fourccToString(fourccRaw) + "')");
                }
                {
                    int tf = (int) videoCapture.get(cv::CAP_PROP_FRAME_COUNT);
                    if (tf <= 1) tf = 0; // treat unknown/invalid as 0 so UI uses normalized seeks
                    totalFrames.store(tf);
                    juce::Logger::writeToLog("[VideoFileLoader] Opened '" + currentVideoFile.getFileName() + "' frames=" + juce::String(tf) +
                                             ", fps=" + juce::String(videoFps,2) + ", fourcc='" + fourccToString(lastFourcc.load()) + "'");
                    if (tf > 1 && videoFps > 0.0)
                        totalDurationMs.store((double)tf * (1000.0 / videoFps));
                    else
                        totalDurationMs.store(0.0);
                }
                if (videoFps > 0.0 && videoFps < 1000.0) // Sanity check
                {
                    frameDurationMs = 1000.0 / videoFps;
                    juce::Logger::writeToLog("[VideoFileLoader] Opened: " + currentVideoFile.getFileName() + 
                                            " (FPS: " + juce::String(videoFps, 2) + ")");
                }
                else
                {
                    frameDurationMs = 33.0; // Fallback to 30fps
                    juce::Logger::writeToLog("[VideoFileLoader] Opened: " + currentVideoFile.getFileName() + 
                                            " (FPS unknown, using 30fps)");
                }
            }
            else
            {
                juce::Logger::writeToLog("[VideoFileLoader] Failed to open: " + videoFileToLoad.getFullPathName());
                videoFileToLoad = juce::File{};
            }
        }
        
        if (!sourceIsOpen)
        {
            wait(500);
            continue;
        }
        
        // Apply any pending seeks (UI-driven) before processing
        int tfLocal = totalFrames.load();
        {
            // 1) If we have a normalized pending seek, prefer time-based seek when duration is known
            float pendingNorm = pendingSeekNorm.exchange(-1.0f);
            if (pendingNorm >= 0.0f)
            {
                const double durMs = totalDurationMs.load();
                if (durMs > 0.0)
                {
                    double seekToMs = juce::jlimit(0.0, durMs, (double)pendingNorm * durMs);
                    const juce::ScopedLock capLock(captureLock);
                    if (videoCapture.isOpened())
                        videoCapture.set(cv::CAP_PROP_POS_MSEC, seekToMs);
                    needPreviewFrame.store(true);
                    juce::Logger::writeToLog("[VideoFileLoader][Seek] Applied normalized seek via MSEC=" + juce::String(seekToMs));
                }
                else if (tfLocal > 1)
                {
                    int toFrame = (int) std::round(juce::jlimit(0.0f, 1.0f, pendingNorm) * (tfLocal - 1));
                    pendingSeekFrame.store(toFrame);
                }
                else
                {
                    const juce::ScopedLock capLock(captureLock);
                    if (videoCapture.isOpened())
                        videoCapture.set(cv::CAP_PROP_POS_AVI_RATIO, juce::jlimit(0.0, 1.0, (double) pendingNorm));
                    needPreviewFrame.store(true);
                    juce::Logger::writeToLog("[VideoFileLoader][Seek] WARNING ratio seek");
                }
            }

            // 2) If we have a normalized pending start and frames are now known, convert and seek
            float pendingStart = pendingStartNorm.exchange(-1.0f);
            if (pendingStart >= 0.0f)
            {
                const double durMs = totalDurationMs.load();
                if (durMs > 0.0)
                {
                    double seekToMs = juce::jlimit(0.0, durMs, (double)pendingStart * durMs);
                    const juce::ScopedLock capLock(captureLock);
                    if (videoCapture.isOpened())
                        videoCapture.set(cv::CAP_PROP_POS_MSEC, seekToMs);
                    needPreviewFrame.store(true);
                    juce::Logger::writeToLog("[VideoFileLoader][Seek] Applied normalized start via MSEC=" + juce::String(seekToMs));
                }
                else if (tfLocal > 1)
                {
                    int inF = (int) std::round(juce::jlimit(0.0f, 1.0f, pendingStart) * (tfLocal - 1));
                    pendingSeekFrame.store(inF);
                }
                else
                {
                    const juce::ScopedLock capLock(captureLock);
                    if (videoCapture.isOpened())
                        videoCapture.set(cv::CAP_PROP_POS_AVI_RATIO, juce::jlimit(0.0, 1.0, (double) pendingStart));
                    needPreviewFrame.store(true);
                    juce::Logger::writeToLog("[VideoFileLoader][Seek] Applied normalized start ratio=" + juce::String(pendingStart, 3));
                }
            }
        }

        // On play edge: seek to IN point
        bool nowPlaying = playing.load();
        bool wasPlaying = lastPlaying.exchange(nowPlaying);
        if (nowPlaying && !wasPlaying)
        {
            float inN = inNormParam ? inNormParam->load() : 0.0f;
            const double durMs = totalDurationMs.load();
            if (durMs > 0.0)
            {
                double seekToMs = juce::jlimit(0.0, durMs, (double)inN * durMs);
                const juce::ScopedLock capLock(captureLock);
                if (videoCapture.isOpened())
                    videoCapture.set(cv::CAP_PROP_POS_MSEC, seekToMs);
                juce::Logger::writeToLog("[VideoFileLoader][PlayEdge] Seeking to in(ms)=" + juce::String(seekToMs));
            }
            else if (tfLocal > 1)
            {
                int inF = juce::jlimit(0, juce::jmax(1, tfLocal) - 1, (int) std::round(inN * (tfLocal - 1)));
                pendingSeekFrame.store(inF);
                juce::Logger::writeToLog("[VideoFileLoader][PlayEdge] Seeking to inF=" + juce::String(inF));
            }
            else
            {
                pendingSeekNorm.store(juce::jlimit(0.0f, 1.0f, inN));
                juce::Logger::writeToLog("[VideoFileLoader][PlayEdge] Seeking to inNorm=" + juce::String(inN, 3));
            }
            needPreviewFrame.store(true);
        }

        int seekTo = pendingSeekFrame.exchange(-1);
        if (seekTo >= 0)
        {
            const juce::ScopedLock capLock(captureLock);
            if (videoCapture.isOpened())
                videoCapture.set(cv::CAP_PROP_POS_FRAMES, (double) seekTo);
            needPreviewFrame.store(true);
            juce::Logger::writeToLog("[VideoFileLoader][Seek] Applied pending seek to frame=" + juce::String(seekTo));
        }

        // Respect play/pause
        if (!playing.load())
        {
            // If paused, show a single preview frame after (re)open
            if (needPreviewFrame.exchange(false))
            {
                cv::Mat preview;
                if (videoCapture.isOpened())
                {
                    videoCapture.read(preview);
                }
                {
                    if (!preview.empty())
                    {
                        VideoFrameManager::getInstance().setFrame(getLogicalId(), preview);
                        updateGuiFrame(preview);
                        juce::Logger::writeToLog("[VideoFileLoader][Preview] Published paused preview frame");
                        lastPosFrame.store((int) videoCapture.get(cv::CAP_PROP_POS_FRAMES));
                        if (lastFourcc.load() == 0)
                            lastFourcc.store((int) videoCapture.get(cv::CAP_PROP_FOURCC));
                        // Also try to refresh total frames after the first paused read
                        if (totalFrames.load() <= 1)
                        {
                            int tf = (int) videoCapture.get(cv::CAP_PROP_FRAME_COUNT);
                            if (tf > 1)
                            {
                                totalFrames.store(tf);
                                juce::Logger::writeToLog("[VideoFileLoader] Frame count acquired after paused read: " + juce::String(tf));
                            }
                        }
                    }
                }
            }
            wait(40);
            continue;
        }

        // Time the frame processing to maintain correct playback speed
        auto loopStartTime = juce::Time::getMillisecondCounterHiRes();
        
        cv::Mat frame;
        if (videoCapture.isOpened())
            videoCapture.read(frame);
        if (!frame.empty())
        {
            // Publish frame to central manager
            VideoFrameManager::getInstance().setFrame(getLogicalId(), frame);
            
            // Update local preview
            updateGuiFrame(frame);
            lastPosFrame.store((int) videoCapture.get(cv::CAP_PROP_POS_FRAMES));
            if (lastFourcc.load() == 0)
                lastFourcc.store((int) videoCapture.get(cv::CAP_PROP_FOURCC));
            // If frame count was unknown at open time, refresh it after first (or any) read
            if (totalFrames.load() <= 1)
            {
                int tf = (int) videoCapture.get(cv::CAP_PROP_FRAME_COUNT);
                if (tf > 1)
                {
                    totalFrames.store(tf);
                    if (videoFps > 0.0)
                        totalDurationMs.store((double)tf * (1000.0 / videoFps));
                    juce::Logger::writeToLog("[VideoFileLoader] Frame count acquired after playing read: " + juce::String(tf));
                }
            }

            // Trim window enforcement (only when frame count available)
            if (totalFrames.load() > 1)
            {
                int pos = 0;
                {
                    const juce::ScopedLock capLock(captureLock);
                    if (videoCapture.isOpened())
                        pos = (int) videoCapture.get(cv::CAP_PROP_POS_FRAMES);
                }
                float inN = inNormParam ? inNormParam->load() : 0.0f;
                float outN = outNormParam ? outNormParam->load() : 1.0f;
                inN = juce::jlimit(0.0f, 1.0f, inN);
                outN = juce::jlimit(0.0f, 1.0f, outN);
                if (outN <= inN) outN = juce::jmin(1.0f, inN + 0.01f);
                const int tfLocal = totalFrames.load();
                int inF = juce::jlimit(0, juce::jmax(0, tfLocal - 1), (int)std::round(inN * (tfLocal - 1)));
                int outF = juce::jlimit(inF + 1, juce::jmax(1, tfLocal), (int)std::round(outN * (tfLocal - 1)));
                if (pos < inF)
                {
                    juce::Logger::writeToLog("[VideoFileLoader][Trim] pos=" + juce::String(pos) + " < inF=" + juce::String(inF) + " -> seeking to inF");
                    const juce::ScopedLock capLock(captureLock);
                    if (videoCapture.isOpened())
                        videoCapture.set(cv::CAP_PROP_POS_FRAMES, (double)inF);
                }
                else if (pos >= outF)
                {
                    if (loopParam && loopParam->load() > 0.5f)
                    {
                        juce::Logger::writeToLog("[VideoFileLoader][Trim] pos>=outF looping to inF=" + juce::String(inF));
                        const juce::ScopedLock capLock(captureLock);
                        if (videoCapture.isOpened())
                            videoCapture.set(cv::CAP_PROP_POS_FRAMES, (double)inF);
                    }
                    else
                    {
                        juce::Logger::writeToLog("[VideoFileLoader][Trim] pos>=outF stopping playback");
                        playing.store(false);
                    }
                }
            }
        }
        else
        {
            // End of video file
            if (loopParam->load() > 0.5f && currentVideoFile.existsAsFile())
            {
                // Loop: reopen the file
                videoCapture.release();
                if (videoCapture.open(currentVideoFile.getFullPathName().toStdString()))
                {
                    sourceIsOpen = true;
                    juce::Logger::writeToLog("[VideoFileLoader] Looping: " + currentVideoFile.getFileName());
                }
                else
                {
                    sourceIsOpen = false;
                }
            }
            else
            {
                // Stop
                sourceIsOpen = false;
                videoCapture.release();
            }
        }
        
        // Calculate how long to wait to maintain the original FPS
        auto processingTime = juce::Time::getMillisecondCounterHiRes() - loopStartTime;
        float spd = speedParam ? speedParam->load() : 1.0f;
        spd = juce::jlimit(0.1f, 4.0f, spd);
        int waitTime = (int)((frameDurationMs / spd) - processingTime);
        if (waitTime > 0)
        {
            wait(waitTime);
        }
        // If processing took longer than frame duration, don't wait (play as fast as possible)
    }
    
    videoCapture.release();
    VideoFrameManager::getInstance().removeSource(getLogicalId());
}

void VideoFileLoaderModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgraFrame;
    cv::cvtColor(frame, bgraFrame, cv::COLOR_BGR2BGRA);
    
    const juce::ScopedLock lock(imageLock);
    
    if (latestFrameForGui.isNull() || 
        latestFrameForGui.getWidth() != bgraFrame.cols || 
        latestFrameForGui.getHeight() != bgraFrame.rows)
    {
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgraFrame.cols, bgraFrame.rows, true);
    }
    
    juce::Image::BitmapData destData(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(destData.data, bgraFrame.data, bgraFrame.total() * bgraFrame.elemSize());
}

juce::Image VideoFileLoaderModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void VideoFileLoaderModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    buffer.clear();
    
    // Output this module's logical ID
    if (buffer.getNumChannels() > 0)
    {
        float sourceId = (float)getLogicalId();
        for (int sample = 0; sample < buffer.getNumSamples(); ++sample)
        {
            buffer.setSample(0, sample, sourceId);
        }
    }
}

juce::ValueTree VideoFileLoaderModule::getExtraStateTree() const
{
    juce::ValueTree state("VideoFileLoaderState");
    // Save the absolute path of the currently loaded video file
    if (currentVideoFile.existsAsFile())
    {
        state.setProperty("videoFilePath", currentVideoFile.getFullPathName(), nullptr);
    }
    return state;
}

void VideoFileLoaderModule::setExtraStateTree(const juce::ValueTree& state)
{
    if (!state.hasType("VideoFileLoaderState")) return;
    
    juce::String filePath = state.getProperty("videoFilePath", "").toString();
    if (filePath.isNotEmpty())
    {
        juce::File restoredFile(filePath);
        if (restoredFile.existsAsFile())
        {
            videoFileToLoad = restoredFile;
            juce::Logger::writeToLog("[VideoFileLoader] Restored video file from preset: " + filePath);
        }
        else
        {
            juce::Logger::writeToLog("[VideoFileLoader] Warning: Saved video file not found: " + filePath);
        }
    }
}

#if defined(PRESET_CREATOR_UI)
ImVec2 VideoFileLoaderModule::getCustomNodeSize() const
{
    // Return different width based on zoom level (0=240,1=480,2=960)
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    const float widths[3] { 240.0f, 480.0f, 960.0f };
    return ImVec2(widths[level], 0.0f);
}

void VideoFileLoaderModule::drawParametersInNode(float itemWidth,
                                                 const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                                 const std::function<void()>& onModificationEnded)
{
    ImGui::PushItemWidth(itemWidth);
    
    if (ImGui::Button("Load Video File...", ImVec2(itemWidth, 0)))
    {
        chooseVideoFile();
    }
    
    if (currentVideoFile.existsAsFile())
    {
        ImGui::TextColored(ImVec4(0.5f, 1.0f, 0.5f, 1.0f), "%s", currentVideoFile.getFileName().toRawUTF8());
    }
    else
    {
        ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "No file loaded");
    }
    
    bool loop = loopParam->load() > 0.5f;
    if (ImGui::Checkbox("Loop", &loop))
    {
        *dynamic_cast<juce::AudioParameterBool*>(apvts.getParameter("loop")) = loop;
        onModificationEnded();
    }
    
    ImGui::Separator();
    
    // Transport sync and play/stop controls
    bool sync = syncParam ? (*syncParam > 0.5f) : true;
    if (ImGui::Checkbox("Sync to Transport", &sync))
    {
        syncToTransport.store(sync);
        if (auto* p = dynamic_cast<juce::AudioParameterBool*>(apvts.getParameter("sync"))) *p = sync;
        if (sync)
        {
            playing.store(lastTransportPlaying.load());
            // Ensure thread will (re)open current file if needed after transport resumes
            if (currentVideoFile.existsAsFile())
                videoFileToLoad = currentVideoFile;
        }
    }

    ImGui::SameLine();
    bool localPlaying = playing.load();
    if (sync) ImGui::BeginDisabled();
    const char* btn = localPlaying ? "Stop" : "Play";
    if (sync)
    {
        // Mirror transport state in label when synced
        btn = lastTransportPlaying.load() ? "Stop" : "Play";
    }
    if (ImGui::Button(btn))
    {
        playing.store(!localPlaying);
    }
    if (sync) ImGui::EndDisabled();

    // Zoom buttons (+/-) across 3 levels
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    float buttonWidth = (itemWidth / 2.0f) - 4.0f;
    const bool atMin = (level <= 0);
    const bool atMax = (level >= 2);

    if (atMin) ImGui::BeginDisabled();
    if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmax(0, level - 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMin) ImGui::EndDisabled();

    ImGui::SameLine();

    if (atMax) ImGui::BeginDisabled();
    if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmin(2, level + 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMax) ImGui::EndDisabled();
    
    ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "Source ID: %d", (int)getLogicalId());
    {
        int fcc = lastFourcc.load();
        juce::String codec = fourccToString(fcc);
        juce::String friendly = fourccFriendlyName(codec);
        juce::String ext = currentVideoFile.getFileExtension();
        if (ext.startsWithChar('.')) ext = ext.substring(1);
        ImGui::TextColored(ImVec4(0.5f, 0.8f, 0.5f, 1.0f), "Codec: %s (%s)   Container: %s",
                           codec.toRawUTF8(), friendly.toRawUTF8(), (ext.isEmpty() ? "unknown" : ext.toRawUTF8()));
        if (totalFrames.load() <= 1)
            ImGui::TextColored(ImVec4(0.9f, 0.7f, 0.2f, 1.0f), "Length unknown yet (ratio seeks)");
    }

    // --- Playback speed (slider only) ---
    float spd = speedParam ? speedParam->load() : 1.0f;
    ImGui::Separator();
    ImGui::SliderFloat("Speed", &spd, 0.25f, 4.0f, "%.2fx");
    if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("speed"))) *p = spd;

    // --- Trim / Timeline --- (always visible, never greyed)
    {
        const int tf = juce::jmax(1, totalFrames.load());
        float inN = inNormParam ? inNormParam->load() : 0.0f;
        float outN = outNormParam ? outNormParam->load() : 1.0f;
        ImGui::Separator();
        if (ImGui::SliderFloat("Start", &inN, 0.0f, 1.0f))
        {
            inN = juce::jlimit(0.0f, outN - 0.01f, inN);
            if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("in"))) *p = inN;
            if (tf > 1)
            {
                int inF = (int)std::round(inN * (tf - 1));
                pendingSeekFrame.store(inF);
                needPreviewFrame.store(true);
                juce::Logger::writeToLog("[VideoFileLoader][UI] Start set: inN=" + juce::String(inN, 3) + " inF=" + juce::String(inF));
            }
            else
            {
                pendingStartNorm.store(inN);
            }
        }
        if (ImGui::SliderFloat("End", &outN, 0.0f, 1.0f))
        {
            outN = juce::jlimit(inN + 0.01f, 1.0f, outN);
            if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("out"))) *p = outN;
            if (tf > 1)
            {
                int outF = (int)std::round(outN * (tf - 1));
                juce::Logger::writeToLog("[VideoFileLoader][UI] End set: outN=" + juce::String(outN, 3) + " outF=" + juce::String(outF));
            }
        }

        int currentFrame = lastPosFrame.load();
        float pos = (tf > 1) ? ((float) currentFrame / (float) tf) : 0.0f;
        // Clamp position UI between in/out
        float minPos = juce::jlimit(0.0f, 1.0f, inN);
        float maxPos = juce::jlimit(minPos, 1.0f, outN);
        pos = juce::jlimit(minPos, maxPos, pos);
        if (ImGui::SliderFloat("Position", &pos, 0.0f, 1.0f))
        {
            if (tf > 1)
            {
                int targetF = (int)std::round(pos * (float)(tf - 1));
                pendingSeekFrame.store(targetF);
                needPreviewFrame.store(true);
                juce::Logger::writeToLog("[VideoFileLoader][UI] Position set: posN=" + juce::String(pos, 3) + " frame=" + juce::String(targetF));
            }
            else
            {
                pendingSeekNorm.store(pos);
            }
        }
    }
    
    ImGui::PopItemWidth();
}

void VideoFileLoaderModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioOutputPin("Source ID", 0);
}
#endif



================================================================================
FILE: juce\\Source\\video\\VideoFrameManager.h
================================================================================


#pragma once

#include <opencv2/core.hpp>
#include <juce_core/juce_core.h>
#include <map>

/**
 * Thread-safe singleton for sharing video frames between source and processing nodes.
 * Source nodes publish frames, processing nodes consume them.
 */
class VideoFrameManager
{
public:
    static VideoFrameManager& getInstance() 
    {
        static VideoFrameManager instance;
        return instance;
    }

    // Called by source node's background thread to publish a frame
    void setFrame(juce::uint32 sourceId, const cv::Mat& frame) 
    {
        const juce::ScopedLock lock(frameMapLock);
        if (!frame.empty())
        {
            frame.copyTo(frameMap[sourceId]);
        }
    }

    // Called by processing node's background thread to retrieve a frame
    cv::Mat getFrame(juce::uint32 sourceId) 
    {
        const juce::ScopedLock lock(frameMapLock);
        auto it = frameMap.find(sourceId);
        if (it != frameMap.end() && !it->second.empty())
        {
            return it->second.clone();
        }
        return cv::Mat();
    }

    // Called when a source node is deleted
    void removeSource(juce::uint32 sourceId) 
    {
        const juce::ScopedLock lock(frameMapLock);
        frameMap.erase(sourceId);
    }

    // For UI: get list of active sources
    juce::StringArray getAvailableSources()
    {
        const juce::ScopedLock lock(frameMapLock);
        juce::StringArray sources;
        for (const auto& pair : frameMap)
        {
            sources.add(juce::String((int)pair.first));
        }
        return sources;
    }

private:
    VideoFrameManager() = default;
    ~VideoFrameManager() = default;
    VideoFrameManager(const VideoFrameManager&) = delete;
    VideoFrameManager& operator=(const VideoFrameManager&) = delete;

    std::map<juce::uint32, cv::Mat> frameMap;
    juce::CriticalSection frameMapLock;
};



================================================================================
FILE: juce\\Source\\audio\\graph\\ModularSynthProcessor.cpp
================================================================================


#include "ModularSynthProcessor.h"
#include "../modules/AudioInputModuleProcessor.h"
#include "../modules/RecordModuleProcessor.h"
#include "../modules/VCOModuleProcessor.h"
#include "../modules/VCFModuleProcessor.h"
#include "../modules/VCAModuleProcessor.h"
#include "../modules/NoiseModuleProcessor.h"
#include "../modules/LFOModuleProcessor.h"
#include "../modules/ADSRModuleProcessor.h"
#include "../modules/MixerModuleProcessor.h"
#include "../modules/DelayModuleProcessor.h"
#include "../modules/ReverbModuleProcessor.h"
#include "../modules/AttenuverterModuleProcessor.h"
#include "../modules/ScopeModuleProcessor.h"
#include "../modules/SAndHModuleProcessor.h"
#include "../modules/StepSequencerModuleProcessor.h"
#include "../modules/MathModuleProcessor.h"
#include "../modules/MapRangeModuleProcessor.h"
#include "../modules/RandomModuleProcessor.h"
#include "../modules/RateModuleProcessor.h"
#include "../modules/QuantizerModuleProcessor.h"
#include "../modules/SequentialSwitchModuleProcessor.h"
#include "../modules/LogicModuleProcessor.h"
#include "../modules/ValueModuleProcessor.h"
#include "../modules/ClockDividerModuleProcessor.h"
#include "../modules/WaveshaperModuleProcessor.h"
#include "../modules/MultiBandShaperModuleProcessor.h"
#include "../modules/GranulatorModuleProcessor.h"
#include "../modules/HarmonicShaperModuleProcessor.h"
#include "../modules/TrackMixerModuleProcessor.h"
#include "../modules/TTSPerformerModuleProcessor.h"
#include "../modules/ComparatorModuleProcessor.h"
#include "../modules/VocalTractFilterModuleProcessor.h"
#include "../modules/VstHostModuleProcessor.h"
#include "../modules/SampleLoaderModuleProcessor.h"
#include "../modules/FunctionGeneratorModuleProcessor.h"
#include "../modules/TimePitchModuleProcessor.h"
#include "../modules/DebugModuleProcessor.h"
#include "../modules/CommentModuleProcessor.h"
#include "../modules/MIDIPlayerModuleProcessor.h"
#include "../modules/PolyVCOModuleProcessor.h"
#include "../modules/BestPracticeNodeProcessor.h"
#include "../modules/BPMMonitorModuleProcessor.h"
#include "../modules/ShapingOscillatorModuleProcessor.h"
#include "../modules/MultiSequencerModuleProcessor.h"
#include "../modules/LagProcessorModuleProcessor.h"
#include "../modules/DeCrackleModuleProcessor.h"
#include "../modules/CVMixerModuleProcessor.h"
#include "../modules/GraphicEQModuleProcessor.h"
#include "../modules/FrequencyGraphModuleProcessor.h"
#include "../modules/ChorusModuleProcessor.h"
#include "../modules/PhaserModuleProcessor.h"
#include "../modules/CompressorModuleProcessor.h"
#include "../modules/RecordModuleProcessor.h"
#include "../modules/LimiterModuleProcessor.h"
#include "../modules/GateModuleProcessor.h"
#include "../modules/DriveModuleProcessor.h"
#include "../modules/SnapshotSequencerModuleProcessor.h"
#include "../modules/MIDICVModuleProcessor.h"
#include "../modules/MIDIFadersModuleProcessor.h"
#include "../modules/MIDIKnobsModuleProcessor.h"
#include "../modules/MIDIButtonsModuleProcessor.h"
#include "../modules/MIDIJogWheelModuleProcessor.h"
#include "../modules/MIDIPadModuleProcessor.h"
#include "../modules/MidiLoggerModuleProcessor.h"
#include "../modules/TempoClockModuleProcessor.h"
#include "../modules/PhysicsModuleProcessor.h"
#include "../modules/StrokeSequencerModuleProcessor.h"
#include "../modules/AnimationModuleProcessor.h"
#include "../modules/WebcamLoaderModule.h"
#include "../modules/VideoFileLoaderModule.h"
#include "../modules/MovementDetectorModule.h"
#include "../modules/HumanDetectorModule.h"
#include "../modules/PoseEstimatorModule.h"
#include "../modules/HandTrackerModule.h"
#include "../modules/FaceTrackerModule.h"
#include "../modules/ObjectDetectorModule.h"
#include "../modules/ColorTrackerModule.h"
#include "../modules/ContourDetectorModule.h"
#include "../modules/SemanticSegmentationModule.h"
#include "../modules/InletModuleProcessor.h"
#include "../modules/OutletModuleProcessor.h"
#include "../modules/MetaModuleProcessor.h"

ModularSynthProcessor::ModularSynthProcessor()
    : juce::AudioProcessor(BusesProperties()
                            .withInput("Input", juce::AudioChannelSet::stereo(), true)
                            .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
      apvts(*this, nullptr, "ModularSynthParams", {})
{
    internalGraph = std::make_unique<juce::AudioProcessorGraph>();

    using IOProcessor = juce::AudioProcessorGraph::AudioGraphIOProcessor;
    audioInputNode = internalGraph->addNode(std::make_unique<IOProcessor>(IOProcessor::audioInputNode));
    audioOutputNode = internalGraph->addNode(std::make_unique<IOProcessor>(IOProcessor::audioOutputNode));
    midiInputNode  = internalGraph->addNode(std::make_unique<IOProcessor>(IOProcessor::midiInputNode));

    internalGraph->addConnection({ { midiInputNode->nodeID, juce::AudioProcessorGraph::midiChannelIndex },
                                   { audioOutputNode->nodeID, juce::AudioProcessorGraph::midiChannelIndex } });
    
    probeScopeNode = internalGraph->addNode(std::make_unique<ScopeModuleProcessor>());
    probeScopeNodeId = probeScopeNode->nodeID;
    juce::Logger::writeToLog("[ModularSynth] Initialized probe scope with nodeID: " + juce::String(probeScopeNodeId.uid));
    
    // Create BPM Monitor node (always present, undeletable like output node)
    auto bpmMonitor = std::make_unique<BPMMonitorModuleProcessor>();
    bpmMonitor->setLogicalId(999); // Special ID to make it undeletable
    bpmMonitorNode = internalGraph->addNode(std::move(bpmMonitor));
    if (auto* processor = dynamic_cast<ModuleProcessor*>(bpmMonitorNode->getProcessor()))
        processor->setParent(this);
    juce::Logger::writeToLog("[ModularSynth] Initialized BPM Monitor with logicalID: 999");
    
    activeAudioProcessors.store(std::make_shared<const std::vector<std::shared_ptr<ModuleProcessor>>>());
    
    m_voices.resize(8);
    for (auto& voice : m_voices)
    {
        voice.isActive = false;
        voice.noteNumber = -1;
        voice.velocity = 0.0f;
        voice.age = 0;
        voice.targetModuleLogicalId = 0;
    }
}

ModularSynthProcessor::~ModularSynthProcessor() {}

void ModularSynthProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    internalGraph->setPlayConfigDetails(getTotalNumInputChannels(), getTotalNumOutputChannels(), sampleRate, samplesPerBlock);
    internalGraph->prepareToPlay(sampleRate, samplesPerBlock);
}

void ModularSynthProcessor::releaseResources()
{
    internalGraph->releaseResources();
}

//==============================================================================
// Multi-MIDI Device Support
//==============================================================================

void ModularSynthProcessor::processMidiWithDeviceInfo(const std::vector<MidiMessageWithDevice>& messages)
{
    const juce::ScopedLock lock(midiActivityLock);
    currentBlockMidiMessages = messages;
    
    // DEBUG LOGGING
    if (!messages.empty())
    {
        juce::Logger::writeToLog("[ModularSynth] processMidiWithDeviceInfo received " + 
                                juce::String(messages.size()) + " MIDI messages");
    }
    
    // Update activity tracking
    currentActivity.deviceChannelActivity.clear();
    currentActivity.deviceNames.clear();
    
    for (const auto& msg : messages)
    {
        // Skip system realtime messages
        if (msg.message.isMidiClock() || msg.message.isActiveSense())
            continue;
        
        int channel = msg.message.getChannel();
        if (channel >= 1 && channel <= 16)
        {
            int channelIndex = channel - 1;  // 0-15
            currentActivity.deviceChannelActivity[msg.deviceIndex][channelIndex] = true;
            currentActivity.deviceNames[msg.deviceIndex] = msg.deviceName;
        }
    }
}

ModularSynthProcessor::MidiActivityState ModularSynthProcessor::getMidiActivityState() const
{
    const juce::ScopedLock lock(midiActivityLock);
    return currentActivity;
}

//==============================================================================
// Audio Processing
//==============================================================================

void ModularSynthProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    try {
        // NOTE: Both tempo and division control flags are managed by Tempo Clock modules directly
        // No resets here to avoid flickering in UI
        
        // --- ADD THIS LOGGING BLOCK ---
        if (!midiMessages.isEmpty())
        {
            // If we get this message, it means MIDI is successfully reaching the synth.
            juce::Logger::writeToLog("[SynthCore] Received " + juce::String(midiMessages.getNumEvents()) + " MIDI events this block.");
            m_midiActivityFlag.store(true);
        }
        // --- END OF BLOCK ---
        
        if (m_transportState.isPlaying)
        {
            m_samplePosition += buffer.getNumSamples();
            m_transportState.songPositionSeconds = m_samplePosition / getSampleRate();
            m_transportState.songPositionBeats = (m_transportState.songPositionSeconds / 60.0) * m_transportState.bpm;
        }

        // --- FINAL THREAD-SAFE FIX ---
        auto currentProcessors = activeAudioProcessors.load();
        if (currentProcessors)
        {
            // Iterate over the safe, shared list.
            for (const auto& modulePtr : *currentProcessors)
            {
                // SAFETY NET + GRANULAR LOGGING
                if (modulePtr != nullptr)
                {
                    // Log the memory address before calling the function
                    // juce::Logger::writeToLog("[AudioThread] Ticking module at 0x" + juce::String::toHexString((juce::pointer_sized_int)modulePtr.get()));
                    modulePtr->setTimingInfo(m_transportState);
                }
                else
                {
                    // This should never happen with the shared_ptr fix, but if it does, it's critical info.
                    juce::Logger::writeToLog("[AudioThread] CRITICAL WARNING: Encountered nullptr in active processor list!");
                }
            }
        }
        // --- END OF FIX ---
        
        // === MULTI-MIDI DEVICE SUPPORT: Distribute device-aware MIDI to modules ===
        // This happens BEFORE voice management and graph processing
        // Modules receive device info and can filter by device/channel
        {
            const juce::ScopedLock lock(midiActivityLock);
            
            // DEBUG: Log every processBlock attempt to check the buffer
            static int checkCount = 0;
            static int distributionCount = 0;
            checkCount++;
            
            if (!currentBlockMidiMessages.empty())
            {
                distributionCount++;
                
                // Log only first few times to avoid spam
                if (distributionCount <= 5)
                {
                    juce::Logger::writeToLog("[ModularSynth processBlock] CHECK #" + juce::String(checkCount) + 
                                            " - Found " + juce::String(currentBlockMidiMessages.size()) + " messages to distribute");
                }
                
                if (internalGraph)
                {
                    int nodeCount = internalGraph->getNodes().size();
                    int moduleCount = 0;
                    
                    if (distributionCount <= 5)
                    {
                        juce::Logger::writeToLog("[ModularSynth] Distributing to " + juce::String(nodeCount) + " nodes");
                    }
                    
                    for (auto* node : internalGraph->getNodes())
                    {
                        if (auto* module = dynamic_cast<ModuleProcessor*>(node->getProcessor()))
                        {
                            moduleCount++;
                            module->handleDeviceSpecificMidi(currentBlockMidiMessages);
                        }
                    }
                    
                    if (distributionCount <= 5)
                    {
                        juce::Logger::writeToLog("[ModularSynth] Called handleDeviceSpecificMidi on " + 
                                                juce::String(moduleCount) + " modules");
                    }
                    
                    // Merge device-aware MIDI into standard MidiBuffer for backward compatibility
                    for (const auto& msg : currentBlockMidiMessages)
                    {
                        midiMessages.addEvent(msg.message, 0);
                    }
                    
                    // Clear for next block
                    currentBlockMidiMessages.clear();
                }
                else
                {
                    juce::Logger::writeToLog("[ModularSynth] WARNING: Have MIDI messages but internalGraph is null!");
                }
            }
        }
        // === END MULTI-MIDI DISTRIBUTION ===
        
        if (m_voiceManagerEnabled && !m_voices.empty())
        {
            juce::MidiBuffer processedMidi;
            for (const auto metadata : midiMessages)
            {
                const auto msg = metadata.getMessage();
                if (msg.isNoteOn())
                {
                    int voiceIndex = findFreeVoice();
                    if (voiceIndex < 0) voiceIndex = findOldestVoice();
                    if (voiceIndex >= 0)
                    {
                        assignNoteToVoice(voiceIndex, msg);
                        processedMidi.addEvent(msg, metadata.samplePosition);
                    }
                }
                else if (msg.isNoteOff())
                {
                    releaseVoice(msg);
                    processedMidi.addEvent(msg, metadata.samplePosition);
                }
                else
                {
                    processedMidi.addEvent(msg, metadata.samplePosition);
                }
            }
            midiMessages.swapWith(processedMidi);
        }
        
        internalGraph->processBlock(buffer, midiMessages);
        static int silentCtr = 0;
        if (buffer.getMagnitude(0, buffer.getNumSamples()) < 1.0e-6f)
        {
            if ((++silentCtr % 600) == 0)
                juce::Logger::writeToLog("[ModularSynthProcessor] silent block from internal graph");
        }
        else
        {
            silentCtr = 0;
        }
    } catch (const std::exception& e) {
        juce::Logger::writeToLog(juce::String("[ModSynth][FATAL] Exception in processBlock: ") + e.what());
        buffer.clear();
        return;
    } catch (...) {
        juce::Logger::writeToLog("[ModSynth][FATAL] Unknown exception in processBlock");
        buffer.clear();
        return;
    }
}

void ModularSynthProcessor::getStateInformation(juce::MemoryBlock& destData)
{
    const juce::ScopedLock lock (moduleLock);
    juce::ValueTree root("ModularSynthPreset");
    root.setProperty("version", 1, nullptr);
    root.setProperty("bpm", m_transportState.bpm, nullptr);

    juce::ValueTree modsVT("modules");
    std::map<juce::uint32, juce::uint32> nodeUidToLogical;
    for (const auto& kv : logicalIdToModule)
    {
        const juce::uint32 logicalId = kv.first;
        const auto nodeUID = (juce::uint32) kv.second.nodeID.uid;
        nodeUidToLogical[nodeUID] = logicalId;

        juce::ValueTree mv("module");
        mv.setProperty("logicalId", (int) logicalId, nullptr);
        mv.setProperty("type", kv.second.type, nullptr);
        auto itNode = modules.find(nodeUID);
        if (itNode != modules.end())
        {
            if (auto* modProc = dynamic_cast<ModuleProcessor*>(itNode->second->getProcessor()))
            {
                if (auto* vstHost = dynamic_cast<VstHostModuleProcessor*>(modProc))
                {
                    if (auto extra = vstHost->getExtraStateTree(); extra.isValid())
                    {
                        juce::ValueTree extraWrapper("extra");
                        extraWrapper.addChild(extra, -1, nullptr);
                        mv.addChild(extraWrapper, -1, nullptr);
                    }
                }
                else
                {
                    juce::ValueTree params = modProc->getAPVTS().copyState();
                    juce::ValueTree paramsWrapper("params");
                    paramsWrapper.addChild(params, -1, nullptr);
                    mv.addChild(paramsWrapper, -1, nullptr);

                    if (auto extra = modProc->getExtraStateTree(); extra.isValid())
                    {
                        juce::ValueTree extraWrapper("extra");
                        extraWrapper.addChild(extra, -1, nullptr);
                        mv.addChild(extraWrapper, -1, nullptr);
                    }
                }
            }
        }
        modsVT.addChild(mv, -1, nullptr);
    }
    root.addChild(modsVT, -1, nullptr);

    juce::ValueTree connsVT("connections");
    for (const auto& c : internalGraph->getConnections())
    {
        const juce::uint32 srcUID = (juce::uint32) c.source.nodeID.uid;
        const juce::uint32 dstUID = (juce::uint32) c.destination.nodeID.uid;
        juce::ValueTree cv("connection");
        auto srcIt = nodeUidToLogical.find(srcUID);
        auto dstIt = nodeUidToLogical.find(dstUID);
        if (srcIt != nodeUidToLogical.end() && dstIt != nodeUidToLogical.end())
        {
            cv.setProperty("srcId", (int) srcIt->second, nullptr);
            cv.setProperty("srcChan", (int) c.source.channelIndex, nullptr);
            cv.setProperty("dstId", (int) dstIt->second, nullptr);
            cv.setProperty("dstChan", (int) c.destination.channelIndex, nullptr);
        }
        else if (srcIt != nodeUidToLogical.end() && c.destination.nodeID == audioOutputNode->nodeID)
        {
            cv.setProperty("srcId", (int) srcIt->second, nullptr);
            cv.setProperty("srcChan", (int) c.source.channelIndex, nullptr);
            cv.setProperty("dstId", juce::String("output"), nullptr);
            cv.setProperty("dstChan", (int) c.destination.channelIndex, nullptr);
        }
        else
        {
            continue;
        }
        connsVT.addChild(cv, -1, nullptr);
    }
    root.addChild(connsVT, -1, nullptr);

    if (auto xml = root.createXml())
    {
        juce::MemoryOutputStream mos(destData, false);
        xml->writeTo(mos);
    }
}

void ModularSynthProcessor::setStateInformation(const void* data, int sizeInBytes)
{
    juce::Logger::writeToLog("--- Restoring Snapshot ---");
    std::unique_ptr<juce::XmlElement> xml (juce::XmlDocument::parse(juce::String::fromUTF8((const char*)data, (size_t)sizeInBytes)));
    if (!xml || !xml->hasTagName("ModularSynthPreset"))
    {
        juce::Logger::writeToLog("[STATE] ERROR: Invalid XML or wrong root tag. Aborting restore.");
        return;
    }

    clearAll();
    juce::Logger::writeToLog("[STATE] Cleared existing state.");

    juce::ValueTree root = juce::ValueTree::fromXml(*xml);
    
    // Restore global transport settings
    m_transportState.bpm = root.getProperty("bpm", 120.0);
    juce::Logger::writeToLog("[STATE] Restored BPM to " + juce::String(m_transportState.bpm));
    
    auto modsVT = root.getChildWithName("modules");
    if (!modsVT.isValid())
    {
        juce::Logger::writeToLog("[STATE] WARNING: No <modules> block found in preset.");
        return;
    }
    
    juce::Logger::writeToLog("[STATE] Found <modules> block with " + juce::String(modsVT.getNumChildren()) + " children.");
    juce::uint32 maxId = 0;
    for (int i = 0; i < modsVT.getNumChildren(); ++i)
    {
        auto mv = modsVT.getChild(i);
        if (mv.hasType("module"))
        {
            maxId = juce::jmax(maxId, (juce::uint32)(int)mv.getProperty("logicalId", 0));
        }
    }
    nextLogicalId = maxId + 1;

    std::map<juce::uint32, NodeID> logicalToNodeId;
    juce::Logger::writeToLog("[STATE] Starting module recreation pass...");
    
    for (int i = 0; i < modsVT.getNumChildren(); ++i)
    {
        auto mv = modsVT.getChild(i);
        if (!mv.hasType("module"))
        {
            juce::Logger::writeToLog("[STATE] Skipping non-module child at index " + juce::String(i));
            continue;
        }

        const juce::uint32 logicalId = (juce::uint32)(int)mv.getProperty("logicalId", 0);
        const juce::String type = mv.getProperty("type").toString();

        juce::Logger::writeToLog("[STATE] Processing module " + juce::String(i) + ": logicalId=" + juce::String(logicalId) + " type='" + type + "'");

        if (logicalId > 0 && type.isNotEmpty())
        {
            NodeID nodeId;
            
            auto extraWrapper = mv.getChildWithName("extra");
            bool isVstModule = false;
            
            if (extraWrapper.isValid() && extraWrapper.getNumChildren() > 0)
            {
                auto extraState = extraWrapper.getChild(0);
                if (extraState.hasType("VstHostState"))
                {
                    isVstModule = true;
                    juce::Logger::writeToLog("[STATE]   Loading VST module...");
                    
                    juce::String identifier = extraState.getProperty("fileOrIdentifier", "").toString();
                    
                    if (identifier.isNotEmpty() && pluginFormatManager != nullptr && knownPluginList != nullptr)
                    {
                        bool found = false;
                        for (const auto& desc : knownPluginList->getTypes())
                        {
                            if (desc.fileOrIdentifier == identifier)
                            {
                                juce::Logger::writeToLog("[STATE]   Found VST to load: " + desc.name);
                                nodeId = addVstModule(*pluginFormatManager, desc, logicalId);
                                found = true;
                                break;
                            }
                        }
                        
                        if (!found)
                        {
                            juce::Logger::writeToLog("[STATE]   ERROR: VST plugin not found: " + identifier);
                        }
                    }
                    else
                    {
                        juce::Logger::writeToLog("[STATE]   ERROR: No plugin identifier or format manager/list not available");
                    }
                    
                    if (nodeId.uid == 0)
                    {
                        juce::Logger::writeToLog("[STATE]   ERROR: Failed to create VST module, skipping...");
                        continue;
                    }
                }
            }
            
            if (!isVstModule)
            {
                juce::Logger::writeToLog("[STATE]   Calling addModule('" + type + "')...");
                nodeId = addModule(type, false);
                juce::Logger::writeToLog("[STATE]   addModule returned nodeId.uid=" + juce::String(nodeId.uid));
            }
            
            auto* node = internalGraph->getNodeForId(nodeId);
            
            if (node)
            {
                juce::Logger::writeToLog("[STATE]   Node created successfully.");
                
                if (!isVstModule)
                {
                    for (auto it = logicalIdToModule.begin(); it != logicalIdToModule.end(); )
                    {
                        if (it->second.nodeID == nodeId)
                            it = logicalIdToModule.erase(it);
                        else
                            ++it;
                    }
                    logicalIdToModule[logicalId] = LogicalModule{ nodeId, type };
                }
                
                logicalToNodeId[logicalId] = nodeId;
                juce::Logger::writeToLog("[STATE]   Mapped logicalId " + juce::String(logicalId) + " to nodeId.uid " + juce::String(nodeId.uid));

                // --- FIX: Restore extra state FIRST ---
                // This will load the clip and reset trim sliders to defaults.
                auto extraWrapper = mv.getChildWithName("extra");
                if (extraWrapper.isValid() && extraWrapper.getNumChildren() > 0)
                {
                    auto extra = extraWrapper.getChild(0);
                    if (auto* mp = dynamic_cast<ModuleProcessor*>(node->getProcessor()))
                    {
                        mp->setExtraStateTree(extra);
                        juce::Logger::writeToLog("[STATE]   Restored extra state.");
                    }
                }

                // Now restore parameters SECOND.
                // This will overwrite the temporary default trim values with the correct saved values.
                auto paramsWrapper = mv.getChildWithName("params");
                if (paramsWrapper.isValid() && paramsWrapper.getNumChildren() > 0)
                {
                    auto params = paramsWrapper.getChild(0);
                    if (auto* mp = dynamic_cast<ModuleProcessor*>(node->getProcessor()))
                    {
                        mp->getAPVTS().replaceState(params);
                        juce::Logger::writeToLog("[STATE]   Restored parameters.");
                    }
                }
            }
            else
            {
                juce::Logger::writeToLog("[STATE]   ERROR: Node creation failed! nodeId.uid was " + juce::String(nodeId.uid) + " but getNodeForId returned nullptr.");
            }
        }
        else
        {
            juce::Logger::writeToLog("[STATE]   Skipping module: logicalId=" + juce::String(logicalId) + " (valid=" + juce::String(logicalId > 0 ? "yes" : "no") + ") type='" + type + "' (empty=" + juce::String(type.isEmpty() ? "yes" : "no") + ")");
        }
    }
    
    juce::Logger::writeToLog("[STATE] Module recreation complete. Created " + juce::String(logicalToNodeId.size()) + " modules.");

    auto connsVT = root.getChildWithName("connections");
    if (connsVT.isValid())
    {
        juce::Logger::writeToLog("[STATE] Restoring " + juce::String(connsVT.getNumChildren()) + " connections...");
        int connectedCount = 0;
        int skippedCount = 0;
        
        for (int i = 0; i < connsVT.getNumChildren(); ++i)
        {
            auto cv = connsVT.getChild(i);
            if (!cv.hasType("connection")) continue;

            const juce::uint32 srcId = (juce::uint32)(int)cv.getProperty("srcId");
            const int srcChan = (int)cv.getProperty("srcChan", 0);
            const bool dstIsOutput = cv.getProperty("dstId").toString() == "output";
            const juce::uint32 dstId = dstIsOutput ? 0 : (juce::uint32)(int)cv.getProperty("dstId");
            const int dstChan = (int)cv.getProperty("dstChan", 0);

            NodeID srcNodeId = logicalToNodeId[srcId];
            NodeID dstNodeId = dstIsOutput ? audioOutputNode->nodeID : logicalToNodeId[dstId];

            if (srcNodeId.uid != 0 && dstNodeId.uid != 0)
            {
                connect(srcNodeId, srcChan, dstNodeId, dstChan);
                connectedCount++;
            }
            else
            {
                juce::Logger::writeToLog("[STATE]   WARNING: Skipping connection " + juce::String(i) + 
                                        ": srcId=" + juce::String(srcId) + " (uid=" + juce::String(srcNodeId.uid) + 
                                        ")  dstId=" + (dstIsOutput ? "output" : juce::String(dstId)) + 
                                        " (uid=" + juce::String(dstNodeId.uid) + ")");
                skippedCount++;
            }
        }
        
        juce::Logger::writeToLog("[STATE] Connection restore complete: " + juce::String(connectedCount) + 
                                " connected, " + juce::String(skippedCount) + " skipped.");
    }
    else
    {
        juce::Logger::writeToLog("[STATE] WARNING: No <connections> block found in preset.");
    }


    juce::Logger::writeToLog("[STATE] Calling commitChanges()...");
    commitChanges();
    juce::Logger::writeToLog("[STATE] Restore complete.");
}

namespace {
    static juce::String toLowerId (const juce::String& s)
    {
        return s.toLowerCase();
    }

    using Creator = std::function<std::unique_ptr<juce::AudioProcessor>()>;

    static std::map<juce::String, Creator>& getModuleFactory()
    {
        static std::map<juce::String, Creator> factory;
        static bool initialised = false;
        if (!initialised)
        {
            auto reg = [&](const juce::String& key, Creator c) { factory.emplace(toLowerId(key), std::move(c)); };

            reg("vco", []{ return std::make_unique<VCOModuleProcessor>(); });
            reg("audio_input", []{ return std::make_unique<AudioInputModuleProcessor>(); });
            reg("vcf", []{ return std::make_unique<VCFModuleProcessor>(); });
            reg("vca", []{ return std::make_unique<VCAModuleProcessor>(); });
            reg("noise", []{ return std::make_unique<NoiseModuleProcessor>(); });
            reg("lfo", []{ return std::make_unique<LFOModuleProcessor>(); });
            reg("adsr", []{ return std::make_unique<ADSRModuleProcessor>(); });
            reg("mixer", []{ return std::make_unique<MixerModuleProcessor>(); });
            reg("cv_mixer", []{ return std::make_unique<CVMixerModuleProcessor>(); });
            reg("track_mixer", []{ return std::make_unique<TrackMixerModuleProcessor>(); });
            reg("delay", []{ return std::make_unique<DelayModuleProcessor>(); });
            reg("reverb", []{ return std::make_unique<ReverbModuleProcessor>(); });
            reg("attenuverter", []{ return std::make_unique<AttenuverterModuleProcessor>(); });
            reg("scope", []{ return std::make_unique<ScopeModuleProcessor>(); });
            reg("frequency_graph", []{ return std::make_unique<FrequencyGraphModuleProcessor>(); });
            reg("s_and_h", []{ return std::make_unique<SAndHModuleProcessor>(); });
            reg("sequencer", []{ return std::make_unique<StepSequencerModuleProcessor>(); });
            reg("math", []{ return std::make_unique<MathModuleProcessor>(); });
            reg("map_range", []{ return std::make_unique<MapRangeModuleProcessor>(); });
            reg("comparator", []{ return std::make_unique<ComparatorModuleProcessor>(); });
            reg("random", []{ return std::make_unique<RandomModuleProcessor>(); });
            reg("rate", []{ return std::make_unique<RateModuleProcessor>(); });
            reg("quantizer", []{ return std::make_unique<QuantizerModuleProcessor>(); });
            reg("sequential_switch", []{ return std::make_unique<SequentialSwitchModuleProcessor>(); });
            reg("logic", []{ return std::make_unique<LogicModuleProcessor>(); });
            reg("clock_divider", []{ return std::make_unique<ClockDividerModuleProcessor>(); });
            reg("waveshaper", []{ return std::make_unique<WaveshaperModuleProcessor>(); });
            reg("8bandshaper", []{ return std::make_unique<MultiBandShaperModuleProcessor>(); });
            reg("granulator", []{ return std::make_unique<GranulatorModuleProcessor>(); });
            reg("harmonic_shaper", []{ return std::make_unique<HarmonicShaperModuleProcessor>(); });
            reg("debug", []{ return std::make_unique<DebugModuleProcessor>(); });
            reg("input_debug", []{ return std::make_unique<InputDebugModuleProcessor>(); });
            reg("vocal_tract_filter", []{ return std::make_unique<VocalTractFilterModuleProcessor>(); });
            reg("value", []{ return std::make_unique<ValueModuleProcessor>(); });
            reg("tts_performer", []{ return std::make_unique<TTSPerformerModuleProcessor>(); });
            reg("sample_loader", []{ return std::make_unique<SampleLoaderModuleProcessor>(); });
            reg("function_generator", []{ return std::make_unique<FunctionGeneratorModuleProcessor>(); });
            reg("timepitch", []{ return std::make_unique<TimePitchModuleProcessor>(); });
            reg("midi_player", []{ return std::make_unique<MIDIPlayerModuleProcessor>(); });
            reg("polyvco", []{ return std::make_unique<PolyVCOModuleProcessor>(); });
            reg("best_practice", []{ return std::make_unique<BestPracticeNodeProcessor>(); });
            reg("shaping_oscillator", []{ return std::make_unique<ShapingOscillatorModuleProcessor>(); });
            reg("multi_sequencer", []{ return std::make_unique<MultiSequencerModuleProcessor>(); });
            reg("lag_processor", []{ return std::make_unique<LagProcessorModuleProcessor>(); });
            reg("de_crackle", []{ return std::make_unique<DeCrackleModuleProcessor>(); });
            reg("graphic_eq", []{ return std::make_unique<GraphicEQModuleProcessor>(); });
            reg("chorus", []{ return std::make_unique<ChorusModuleProcessor>(); });
            reg("phaser", []{ return std::make_unique<PhaserModuleProcessor>(); });
            reg("compressor", []{ return std::make_unique<CompressorModuleProcessor>(); });
            reg("recorder", []{ return std::make_unique<RecordModuleProcessor>(); });
            reg("limiter", []{ return std::make_unique<LimiterModuleProcessor>(); });
            reg("gate", []{ return std::make_unique<GateModuleProcessor>(); });
            reg("drive", []{ return std::make_unique<DriveModuleProcessor>(); });
            reg("comment", []{ return std::make_unique<CommentModuleProcessor>(); });
            reg("snapshot_sequencer", []{ return std::make_unique<SnapshotSequencerModuleProcessor>(); });
            reg("midi_cv", []{ return std::make_unique<MIDICVModuleProcessor>(); });
            reg("midi_faders", []{ return std::make_unique<MIDIFadersModuleProcessor>(); });
            reg("midi_knobs", []{ return std::make_unique<MIDIKnobsModuleProcessor>(); });
            reg("midi_buttons", []{ return std::make_unique<MIDIButtonsModuleProcessor>(); });
            reg("midi_jog_wheel", []{ return std::make_unique<MIDIJogWheelModuleProcessor>(); });
            reg("midi_pads", []{ return std::make_unique<MIDIPadModuleProcessor>(); });
            reg("midi_logger", []{ return std::make_unique<MidiLoggerModuleProcessor>(); });
            reg("tempo_clock", []{ return std::make_unique<TempoClockModuleProcessor>(); });
            reg("physics", []{ return std::make_unique<PhysicsModuleProcessor>(); });
            reg("animation", []{ return std::make_unique<AnimationModuleProcessor>(); });
            reg("bpm_monitor", []{ return std::make_unique<BPMMonitorModuleProcessor>(); });
            reg("webcam_loader", []{ return std::make_unique<WebcamLoaderModule>(); });
            reg("video_file_loader", []{ return std::make_unique<VideoFileLoaderModule>(); });
            reg("movement_detector", []{ return std::make_unique<MovementDetectorModule>(); });
            reg("human_detector", []{ return std::make_unique<HumanDetectorModule>(); });
            reg("pose_estimator", []{ return std::make_unique<PoseEstimatorModule>(); });
            reg("hand_tracker", []{ return std::make_unique<HandTrackerModule>(); });
            reg("face_tracker", []{ return std::make_unique<FaceTrackerModule>(); });
            reg("object_detector", []{ return std::make_unique<ObjectDetectorModule>(); });
            reg("color_tracker", []{ return std::make_unique<ColorTrackerModule>(); });
            reg("contour_detector", []{ return std::make_unique<ContourDetectorModule>(); });
            reg("semantic_segmentation", []{ return std::make_unique<SemanticSegmentationModule>(); });
            reg("stroke_sequencer", []{ return std::make_unique<StrokeSequencerModuleProcessor>(); });
            
            reg("meta module", []{ return std::make_unique<MetaModuleProcessor>(); });
            reg("metamodule", []{ return std::make_unique<MetaModuleProcessor>(); });
            reg("inlet", []{ return std::make_unique<InletModuleProcessor>(); });
            reg("outlet", []{ return std::make_unique<OutletModuleProcessor>(); });

            initialised = true;
        }
        return factory;
    }
}

ModularSynthProcessor::NodeID ModularSynthProcessor::addModule(const juce::String& moduleType, bool commit)
{
    const juce::ScopedLock lock (moduleLock);
    auto& factory = getModuleFactory();
    const juce::String key = moduleType.toLowerCase();
    std::unique_ptr<juce::AudioProcessor> processor;

    if (auto it = factory.find(key); it != factory.end())
        processor = it->second();

    if (! processor)
    {
        for (const auto& kv : factory)
            if (moduleType.equalsIgnoreCase(kv.first)) { processor = kv.second(); break; }
    }

    if (processor)
    {
        auto node = internalGraph->addNode(std::move(processor), {}, juce::AudioProcessorGraph::UpdateKind::none);
        if (auto* mp = dynamic_cast<ModuleProcessor*>(node->getProcessor()))
            mp->setParent(this);
        modules[(juce::uint32) node->nodeID.uid] = node;
        const juce::uint32 logicalId = nextLogicalId++;
        logicalIdToModule[logicalId] = LogicalModule{ node->nodeID, moduleType };
        if (auto* mp = dynamic_cast<ModuleProcessor*>(node->getProcessor()))
            mp->setLogicalId(logicalId);
        
        if (moduleType.equalsIgnoreCase("audio_input"))
        {
            std::vector<int> defaultMapping = {0, 1};
            setAudioInputChannelMapping(node->nodeID, defaultMapping);
        }
        
        if (commit)
        {
            // Ensure the new module is immediately active
            commitChanges();
        }
        
        return node->nodeID;
    }

    juce::Logger::writeToLog("[ModSynth][WARN] Unknown module type: " + moduleType);
    return {};
}

ModularSynthProcessor::NodeID ModularSynthProcessor::addVstModule(
    juce::AudioPluginFormatManager& formatManager,
    const juce::PluginDescription& vstDesc,
    juce::uint32 logicalIdToAssign)
{
    juce::String errorMessage;
    std::unique_ptr<juce::AudioPluginInstance> instance = 
        formatManager.createPluginInstance(vstDesc, getSampleRate(), getBlockSize(), errorMessage);

    if (instance == nullptr)
    {
        juce::Logger::writeToLog("[ModSynth][ERROR] Could not create VST instance: " + errorMessage);
        return {};
    }

    auto wrapper = std::make_unique<VstHostModuleProcessor>(std::move(instance), vstDesc);
    
    auto node = internalGraph->addNode(std::move(wrapper), {}, juce::AudioProcessorGraph::UpdateKind::none);

    if (auto* mp = dynamic_cast<ModuleProcessor*>(node->getProcessor()))
        mp->setParent(this);
    
    modules[(juce::uint32) node->nodeID.uid] = node;
    
    logicalIdToModule[logicalIdToAssign] = LogicalModule{ node->nodeID, vstDesc.name };
    
    if (auto* mp = dynamic_cast<ModuleProcessor*>(node->getProcessor()))
        mp->setLogicalId(logicalIdToAssign);
    
    juce::Logger::writeToLog("[ModSynth] Added VST module: " + vstDesc.name + " with logical ID " + juce::String(logicalIdToAssign));
    return node->nodeID;
}

ModularSynthProcessor::NodeID ModularSynthProcessor::addVstModule(
    juce::AudioPluginFormatManager& formatManager,
    const juce::PluginDescription& vstDesc)
{
    const juce::uint32 logicalId = nextLogicalId++;
    auto nodeId = addVstModule(formatManager, vstDesc, logicalId);
    
    if (nodeId.uid != 0)
        commitChanges();
    
    return nodeId;
}

void ModularSynthProcessor::removeModule(const NodeID& nodeID)
{
    if (nodeID.uid == 0) return;
    const juce::ScopedLock lock(moduleLock); // Ensure thread-safe access

    // --- LOGGING ---
    if (auto* node = internalGraph->getNodeForId(nodeID))
    {
        if (auto* proc = node->getProcessor())
        {
            juce::Logger::writeToLog("[GraphSync] Deleting module L-ID " + juce::String(getLogicalIdForNode(nodeID)) + 
                                   " (ptr: 0x" + juce::String::toHexString((int64_t)proc) + ")");
        }
    }
    // --- END LOGGING ---

    const juce::uint32 logicalId = getLogicalIdForNode(nodeID);

    internalGraph->removeNode(nodeID, juce::AudioProcessorGraph::UpdateKind::none);
    
    modules.erase((juce::uint32) nodeID.uid);
    if (logicalId != 0)
    {
        logicalIdToModule.erase(logicalId);
    }
}

bool ModularSynthProcessor::connect(const NodeID& sourceNodeID, int sourceChannel, const NodeID& destNodeID, int destChannel)
{
    juce::AudioProcessorGraph::Connection connection {
        { sourceNodeID, sourceChannel },
        { destNodeID, destChannel }
    };

    for (const auto& existing : internalGraph->getConnections())
    {
        if (existing.source.nodeID == sourceNodeID &&
            existing.source.channelIndex == sourceChannel &&
            existing.destination.nodeID == destNodeID &&
            existing.destination.channelIndex == destChannel)
        {
            juce::Logger::writeToLog("[ModSynth][INFO] Skipping duplicate connection [" + juce::String(sourceNodeID.uid) + ":" + juce::String(sourceChannel)
                                     + "] -> [" + juce::String(destNodeID.uid) + ":" + juce::String(destChannel) + "]");
            return true;
        }
    }

    const bool ok = internalGraph->addConnection(connection, juce::AudioProcessorGraph::UpdateKind::none);
    if (! ok)
    {
        juce::Logger::writeToLog("[ModSynth][WARN] Failed to connect [" + juce::String(sourceNodeID.uid) + ":" + juce::String(sourceChannel)
                                 + "] -> [" + juce::String(destNodeID.uid) + ":" + juce::String(destChannel) + "]");
    }
    return ok;
}

void ModularSynthProcessor::commitChanges()
{
    internalGraph->rebuild();
    
    if (getSampleRate() > 0 && getBlockSize() > 0)
    {
        internalGraph->prepareToPlay(getSampleRate(), getBlockSize());
    }

    juce::Logger::writeToLog("--- Modular Synth Internal Patch State ---");
    juce::Logger::writeToLog("Num Nodes: " + juce::String(internalGraph->getNodes().size()));
    juce::Logger::writeToLog("Num Connections: " + juce::String(internalGraph->getConnections().size()));
    for (const auto& node : internalGraph->getNodes())
    {
        auto* p = node->getProcessor();
        juce::String name = p ? p->getName() : juce::String("<null>");
        const int ins  = p ? p->getTotalNumInputChannels()  : -1;
        const int outs = p ? p->getTotalNumOutputChannels() : -1;
        juce::Logger::writeToLog("  Node: id=" + juce::String(node->nodeID.uid) + " name='" + name + "' ins=" + juce::String(ins) + " outs=" + juce::String(outs));
    }
    for (const auto& conn : internalGraph->getConnections())
    {
        juce::Logger::writeToLog("  Connection: [" + juce::String(conn.source.nodeID.uid) + ":" + juce::String(conn.source.channelIndex)
            + "] -> [" + juce::String(conn.destination.nodeID.uid) + ":" + juce::String(conn.destination.channelIndex) + "]");
    }
    juce::Logger::writeToLog("-----------------------------------------");
    
    for (const auto& kv : logicalIdToModule)
    {
        if (ModuleProcessor* mp = getModuleForLogical(kv.first))
        {
            mp->setLogicalId(kv.first);
        }
    }
    
    // --- FINAL THREAD-SAFE FIX: Rebuild the list of active processors for the audio thread ---
    auto newProcessors = std::make_shared<std::vector<std::shared_ptr<ModuleProcessor>>>();
    {
        const juce::ScopedLock lock(moduleLock);
        newProcessors->reserve(logicalIdToModule.size());
        juce::Logger::writeToLog("[GraphSync] Building new processor list...");
        for (const auto& pair : logicalIdToModule)
        {
            // Find the Node::Ptr from the modules map
            auto modIt = modules.find((juce::uint32)pair.second.nodeID.uid);
            if (modIt != modules.end())
            {
                auto nodePtr = modIt->second; // This is a Node::Ptr (shared_ptr<Node>)
                if (auto* proc = dynamic_cast<ModuleProcessor*>(nodePtr->getProcessor()))
                {
                    // Create a shared_ptr to the processor with a custom deleter that keeps the Node alive
                    auto processor = std::shared_ptr<ModuleProcessor>(proc, [nodePtr](ModuleProcessor*) {
                        // Custom deleter: just hold the nodePtr, don't actually delete the processor
                        // When this shared_ptr is destroyed, the nodePtr will be released
                    });
                    newProcessors->push_back(processor);
                    juce::Logger::writeToLog("  [+] Adding module L-ID " + juce::String(pair.first) + 
                                           " (ptr: 0x" + juce::String::toHexString((int64_t)proc) + ")");
                }
            }
        }
    }
    activeAudioProcessors.store(newProcessors);
    juce::Logger::writeToLog("[GraphSync] Updated active processor list for audio thread with " + juce::String(newProcessors->size()) + " modules.");
}

void ModularSynthProcessor::clearAll()
{
    const juce::ScopedLock lock (moduleLock);
    
    // --- LOGGING ---
    juce::Logger::writeToLog("[GraphSync] clearAll() initiated - removing " + juce::String(logicalIdToModule.size()) + " modules");
    // --- END LOGGING ---
    
    for (const auto& kv : logicalIdToModule)
    {
        internalGraph->removeNode(kv.second.nodeID, juce::AudioProcessorGraph::UpdateKind::none);
    }

    modules.clear();
    logicalIdToModule.clear();
    nextLogicalId = 1;

    commitChanges();
}

void ModularSynthProcessor::clearAllConnections()
{
    auto connections = internalGraph->getConnections();
    for (const auto& conn : connections)
    {
        if (conn.source.channelIndex != juce::AudioProcessorGraph::midiChannelIndex && 
            conn.destination.channelIndex != juce::AudioProcessorGraph::midiChannelIndex)
        {
            internalGraph->removeConnection(conn, juce::AudioProcessorGraph::UpdateKind::none);
        }
    }
    commitChanges();
}

void ModularSynthProcessor::clearOutputConnections()
{
    if (audioOutputNode == nullptr)
        return;

    auto connections = internalGraph->getConnections();
    for (const auto& conn : connections)
    {
        if (conn.destination.nodeID == audioOutputNode->nodeID)
        {
            internalGraph->removeConnection(conn, juce::AudioProcessorGraph::UpdateKind::none);
        }
    }
    commitChanges();
}

void ModularSynthProcessor::clearConnectionsForNode(const NodeID& nodeID)
{
    if (nodeID.uid == 0) return;

    auto connections = internalGraph->getConnections();
    for (const auto& conn : connections)
    {
        if (conn.source.nodeID == nodeID || conn.destination.nodeID == nodeID)
        {
            if (conn.source.channelIndex != juce::AudioProcessorGraph::midiChannelIndex)
            {
                internalGraph->removeConnection(conn, juce::AudioProcessorGraph::UpdateKind::none);
            }
        }
    }

    const juce::uint32 logicalId = getLogicalIdForNode(nodeID);

    commitChanges();
}

void ModularSynthProcessor::setAudioInputChannelMapping(const NodeID& audioInputNodeId, const std::vector<int>& channelMap)
{
    if (audioInputNode == nullptr)
    {
        juce::Logger::writeToLog("[ModSynth][ERROR] setAudioInputChannelMapping called but main audioInputNode is null.");
        return;
    }

    juce::String mapStr;
    for (int i = 0; i < (int)channelMap.size(); ++i)
    {
        if (i > 0) mapStr += ", ";
        mapStr += juce::String(channelMap[i]);
    }
    juce::Logger::writeToLog("[ModSynth] Remapping Audio Input Module " + juce::String(audioInputNodeId.uid) +
                             " to channels: [" + mapStr + "]");

    auto connections = internalGraph->getConnections();
    for (const auto& conn : connections)
    {
        if (conn.source.nodeID == audioInputNode->nodeID && conn.destination.nodeID == audioInputNodeId)
        {
            internalGraph->removeConnection(conn, juce::AudioProcessorGraph::UpdateKind::none);
        }
    }

    for (int moduleChannel = 0; moduleChannel < (int)channelMap.size(); ++moduleChannel)
    {
        int hardwareChannel = channelMap[moduleChannel];
        internalGraph->addConnection({ { audioInputNode->nodeID, hardwareChannel }, { audioInputNodeId, moduleChannel } }, 
                                     juce::AudioProcessorGraph::UpdateKind::none);
    }

    commitChanges();
}

std::vector<std::pair<juce::uint32, juce::String>> ModularSynthProcessor::getModulesInfo() const
{
    const juce::ScopedLock lock (moduleLock);
    std::vector<std::pair<juce::uint32, juce::String>> out;
    out.reserve(logicalIdToModule.size());
    for (const auto& kv : logicalIdToModule)
        out.emplace_back(kv.first, kv.second.type);
    return out;
}

juce::AudioProcessorGraph::NodeID ModularSynthProcessor::getNodeIdForLogical (juce::uint32 logicalId) const
{
    const juce::ScopedLock lock (moduleLock);
    auto it = logicalIdToModule.find(logicalId);
    if (it == logicalIdToModule.end()) return {};
    return it->second.nodeID;
}

juce::uint32 ModularSynthProcessor::getLogicalIdForNode (const NodeID& nodeId) const
{
    const juce::ScopedLock lock (moduleLock);
    for (const auto& kv : logicalIdToModule)
        if (kv.second.nodeID == nodeId)
            return kv.first;
    return 0;
}

bool ModularSynthProcessor::disconnect (const NodeID& sourceNodeID, int sourceChannel, const NodeID& destNodeID, int destChannel)
{
    juce::AudioProcessorGraph::Connection connection {
        { sourceNodeID, sourceChannel },
        { destNodeID, destChannel }
    };
    return internalGraph->removeConnection(connection, juce::AudioProcessorGraph::UpdateKind::none);
}

std::vector<ModularSynthProcessor::ConnectionInfo> ModularSynthProcessor::getConnectionsInfo() const
{
    std::vector<ConnectionInfo> out;
    for (const auto& c : internalGraph->getConnections())
    {
        ConnectionInfo info;
        info.srcLogicalId = getLogicalIdForNode(c.source.nodeID);
        info.srcChan = c.source.channelIndex;
        info.dstLogicalId = getLogicalIdForNode(c.destination.nodeID);
        info.dstChan = c.destination.channelIndex;
        info.dstIsOutput = (c.destination.nodeID == audioOutputNode->nodeID);
        if (info.srcLogicalId != 0 && (info.dstLogicalId != 0 || info.dstIsOutput))
            out.push_back(info);
    }
    return out;
}


ModuleProcessor* ModularSynthProcessor::getModuleForLogical (juce::uint32 logicalId) const
{
    const juce::ScopedLock lock (moduleLock);
    auto it = logicalIdToModule.find(logicalId);
    if (it == logicalIdToModule.end()) return nullptr;
    if (auto* node = internalGraph->getNodeForId(it->second.nodeID))
        return dynamic_cast<ModuleProcessor*>(node->getProcessor());
    return nullptr;
}

juce::String ModularSynthProcessor::getModuleTypeForLogical(juce::uint32 logicalId) const
{
    auto it = logicalIdToModule.find(logicalId);
    if (it != logicalIdToModule.end())
    {
        return it->second.type;
    }
    return {};
}

// === COMPREHENSIVE DIAGNOSTICS SYSTEM ===

juce::String ModularSynthProcessor::getSystemDiagnostics() const
{
    juce::String result = "=== MODULAR SYNTH SYSTEM DIAGNOSTICS ===\n\n";
    
    result += "Total Modules: " + juce::String((int)logicalIdToModule.size()) + "\n";
    result += "Next Logical ID: " + juce::String((int)nextLogicalId) + "\n\n";
    
    result += "=== MODULES ===\n";
    for (const auto& pair : logicalIdToModule)
    {
        result += "Logical ID " + juce::String((int)pair.first) + ": " + pair.second.type + 
                 " (Node ID: " + juce::String((int)pair.second.nodeID.uid) + ")\n";
    }
    result += "\n";
    
    result += getConnectionDiagnostics() + "\n";
    
    result += "=== GRAPH STATE ===\n";
    result += "Total Nodes: " + juce::String(internalGraph->getNumNodes()) + "\n";
    result += "Total Connections: (not available)\n";
    
    return result;
}

juce::String ModularSynthProcessor::getModuleDiagnostics(juce::uint32 logicalId) const
{
    auto* module = getModuleForLogical(logicalId);
    if (module)
    {
        return module->getAllDiagnostics();
    }
    else
    {
        return "Module with Logical ID " + juce::String((int)logicalId) + " not found!";
    }
}

juce::String ModularSynthProcessor::getModuleParameterRoutingDiagnostics(juce::uint32 logicalId) const
{
    auto* module = getModuleForLogical(logicalId);
    if (!module)
    {
        return "Module with Logical ID " + juce::String((int)logicalId) + " not found!";
    }
    
    juce::String result = "=== PARAMETER ROUTING DIAGNOSTICS ===\n";
    result += "Module: " + module->getName() + "\n\n";
    
    auto params = module->getParameters();
    
    for (int i = 0; i < params.size(); ++i)
    {
        auto* param = params[i];
        if (auto* paramWithId = dynamic_cast<juce::AudioProcessorParameterWithID*>(param))
        {
            int busIndex, channelIndex;
            if (module->getParamRouting(paramWithId->paramID, busIndex, channelIndex))
            {
                int absoluteChannel = module->getChannelIndexInProcessBlockBuffer(true, busIndex, channelIndex);
                result += "  \"" + paramWithId->paramID + "\" -> Bus " + juce::String(busIndex) + 
                         ", Channel " + juce::String(channelIndex) + " (Absolute: " + juce::String(absoluteChannel) + ")\n";
            }
            else
            {
                result += "  \"" + paramWithId->paramID + "\" -> NO ROUTING\n";
            }
        }
    }
    
    return result;
}

juce::String ModularSynthProcessor::getConnectionDiagnostics() const
{
    juce::String result = "=== CONNECTIONS ===\n";
    
    auto connections = getConnectionsInfo();
    for (const auto& conn : connections)
    {
        result += "Logical " + juce::String((int)conn.srcLogicalId) + ":" + juce::String(conn.srcChan) + 
                 " -> ";
        
        if (conn.dstIsOutput)
        {
            result += "OUTPUT:" + juce::String(conn.dstChan);
        }
        else
        {
            result += "Logical " + juce::String((int)conn.dstLogicalId) + ":" + juce::String(conn.dstChan);
        }
        result += "\n";
    }
    
    if (connections.empty())
    {
        result += "No connections found.\n";
    }
    
    return result;
}

bool ModularSynthProcessor::isAnyModuleRecording() const
{
    for (const auto& kv : modules)
    {
        if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(kv.second->getProcessor()))
        {
            if (recorder->getIsRecording())
                return true;
        }
    }
    return false;
}

void ModularSynthProcessor::pauseAllRecorders()
{
    for (const auto& kv : modules)
    {
        if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(kv.second->getProcessor()))
        {
            recorder->pauseRecording();
        }
    }
}

void ModularSynthProcessor::resumeAllRecorders()
{
    for (const auto& kv : modules)
    {
        if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(kv.second->getProcessor()))
        {
            recorder->resumeRecording();
        }
    }
}

void ModularSynthProcessor::startAllRecorders()
{
    for (const auto& kv : modules)
    {
        if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(kv.second->getProcessor()))
        {
            recorder->programmaticStartRecording();
        }
    }
}

void ModularSynthProcessor::stopAllRecorders()
{
    for (const auto& kv : modules)
    {
        if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(kv.second->getProcessor()))
        {
            recorder->programmaticStopRecording();
        }
    }
}

// === VOICE MANAGEMENT IMPLEMENTATION ===

int ModularSynthProcessor::findFreeVoice()
{
    for (int i = 0; i < static_cast<int>(m_voices.size()); ++i)
    {
        if (!m_voices[i].isActive)
            return i;
    }
    return -1;
}

int ModularSynthProcessor::findOldestVoice()
{
    if (m_voices.empty())
        return -1;
    
    int oldestIndex = 0;
    juce::uint32 oldestAge = m_voices[0].age;
    
    for (int i = 1; i < static_cast<int>(m_voices.size()); ++i)
    {
        if (m_voices[i].age < oldestAge)
        {
            oldestAge = m_voices[i].age;
            oldestIndex = i;
        }
    }
    
    return oldestIndex;
}

void ModularSynthProcessor::assignNoteToVoice(int voiceIndex, const juce::MidiMessage& noteOn)
{
    if (voiceIndex < 0 || voiceIndex >= static_cast<int>(m_voices.size()))
        return;
    
    Voice& voice = m_voices[voiceIndex];
    voice.isActive = true;
    voice.noteNumber = noteOn.getNoteNumber();
    voice.velocity = noteOn.getFloatVelocity();
    voice.age = m_globalVoiceAge++;
    
    juce::Logger::writeToLog("[VoiceManager] Assigned note " + juce::String(voice.noteNumber) + 
                            " to voice " + juce::String(voiceIndex));
}

void ModularSynthProcessor::releaseVoice(const juce::MidiMessage& noteOff)
{
    int noteNumber = noteOff.getNoteNumber();
    
    for (auto& voice : m_voices)
    {
        if (voice.isActive && voice.noteNumber == noteNumber)
        {
            voice.isActive = false;
            voice.noteNumber = -1;
            juce::Logger::writeToLog("[VoiceManager] Released note " + juce::String(noteNumber));
            return;
        }
    }
}

// === PROBE TOOL IMPLEMENTATION ===

void ModularSynthProcessor::setProbeConnection(const NodeID& sourceNodeID, int sourceChannel)
{
    if (!probeScopeNode || probeScopeNodeId.uid == 0)
    {
        juce::Logger::writeToLog("[PROBE] ERROR: Probe scope not initialized!");
        return;
    }
    
    juce::Logger::writeToLog("[PROBE] setProbeConnection called. Source NodeID: " + juce::String(sourceNodeID.uid) + ", Channel: " + juce::String(sourceChannel));
    
    auto connections = internalGraph->getConnections();
    for (const auto& conn : connections)
    {
        if (conn.destination.nodeID == probeScopeNodeId)
        {
            internalGraph->removeConnection(conn, juce::AudioProcessorGraph::UpdateKind::none);
            juce::Logger::writeToLog("[PROBE] Cleared old probe connection.");
        }
    }
    
    bool success = connect(sourceNodeID, sourceChannel, probeScopeNodeId, 0);
    juce::Logger::writeToLog("[PROBE] New connection attempt " + juce::String(success ? "succeeded." : "FAILED."));
    if (success)
    {
        juce::Logger::writeToLog("[Probe] Successfully connected to probe scope");
    }
    else
    {
        juce::Logger::writeToLog("[Probe] ERROR: Failed to connect to probe scope");
    }
    
    commitChanges();
}

void ModularSynthProcessor::clearProbeConnection()
{
    if (!probeScopeNode || probeScopeNodeId.uid == 0)
        return;
    
    juce::Logger::writeToLog("[PROBE] clearProbeConnection called.");
    bool cleared = false;
    
    auto connections = internalGraph->getConnections();
    for (const auto& conn : connections)
    {
        if (conn.destination.nodeID == probeScopeNodeId)
        {
            internalGraph->removeConnection(conn, juce::AudioProcessorGraph::UpdateKind::none);
            cleared = true;
        }
    }
    
    if (cleared) {
        juce::Logger::writeToLog("[PROBE] Cleared active probe connection.");
        commitChanges();
    } else {
        juce::Logger::writeToLog("[PROBE] No active probe connection to clear.");
    }
}

ModuleProcessor* ModularSynthProcessor::getProbeScopeProcessor() const
{
    if (!probeScopeNode)
        return nullptr;
    
    return dynamic_cast<ModuleProcessor*>(probeScopeNode->getProcessor());
}

================================================================================
FILE: juce\\Source\\preset_creator\\PinDatabase.cpp
================================================================================


#include "PinDatabase.h"
#include "ImGuiNodeEditorComponent.h" // For NodeWidth enum

// Module Descriptions - populated on first use
void populateModuleDescriptions()
{
    auto& descriptions = getModuleDescriptions();
    if (!descriptions.empty()) return; // Only run once
    
    // Sources
    descriptions["audio_input"] = "Brings hardware audio into the patch.";
    descriptions["VCO"] = "A standard Voltage-Controlled Oscillator.";
    descriptions["polyvco"] = "A multi-voice oscillator bank for polyphony.";
    descriptions["Noise"] = "Generates white, pink, or brown noise.";
    descriptions["Sequencer"] = "A classic 16-step CV and Gate sequencer.";
    descriptions["multi sequencer"] = "Advanced sequencer with parallel per-step outputs.";
    descriptions["midi player"] = "Plays MIDI files and outputs CV/Gate for each track.";
    descriptions["midi cv"] = "Converts MIDI Note/CC messages to CV signals. (Monophonic)";
    descriptions["midi control center"] = "A powerful MIDI learn interface to map any MIDI CC to CV/Gate outputs.";
    descriptions["midi faders"] = "1-16 MIDI-learnable faders with customizable output ranges.";
    descriptions["midi knobs"] = "1-16 MIDI-learnable knobs with customizable output ranges.";
    descriptions["midi buttons"] = "1-32 MIDI-learnable buttons with Gate/Toggle/Trigger modes.";
    descriptions["midi jog wheel"] = "A single MIDI-learnable jog wheel control for expressive modulation.";
    descriptions["Value"] = "Outputs a constant, adjustable numerical value.";
    descriptions["sample_loader"] = "Loads and plays audio samples with pitch/time control.";
    descriptions["best_practice"] = "A template and example node demonstrating best practices.";
    // TTS Family
    descriptions["TTS Performer"] = "Advanced Text-to-Speech engine with word-level sequencing.";
    descriptions["Vocal Tract Filter"] = "A formant filter that simulates human vowel sounds.";
    // Effects
    descriptions["VCF"] = "A Voltage-Controlled Filter (LP, HP, BP).";
    descriptions["Delay"] = "A stereo delay effect with modulation.";
    descriptions["Reverb"] = "A stereo reverb effect.";
    descriptions["chorus"] = "A stereo chorus effect.";
    descriptions["phaser"] = "A stereo phaser effect.";
    descriptions["compressor"] = "Reduces the dynamic range of a signal.";
    descriptions["limiter"] = "Prevents a signal from exceeding a set level.";
    descriptions["gate"] = "A stereo noise gate to silence signals below a threshold.";
    descriptions["drive"] = "A waveshaping distortion effect.";
    descriptions["graphic_eq"] = "An 8-band graphic equalizer.";
    descriptions["frequency_graph"] = "A high-resolution, real-time spectrum analyzer.";
    descriptions["Waveshaper"] = "A distortion effect with multiple shaping algorithms.";
    descriptions["8bandshaper"] = "A multi-band waveshaper for frequency-specific distortion.";
    descriptions["Granulator"] = "A granular synthesizer/effect that plays small grains of a sample.";
    descriptions["harmonic shaper"] = "Shapes the harmonic content of a signal.";
    descriptions["timepitch"] = "Real-time pitch and time manipulation using RubberBand.";
    descriptions["De-Crackle"] = "A utility to reduce clicks from discontinuous signals.";
    descriptions["recorder"] = "Records incoming audio to a WAV, AIFF, or FLAC file.";
    descriptions["tempo_clock"] = "Global clock generator with BPM control, transport, and clock outputs.";
    descriptions["bpm_monitor"] = "Monitors and reports BPM from rhythm-producing modules (sequencers, animations). Always present and undeletable.";
    // Modulators
    descriptions["LFO"] = "A Low-Frequency Oscillator for modulation.";
    descriptions["ADSR"] = "An Attack-Decay-Sustain-Release envelope generator.";
    descriptions["Random"] = "A random value generator with internal sample & hold.";
    descriptions["S&H"] = "A classic Sample and Hold module.";
    descriptions["function_generator"] = "A complex, drawable envelope/LFO generator.";
    descriptions["shaping_oscillator"] = "An oscillator with a built-in waveshaper.";
    // Utilities & Logic
    descriptions["VCA"] = "A Voltage-Controlled Amplifier to control signal level.";
    descriptions["Mixer"] = "A stereo audio mixer with crossfading and panning.";
    descriptions["cv mixer"] = "A mixer specifically for control voltage signals.";
    descriptions["trackmixer"] = "A multi-channel mixer for polyphonic sources.";
    descriptions["Attenuverter"] = "Attenuates (reduces) and/or inverts signals.";
    descriptions["Lag Processor"] = "Smooths out abrupt changes in a signal (slew limiter).";
    descriptions["Math"] = "Performs mathematical operations on signals.";
    descriptions["MapRange"] = "Remaps a signal from one numerical range to another.";
    descriptions["Quantizer"] = "Snaps a continuous signal to a musical scale.";
    descriptions["Rate"] = "Converts a control signal into a normalized rate value.";
    descriptions["Comparator"] = "Outputs a high signal if an input is above a threshold.";
    descriptions["Logic"] = "Performs boolean logic (AND, OR, XOR, NOT) on gate signals.";
    descriptions["ClockDivider"] = "Divides and multiplies clock signals.";
    descriptions["SequentialSwitch"] = "A signal router with multiple thresholds.";
    // Analysis
    descriptions["Scope"] = "Visualizes an audio or CV signal.";
    descriptions["debug"] = "A tool for logging signal value changes.";
    descriptions["input_debug"] = "A passthrough version of the Debug node for inspecting signals on a cable.";
    
    // Physics
    descriptions["physics"] = "A 2D physics simulation that outputs collision and contact data.";
    descriptions["animation"] = "Loads and plays 3D animations, outputs joint positions and velocities.";
    descriptions["stroke_sequencer"] = "Gesture-based sequencer that records and plays back drawn patterns.";
    
    // OpenCV (Computer Vision)
    descriptions["webcam_loader"] = "Captures video from a webcam and publishes it as a source for vision processing modules.";
    descriptions["video_file_loader"] = "Loads and plays a video file, publishes it as a source for vision processing modules.";
    descriptions["movement_detector"] = "Analyzes video source for motion via optical flow or background subtraction, outputs motion data as CV.";
    descriptions["human_detector"] = "Detects faces or bodies in video source via Haar Cascades or HOG, outputs position and size as CV.";
    descriptions["pose_estimator"] = "Uses OpenPose to detect 15 body keypoints (head, shoulders, elbows, wrists, hips, knees, ankles) and outputs their positions as CV signals.";
    descriptions["hand_tracker"] = "Detects 21 hand keypoints and outputs their X/Y positions as CV (42 channels).";
    descriptions["face_tracker"] = "Detects 70 facial landmarks and outputs X/Y positions as CV (140 channels).";
    descriptions["object_detector"] = "Uses YOLOv3 to detect objects (person, car, etc.) and outputs bounding box position/size as CV.";
    descriptions["color_tracker"] = "Tracks multiple colors in video and outputs their positions and sizes as CV.";
    descriptions["contour_detector"] = "Detects shapes via background subtraction and outputs area, complexity, and aspect ratio as CV.";
    descriptions["semantic_segmentation"] = "Uses deep learning to segment video into semantic regions and outputs detected areas as CV.";
    
    // Add aliases for underscore naming conventions
    descriptions["clock_divider"] = descriptions["ClockDivider"];
    descriptions["sequential_switch"] = descriptions["SequentialSwitch"];
    descriptions["s_and_h"] = descriptions["S&H"];
    descriptions["snapshot_sequencer"] = "A sequencer that stores and recalls complete patch states.";
}

void populatePinDatabase()
{
    // Populate both databases
    populateModuleDescriptions();
    
    auto& db = getModulePinDatabase();
    if (!db.empty()) return; // Only run once

    // --- Sources ---
    db["audio_input"] = ModulePinInfo(
        NodeWidth::Small,
        {},
        { AudioPin("Out 1", 0, PinDataType::Audio), AudioPin("Out 2", 1, PinDataType::Audio),
          AudioPin("Gate", 16, PinDataType::Gate), AudioPin("Trigger", 17, PinDataType::Gate), AudioPin("EOP", 18, PinDataType::Gate) },
        {}
    );
    db["vco"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("Frequency", 0, PinDataType::CV), AudioPin("Waveform", 1, PinDataType::CV), AudioPin("Gate", 2, PinDataType::Gate) },
        { AudioPin("Out", 0, PinDataType::Audio) },
        {}
    );
    db["noise"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("Level Mod", 0, PinDataType::CV), AudioPin("Colour Mod", 1, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) }, // Stereo output to match actual implementation
        {}
    );
    db["value"] = ModulePinInfo(
        NodeWidth::Small,
        {},
        { AudioPin("Raw", 0, PinDataType::Raw), AudioPin("Normalized", 1, PinDataType::CV), AudioPin("Inverted", 2, PinDataType::Raw),
          AudioPin("Integer", 3, PinDataType::Raw), AudioPin("CV Out", 4, PinDataType::CV) },
        {}
    );
    db["sample_loader"] = ModulePinInfo(
        NodeWidth::Big,
        { AudioPin("Pitch Mod", 0, PinDataType::CV), AudioPin("Speed Mod", 1, PinDataType::CV), AudioPin("Gate Mod", 2, PinDataType::CV),
          AudioPin("Trigger Mod", 3, PinDataType::Gate), AudioPin("Range Start Mod", 4, PinDataType::CV), AudioPin("Range End Mod", 5, PinDataType::CV),
          AudioPin("Randomize Trig", 6, PinDataType::Gate) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );

    // --- Effects ---
    db["vcf"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Cutoff Mod", 2, PinDataType::CV),
          AudioPin("Resonance Mod", 3, PinDataType::CV), AudioPin("Type Mod", 4, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["delay"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Time Mod", 2, PinDataType::CV),
          AudioPin("Feedback Mod", 3, PinDataType::CV), AudioPin("Mix Mod", 4, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["reverb"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Size Mod", 2, PinDataType::CV),
          AudioPin("Damp Mod", 3, PinDataType::CV), AudioPin("Mix Mod", 4, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["compressor"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Thresh Mod", 2, PinDataType::CV),
          AudioPin("Ratio Mod", 3, PinDataType::CV), AudioPin("Attack Mod", 4, PinDataType::CV), AudioPin("Release Mod", 5, PinDataType::CV),
          AudioPin("Makeup Mod", 6, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );

    // --- Modulators ---
    db["lfo"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("Rate Mod", 0, PinDataType::CV), AudioPin("Depth Mod", 1, PinDataType::CV), AudioPin("Wave Mod", 2, PinDataType::CV) },
        { AudioPin("Out", 0, PinDataType::CV) },
        {}
    );
    db["adsr"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("Gate In", 0, PinDataType::Gate), AudioPin("Trigger In", 1, PinDataType::Gate), AudioPin("Attack Mod", 2, PinDataType::CV),
          AudioPin("Decay Mod", 3, PinDataType::CV), AudioPin("Sustain Mod", 4, PinDataType::CV), AudioPin("Release Mod", 5, PinDataType::CV) },
        { AudioPin("Env Out", 0, PinDataType::CV), AudioPin("Inv Out", 1, PinDataType::CV), AudioPin("EOR Gate", 2, PinDataType::Gate),
          AudioPin("EOC Gate", 3, PinDataType::Gate) },
        {}
    );
    db["random"] = ModulePinInfo(
        NodeWidth::Small,
        {}, // No inputs - self-contained random generator
        { AudioPin("Norm Out", 0, PinDataType::CV), AudioPin("Raw Out", 1, PinDataType::Raw), AudioPin("CV Out", 2, PinDataType::CV),
          AudioPin("Bool Out", 3, PinDataType::Gate), AudioPin("Trig Out", 4, PinDataType::Gate) },
        {}
    );

    // --- Utilities ---
    db["vca"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Gain Mod", 2, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["mixer"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In A L", 0, PinDataType::Audio), AudioPin("In A R", 1, PinDataType::Audio), AudioPin("In B L", 2, PinDataType::Audio),
          AudioPin("In B R", 3, PinDataType::Audio), AudioPin("Gain Mod", 4, PinDataType::CV), AudioPin("Pan Mod", 5, PinDataType::CV),
          AudioPin("X-Fade Mod", 6, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["scope"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In", 0, PinDataType::Audio) },
        { AudioPin("Out", 0, PinDataType::Audio) },
        {}
    );
    db["graphic_eq"] = ModulePinInfo(
        NodeWidth::Big,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio),
          AudioPin("Band 1 Mod", 2, PinDataType::CV), AudioPin("Band 2 Mod", 3, PinDataType::CV),
          AudioPin("Band 3 Mod", 4, PinDataType::CV), AudioPin("Band 4 Mod", 5, PinDataType::CV),
          AudioPin("Band 5 Mod", 6, PinDataType::CV), AudioPin("Band 6 Mod", 7, PinDataType::CV),
          AudioPin("Band 7 Mod", 8, PinDataType::CV), AudioPin("Band 8 Mod", 9, PinDataType::CV),
          AudioPin("Gate Thresh Mod", 10, PinDataType::CV), AudioPin("Trig Thresh Mod", 11, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio),
          AudioPin("Gate Out", 2, PinDataType::Gate), AudioPin("Trig Out", 3, PinDataType::Gate) },
        {}
    );
    db["frequency_graph"] = ModulePinInfo(
        NodeWidth::ExtraWide,
        { AudioPin("In", 0, PinDataType::Audio) }, // Mono Audio Input
        { // Outputs: Stereo audio pass-through + 8 Gate/Trigger outputs
            AudioPin("Out L", 0, PinDataType::Audio),
            AudioPin("Out R", 1, PinDataType::Audio),
            AudioPin("Sub Gate", 2, PinDataType::Gate),
            AudioPin("Sub Trig", 3, PinDataType::Gate),
            AudioPin("Bass Gate", 4, PinDataType::Gate),
            AudioPin("Bass Trig", 5, PinDataType::Gate),
            AudioPin("Mid Gate", 6, PinDataType::Gate),
            AudioPin("Mid Trig", 7, PinDataType::Gate),
            AudioPin("High Gate", 8, PinDataType::Gate),
            AudioPin("High Trig", 9, PinDataType::Gate)
        },
        {} // No modulation inputs
    );
    db["chorus"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio),
          AudioPin("Rate Mod", 2, PinDataType::CV), AudioPin("Depth Mod", 3, PinDataType::CV),
          AudioPin("Mix Mod", 4, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["phaser"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio),
          AudioPin("Rate Mod", 2, PinDataType::CV), AudioPin("Depth Mod", 3, PinDataType::CV),
          AudioPin("Centre Mod", 4, PinDataType::CV), AudioPin("Feedback Mod", 5, PinDataType::CV),
          AudioPin("Mix Mod", 6, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["compressor"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio),
          AudioPin("Thresh Mod", 2, PinDataType::CV), AudioPin("Ratio Mod", 3, PinDataType::CV),
          AudioPin("Attack Mod", 4, PinDataType::CV), AudioPin("Release Mod", 5, PinDataType::CV),
          AudioPin("Makeup Mod", 6, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["Recorder"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio) },
        {}, // No outputs
        {}
    );
    db["limiter"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio),
          AudioPin("Thresh Mod", 2, PinDataType::CV), AudioPin("Release Mod", 3, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["gate"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["drive"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["timepitch"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Speed Mod", 2, PinDataType::CV), AudioPin("Pitch Mod", 3, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["waveshaper"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Drive Mod", 2, PinDataType::CV), AudioPin("Type Mod", 3, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["8bandshaper"] = ModulePinInfo(
        NodeWidth::Big,
        {
            AudioPin("In L", 0, PinDataType::Audio),
            AudioPin("In R", 1, PinDataType::Audio),
            AudioPin("Drive 1 Mod", 2, PinDataType::CV),
            AudioPin("Drive 2 Mod", 3, PinDataType::CV),
            AudioPin("Drive 3 Mod", 4, PinDataType::CV),
            AudioPin("Drive 4 Mod", 5, PinDataType::CV),
            AudioPin("Drive 5 Mod", 6, PinDataType::CV),
            AudioPin("Drive 6 Mod", 7, PinDataType::CV),
            AudioPin("Drive 7 Mod", 8, PinDataType::CV),
            AudioPin("Drive 8 Mod", 9, PinDataType::CV),
            AudioPin("Gain Mod", 10, PinDataType::CV)
        },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["granulator"] = ModulePinInfo(
        NodeWidth::Big,
        {
            AudioPin("In L", 0, PinDataType::Audio),
            AudioPin("In R", 1, PinDataType::Audio),
            AudioPin("Trigger In", 2, PinDataType::Gate),
            AudioPin("Density Mod", 3, PinDataType::CV),
            AudioPin("Size Mod", 4, PinDataType::CV),
            AudioPin("Position Mod", 5, PinDataType::CV),
            AudioPin("Pitch Mod", 6, PinDataType::CV),
            AudioPin("Gate Mod", 7, PinDataType::CV)
        },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["mixer"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In A L", 0, PinDataType::Audio), AudioPin("In A R", 1, PinDataType::Audio), AudioPin("In B L", 2, PinDataType::Audio), AudioPin("In B R", 3, PinDataType::Audio), AudioPin("Gain Mod", 4, PinDataType::CV), AudioPin("Pan Mod", 5, PinDataType::CV), AudioPin("X-Fade Mod", 6, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    db["sequencer"] = ModulePinInfo(
        NodeWidth::ExtraWide,
        { AudioPin("Mod In L", 0, PinDataType::Audio), AudioPin("Mod In R", 1, PinDataType::Audio), AudioPin("Rate Mod", 2, PinDataType::CV), AudioPin("Gate Mod", 3, PinDataType::CV), AudioPin("Steps Mod", 4, PinDataType::CV), AudioPin("Gate Thr Mod", 5, PinDataType::CV),
          // Per-step value mods absolute 6..21 (Step1..Step16)
          AudioPin("Step 1 Mod", 6, PinDataType::CV), AudioPin("Step 2 Mod", 7, PinDataType::CV), AudioPin("Step 3 Mod", 8, PinDataType::CV), AudioPin("Step 4 Mod", 9, PinDataType::CV),
          AudioPin("Step 5 Mod", 10, PinDataType::CV), AudioPin("Step 6 Mod", 11, PinDataType::CV), AudioPin("Step 7 Mod", 12, PinDataType::CV), AudioPin("Step 8 Mod", 13, PinDataType::CV),
          AudioPin("Step 9 Mod", 14, PinDataType::CV), AudioPin("Step 10 Mod", 15, PinDataType::CV), AudioPin("Step 11 Mod", 16, PinDataType::CV), AudioPin("Step 12 Mod", 17, PinDataType::CV),
          AudioPin("Step 13 Mod", 18, PinDataType::CV), AudioPin("Step 14 Mod", 19, PinDataType::CV), AudioPin("Step 15 Mod", 20, PinDataType::CV), AudioPin("Step 16 Mod", 21, PinDataType::CV),
          // Per-step trig mods absolute 22..37 (Step1..Step16)  these are Gates
          AudioPin("Step 1 Trig Mod", 22, PinDataType::Gate), AudioPin("Step 2 Trig Mod", 23, PinDataType::Gate), AudioPin("Step 3 Trig Mod", 24, PinDataType::Gate), AudioPin("Step 4 Trig Mod", 25, PinDataType::Gate),
          AudioPin("Step 5 Trig Mod", 26, PinDataType::Gate), AudioPin("Step 6 Trig Mod", 27, PinDataType::Gate), AudioPin("Step 7 Trig Mod", 28, PinDataType::Gate), AudioPin("Step 8 Trig Mod", 29, PinDataType::Gate),
          AudioPin("Step 9 Trig Mod", 30, PinDataType::Gate), AudioPin("Step 10 Trig Mod", 31, PinDataType::Gate), AudioPin("Step 11 Trig Mod", 32, PinDataType::Gate), AudioPin("Step 12 Trig Mod", 33, PinDataType::Gate),
          AudioPin("Step 13 Trig Mod", 34, PinDataType::Gate), AudioPin("Step 14 Trig Mod", 35, PinDataType::Gate), AudioPin("Step 15 Trig Mod", 36, PinDataType::Gate), AudioPin("Step 16 Trig Mod", 37, PinDataType::Gate),
          // Per-step gate level mods absolute 38..53
          AudioPin("Step 1 Gate Mod", 38, PinDataType::CV), AudioPin("Step 2 Gate Mod", 39, PinDataType::CV), AudioPin("Step 3 Gate Mod", 40, PinDataType::CV), AudioPin("Step 4 Gate Mod", 41, PinDataType::CV),
          AudioPin("Step 5 Gate Mod", 42, PinDataType::CV), AudioPin("Step 6 Gate Mod", 43, PinDataType::CV), AudioPin("Step 7 Gate Mod", 44, PinDataType::CV), AudioPin("Step 8 Gate Mod", 45, PinDataType::CV),
          AudioPin("Step 9 Gate Mod", 46, PinDataType::CV), AudioPin("Step 10 Gate Mod", 47, PinDataType::CV), AudioPin("Step 11 Gate Mod", 48, PinDataType::CV), AudioPin("Step 12 Gate Mod", 49, PinDataType::CV),
          AudioPin("Step 13 Gate Mod", 50, PinDataType::CV), AudioPin("Step 14 Gate Mod", 51, PinDataType::CV), AudioPin("Step 15 Gate Mod", 52, PinDataType::CV), AudioPin("Step 16 Gate Mod", 53, PinDataType::CV) },
        { AudioPin("Pitch", 0, PinDataType::CV), AudioPin("Gate", 1, PinDataType::Gate), AudioPin("Gate Nuanced", 2, PinDataType::CV), AudioPin("Velocity", 3, PinDataType::CV), AudioPin("Mod", 4, PinDataType::CV), AudioPin("Trigger", 5, PinDataType::Gate) },
        {}
    );

    db["value"] = ModulePinInfo(
        NodeWidth::Small,
        {},
        { AudioPin("Raw", 0, PinDataType::Raw), AudioPin("Normalized", 1, PinDataType::CV), AudioPin("Inverted", 2, PinDataType::Raw), AudioPin("Integer", 3, PinDataType::Raw), AudioPin("CV Out", 4, PinDataType::CV) },
        {}
    );

db["random"] = ModulePinInfo(
    NodeWidth::Small,
    {}, // No inputs - self-contained random generator
    { 
        AudioPin("Norm Out", 0, PinDataType::CV), 
        AudioPin("Raw Out", 1, PinDataType::Raw), 
        AudioPin("CV Out", 2, PinDataType::CV),
        AudioPin("Bool Out", 3, PinDataType::Gate), 
        AudioPin("Trig Out", 4, PinDataType::Gate) 
    },
    {} // No modulation inputs
);

    db["tts performer"] = ModulePinInfo(
        NodeWidth::Big,
        { // Inputs (absolute channels based on bus structure)
            AudioPin("Rate Mod", 0, PinDataType::CV),
            AudioPin("Gate Mod", 1, PinDataType::CV),
            AudioPin("Trigger", 2, PinDataType::Gate),
            AudioPin("Reset", 3, PinDataType::Gate),
            AudioPin("Randomize Trig", 4, PinDataType::Gate),
            AudioPin("Trim Start Mod", 5, PinDataType::CV),
            AudioPin("Trim End Mod", 6, PinDataType::CV),
            AudioPin("Speed Mod", 7, PinDataType::CV),
            AudioPin("Pitch Mod", 8, PinDataType::CV),
            // Word Triggers (Channels 9-24)
            AudioPin("Word 1 Trig", 9, PinDataType::Gate), AudioPin("Word 2 Trig", 10, PinDataType::Gate),
            AudioPin("Word 3 Trig", 11, PinDataType::Gate), AudioPin("Word 4 Trig", 12, PinDataType::Gate),
            AudioPin("Word 5 Trig", 13, PinDataType::Gate), AudioPin("Word 6 Trig", 14, PinDataType::Gate),
            AudioPin("Word 7 Trig", 15, PinDataType::Gate), AudioPin("Word 8 Trig", 16, PinDataType::Gate),
            AudioPin("Word 9 Trig", 17, PinDataType::Gate), AudioPin("Word 10 Trig", 18, PinDataType::Gate),
            AudioPin("Word 11 Trig", 19, PinDataType::Gate), AudioPin("Word 12 Trig", 20, PinDataType::Gate),
            AudioPin("Word 13 Trig", 21, PinDataType::Gate), AudioPin("Word 14 Trig", 22, PinDataType::Gate),
            AudioPin("Word 15 Trig", 23, PinDataType::Gate), AudioPin("Word 16 Trig", 24, PinDataType::Gate)
        },
        { // Outputs
            AudioPin("Audio", 0, PinDataType::Audio),
            AudioPin("Word Gate", 1, PinDataType::Gate),
            AudioPin("EOP Gate", 2, PinDataType::Gate),
            // Per-Word Gates (Channels 3-18)
            AudioPin("Word 1 Gate", 3, PinDataType::Gate), AudioPin("Word 2 Gate", 4, PinDataType::Gate),
            AudioPin("Word 3 Gate", 5, PinDataType::Gate), AudioPin("Word 4 Gate", 6, PinDataType::Gate),
            AudioPin("Word 5 Gate", 7, PinDataType::Gate), AudioPin("Word 6 Gate", 8, PinDataType::Gate),
            AudioPin("Word 7 Gate", 9, PinDataType::Gate), AudioPin("Word 8 Gate", 10, PinDataType::Gate),
            AudioPin("Word 9 Gate", 11, PinDataType::Gate), AudioPin("Word 10 Gate", 12, PinDataType::Gate),
            AudioPin("Word 11 Gate", 13, PinDataType::Gate), AudioPin("Word 12 Gate", 14, PinDataType::Gate),
            AudioPin("Word 13 Gate", 15, PinDataType::Gate), AudioPin("Word 14 Gate", 16, PinDataType::Gate),
            AudioPin("Word 15 Gate", 17, PinDataType::Gate), AudioPin("Word 16 Gate", 18, PinDataType::Gate),
            // Per-Word Triggers (Channels 19-34)
            AudioPin("Word 1 Trig", 19, PinDataType::Gate), AudioPin("Word 2 Trig", 20, PinDataType::Gate),
            AudioPin("Word 3 Trig", 21, PinDataType::Gate), AudioPin("Word 4 Trig", 22, PinDataType::Gate),
            AudioPin("Word 5 Trig", 23, PinDataType::Gate), AudioPin("Word 6 Trig", 24, PinDataType::Gate),
            AudioPin("Word 7 Trig", 25, PinDataType::Gate), AudioPin("Word 8 Trig", 26, PinDataType::Gate),
            AudioPin("Word 9 Trig", 27, PinDataType::Gate), AudioPin("Word 10 Trig", 28, PinDataType::Gate),
            AudioPin("Word 11 Trig", 29, PinDataType::Gate), AudioPin("Word 12 Trig", 30, PinDataType::Gate),
            AudioPin("Word 13 Trig", 31, PinDataType::Gate), AudioPin("Word 14 Trig", 32, PinDataType::Gate),
            AudioPin("Word 15 Trig", 33, PinDataType::Gate), AudioPin("Word 16 Trig", 34, PinDataType::Gate)
        },
        { // Modulation Pins (for UI parameter disabling)
            ModPin("Rate", "rate_mod", PinDataType::CV),
            ModPin("Gate", "gate_mod", PinDataType::CV),
            ModPin("Trim Start", "trimStart_mod", PinDataType::CV),
            ModPin("Trim End", "trimEnd_mod", PinDataType::CV),
            ModPin("Speed", "speed_mod", PinDataType::CV),
            ModPin("Pitch", "pitch_mod", PinDataType::CV)
        }
    );
    db["vocal tract filter"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("Audio In", 0, PinDataType::Audio) },
        { AudioPin("Audio Out", 0, PinDataType::Audio) },
        { ModPin("Vowel", "vowelShape", PinDataType::CV), ModPin("Formant", "formantShift", PinDataType::CV), ModPin("Instability", "instability", PinDataType::CV), ModPin("Gain", "formantGain", PinDataType::CV) }
    );
    db["best_practice"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Freq Mod", 2, PinDataType::CV), AudioPin("Wave Mod", 3, PinDataType::CV), AudioPin("Drive Mod", 4, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        { ModPin("Frequency", "frequency_mod", PinDataType::CV), ModPin("Waveform", "waveform_mod", PinDataType::CV), ModPin("Drive", "drive_mod", PinDataType::CV) }
    );
    db["shaping_oscillator"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Freq Mod", 2, PinDataType::CV), AudioPin("Wave Mod", 3, PinDataType::CV), AudioPin("Drive Mod", 4, PinDataType::CV) },
        { AudioPin("Out", 0, PinDataType::Audio) },
        { ModPin("Frequency", "frequency_mod", PinDataType::CV), ModPin("Waveform", "waveform_mod", PinDataType::CV), ModPin("Drive", "drive_mod", PinDataType::CV) }
    );
    db["harmonic shaper"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Freq Mod", 2, PinDataType::CV), AudioPin("Drive Mod", 3, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        { ModPin("Master Frequency", "masterFrequency_mod", PinDataType::CV), ModPin("Master Drive", "masterDrive_mod", PinDataType::CV) }
    );
    db["function_generator"] = ModulePinInfo(
        NodeWidth::Big,
        { 
            AudioPin("Gate In", 0, PinDataType::Gate),
            AudioPin("Trigger In", 1, PinDataType::Gate),
            AudioPin("Sync In", 2, PinDataType::Gate),
            AudioPin("Rate Mod", 3, PinDataType::CV),
            AudioPin("Slew Mod", 4, PinDataType::CV),
            AudioPin("Gate Thresh Mod", 5, PinDataType::CV),
            AudioPin("Trig Thresh Mod", 6, PinDataType::CV),
            AudioPin("Pitch Base Mod", 7, PinDataType::CV),
            AudioPin("Value Mult Mod", 8, PinDataType::CV),
            AudioPin("Curve Select Mod", 9, PinDataType::CV)
        },
        { 
            AudioPin("Value", 0, PinDataType::CV),
            AudioPin("Inverted", 1, PinDataType::CV),
            AudioPin("Bipolar", 2, PinDataType::CV),
            AudioPin("Pitch", 3, PinDataType::CV),
            AudioPin("Gate", 4, PinDataType::Gate),
            AudioPin("Trigger", 5, PinDataType::Gate),
            AudioPin("End of Cycle", 6, PinDataType::Gate),
            // New dedicated outputs
            AudioPin("Blue Value", 7, PinDataType::CV),
            AudioPin("Blue Pitch", 8, PinDataType::CV),
            AudioPin("Red Value", 9, PinDataType::CV),
            AudioPin("Red Pitch", 10, PinDataType::CV),
            AudioPin("Green Value", 11, PinDataType::CV),
            AudioPin("Green Pitch", 12, PinDataType::CV)
        },
        { 
            ModPin("Rate", "rate_mod", PinDataType::CV),
            ModPin("Slew", "slew_mod", PinDataType::CV),
            ModPin("Gate Thresh", "gateThresh_mod", PinDataType::CV),
            ModPin("Trig Thresh", "trigThresh_mod", PinDataType::CV),
            ModPin("Pitch Base", "pitchBase_mod", PinDataType::CV),
            ModPin("Value Mult", "valueMult_mod", PinDataType::CV),
            ModPin("Curve Select", "curveSelect_mod", PinDataType::CV)
        }
    );

    db["multi sequencer"] = ModulePinInfo(
        NodeWidth::ExtraWide,
        { // Inputs: Mod In L, Mod In R, Rate Mod, Gate Mod, Steps Mod, Gate Thr Mod, plus per-step mods and triggers
            AudioPin("Mod In L", 0, PinDataType::Audio), AudioPin("Mod In R", 1, PinDataType::Audio),
            AudioPin("Rate Mod", 2, PinDataType::CV), AudioPin("Gate Mod", 3, PinDataType::CV),
            AudioPin("Steps Mod", 4, PinDataType::CV), AudioPin("Gate Thr Mod", 5, PinDataType::CV),
            // Per-step mods (channels 6-21)
            AudioPin("Step 1 Mod", 6, PinDataType::CV), AudioPin("Step 2 Mod", 7, PinDataType::CV),
            AudioPin("Step 3 Mod", 8, PinDataType::CV), AudioPin("Step 4 Mod", 9, PinDataType::CV),
            AudioPin("Step 5 Mod", 10, PinDataType::CV), AudioPin("Step 6 Mod", 11, PinDataType::CV),
            AudioPin("Step 7 Mod", 12, PinDataType::CV), AudioPin("Step 8 Mod", 13, PinDataType::CV),
            AudioPin("Step 9 Mod", 14, PinDataType::CV), AudioPin("Step 10 Mod", 15, PinDataType::CV),
            AudioPin("Step 11 Mod", 16, PinDataType::CV), AudioPin("Step 12 Mod", 17, PinDataType::CV),
            AudioPin("Step 13 Mod", 18, PinDataType::CV), AudioPin("Step 14 Mod", 19, PinDataType::CV),
            AudioPin("Step 15 Mod", 20, PinDataType::CV), AudioPin("Step 16 Mod", 21, PinDataType::CV),
            // Per-step trigger mods (channels 22-37)
            AudioPin("Step 1 Trig Mod", 22, PinDataType::Gate), AudioPin("Step 2 Trig Mod", 23, PinDataType::Gate),
            AudioPin("Step 3 Trig Mod", 24, PinDataType::Gate), AudioPin("Step 4 Trig Mod", 25, PinDataType::Gate),
            AudioPin("Step 5 Trig Mod", 26, PinDataType::Gate), AudioPin("Step 6 Trig Mod", 27, PinDataType::Gate),
            AudioPin("Step 7 Trig Mod", 28, PinDataType::Gate), AudioPin("Step 8 Trig Mod", 29, PinDataType::Gate),
            AudioPin("Step 9 Trig Mod", 30, PinDataType::Gate), AudioPin("Step 10 Trig Mod", 31, PinDataType::Gate),
            AudioPin("Step 11 Trig Mod", 32, PinDataType::Gate), AudioPin("Step 12 Trig Mod", 33, PinDataType::Gate),
            AudioPin("Step 13 Trig Mod", 34, PinDataType::Gate), AudioPin("Step 14 Trig Mod", 35, PinDataType::Gate),
            AudioPin("Step 15 Trig Mod", 36, PinDataType::Gate), AudioPin("Step 16 Trig Mod", 37, PinDataType::Gate)
        },
        { // Outputs: Live outputs (0-6) + Parallel step outputs (7+)
            // Live Outputs
            AudioPin("Pitch", 0, PinDataType::CV), AudioPin("Gate", 1, PinDataType::Gate),
            AudioPin("Gate Nuanced", 2, PinDataType::CV), AudioPin("Velocity", 3, PinDataType::CV),
            AudioPin("Mod", 4, PinDataType::CV), AudioPin("Trigger", 5, PinDataType::Gate),
            AudioPin("Num Steps", 6, PinDataType::Raw),
            // Parallel Step Outputs (Corrected Names and Channels, shifted by +1 after Num Steps)
            AudioPin("Pitch 1", 7, PinDataType::CV), AudioPin("Gate 1", 8, PinDataType::Gate), AudioPin("Trig 1", 9, PinDataType::Gate),
            AudioPin("Pitch 2", 10, PinDataType::CV), AudioPin("Gate 2", 11, PinDataType::Gate), AudioPin("Trig 2", 12, PinDataType::Gate),
            AudioPin("Pitch 3", 13, PinDataType::CV), AudioPin("Gate 3", 14, PinDataType::Gate), AudioPin("Trig 3", 15, PinDataType::Gate),
            AudioPin("Pitch 4", 16, PinDataType::CV), AudioPin("Gate 4", 17, PinDataType::Gate), AudioPin("Trig 4", 18, PinDataType::Gate),
            AudioPin("Pitch 5", 19, PinDataType::CV), AudioPin("Gate 5", 20, PinDataType::Gate), AudioPin("Trig 5", 21, PinDataType::Gate),
            AudioPin("Pitch 6", 22, PinDataType::CV), AudioPin("Gate 6", 23, PinDataType::Gate), AudioPin("Trig 6", 24, PinDataType::Gate),
            AudioPin("Pitch 7", 25, PinDataType::CV), AudioPin("Gate 7", 26, PinDataType::Gate), AudioPin("Trig 7", 27, PinDataType::Gate),
            AudioPin("Pitch 8", 28, PinDataType::CV), AudioPin("Gate 8", 29, PinDataType::Gate), AudioPin("Trig 8", 30, PinDataType::Gate),
            AudioPin("Pitch 9", 31, PinDataType::CV), AudioPin("Gate 9", 32, PinDataType::Gate), AudioPin("Trig 9", 33, PinDataType::Gate),
            AudioPin("Pitch 10", 34, PinDataType::CV), AudioPin("Gate 10", 35, PinDataType::Gate), AudioPin("Trig 10", 36, PinDataType::Gate),
            AudioPin("Pitch 11", 37, PinDataType::CV), AudioPin("Gate 11", 38, PinDataType::Gate), AudioPin("Trig 11", 39, PinDataType::Gate),
            AudioPin("Pitch 12", 40, PinDataType::CV), AudioPin("Gate 12", 41, PinDataType::Gate), AudioPin("Trig 12", 42, PinDataType::Gate),
            AudioPin("Pitch 13", 43, PinDataType::CV), AudioPin("Gate 13", 44, PinDataType::Gate), AudioPin("Trig 13", 45, PinDataType::Gate),
            AudioPin("Pitch 14", 46, PinDataType::CV), AudioPin("Gate 14", 47, PinDataType::Gate), AudioPin("Trig 14", 48, PinDataType::Gate),
            AudioPin("Pitch 15", 49, PinDataType::CV), AudioPin("Gate 15", 50, PinDataType::Gate), AudioPin("Trig 15", 51, PinDataType::Gate),
            AudioPin("Pitch 16", 52, PinDataType::CV), AudioPin("Gate 16", 53, PinDataType::Gate), AudioPin("Trig 16", 54, PinDataType::Gate)
        },
        {}
    );
    db["comparator"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In", 0, PinDataType::CV) },
        { AudioPin("Out", 0, PinDataType::Gate) },
        {}
    );

    db["sample_loader"] = ModulePinInfo(
        NodeWidth::Big,
        {
            AudioPin("Pitch Mod", 0, PinDataType::CV),
            AudioPin("Speed Mod", 1, PinDataType::CV),
            AudioPin("Gate Mod", 2, PinDataType::CV),
            AudioPin("Trigger Mod", 3, PinDataType::Gate),
            AudioPin("Range Start Mod", 4, PinDataType::CV),
            AudioPin("Range End Mod", 5, PinDataType::CV),
            AudioPin("Randomize Trig", 6, PinDataType::Gate)
        },
        {
            AudioPin("Out L", 0, PinDataType::Audio),
            AudioPin("Out R", 1, PinDataType::Audio)
        },
        {}
    );
    
    // Track Mixer - first 8 tracks UI definition (mono per track + gain/pan CV) and a Tracks Mod pin
    db["track mixer"] = ModulePinInfo(
        NodeWidth::Big,
        {
            // Mono audio inputs for first 8 tracks (absolute channels 0..7)
            AudioPin("In 1", 0, PinDataType::Audio),
            AudioPin("In 2", 1, PinDataType::Audio),
            AudioPin("In 3", 2, PinDataType::Audio),
            AudioPin("In 4", 3, PinDataType::Audio),
            AudioPin("In 5", 4, PinDataType::Audio),
            AudioPin("In 6", 5, PinDataType::Audio),
            AudioPin("In 7", 6, PinDataType::Audio),
            AudioPin("In 8", 7, PinDataType::Audio),

            // Num Tracks modulation CV at absolute channel 64 (start of Mod bus)
            AudioPin("Num Tracks Mod", 64, PinDataType::Raw),

            // Per-track CV inputs on Mod bus: Gain at 65,67,... Pan at 66,68,...
            AudioPin("Gain 1 Mod", 65, PinDataType::CV),  AudioPin("Pan 1 Mod", 66, PinDataType::CV),
            AudioPin("Gain 2 Mod", 67, PinDataType::CV),  AudioPin("Pan 2 Mod", 68, PinDataType::CV),
            AudioPin("Gain 3 Mod", 69, PinDataType::CV),  AudioPin("Pan 3 Mod", 70, PinDataType::CV),
            AudioPin("Gain 4 Mod", 71, PinDataType::CV),  AudioPin("Pan 4 Mod", 72, PinDataType::CV),
            AudioPin("Gain 5 Mod", 73, PinDataType::CV),  AudioPin("Pan 5 Mod", 74, PinDataType::CV),
            AudioPin("Gain 6 Mod", 75, PinDataType::CV),  AudioPin("Pan 6 Mod", 76, PinDataType::CV),
            AudioPin("Gain 7 Mod", 77, PinDataType::CV),  AudioPin("Pan 7 Mod", 78, PinDataType::CV),
            AudioPin("Gain 8 Mod", 79, PinDataType::CV),  AudioPin("Pan 8 Mod", 80, PinDataType::CV)
        },
        {
            AudioPin("Out L", 0, PinDataType::Audio),
            AudioPin("Out R", 1, PinDataType::Audio)
        },
        {}
    );
    
    // Add PolyVCO module - Build the pin lists directly in initializer list
    db["polyvco"] = ModulePinInfo(
        NodeWidth::Big,
        {
            // Num Voices modulation input
            AudioPin("Num Voices Mod", 0, PinDataType::Raw),
            
            // Frequency modulation inputs (channels 1-32)
            AudioPin("Freq 1 Mod", 1, PinDataType::CV), AudioPin("Freq 2 Mod", 2, PinDataType::CV),
            AudioPin("Freq 3 Mod", 3, PinDataType::CV), AudioPin("Freq 4 Mod", 4, PinDataType::CV),
            AudioPin("Freq 5 Mod", 5, PinDataType::CV), AudioPin("Freq 6 Mod", 6, PinDataType::CV),
            AudioPin("Freq 7 Mod", 7, PinDataType::CV), AudioPin("Freq 8 Mod", 8, PinDataType::CV),
            AudioPin("Freq 9 Mod", 9, PinDataType::CV), AudioPin("Freq 10 Mod", 10, PinDataType::CV),
            AudioPin("Freq 11 Mod", 11, PinDataType::CV), AudioPin("Freq 12 Mod", 12, PinDataType::CV),
            AudioPin("Freq 13 Mod", 13, PinDataType::CV), AudioPin("Freq 14 Mod", 14, PinDataType::CV),
            AudioPin("Freq 15 Mod", 15, PinDataType::CV), AudioPin("Freq 16 Mod", 16, PinDataType::CV),
            AudioPin("Freq 17 Mod", 17, PinDataType::CV), AudioPin("Freq 18 Mod", 18, PinDataType::CV),
            AudioPin("Freq 19 Mod", 19, PinDataType::CV), AudioPin("Freq 20 Mod", 20, PinDataType::CV),
            AudioPin("Freq 21 Mod", 21, PinDataType::CV), AudioPin("Freq 22 Mod", 22, PinDataType::CV),
            AudioPin("Freq 23 Mod", 23, PinDataType::CV), AudioPin("Freq 24 Mod", 24, PinDataType::CV),
            AudioPin("Freq 25 Mod", 25, PinDataType::CV), AudioPin("Freq 26 Mod", 26, PinDataType::CV),
            AudioPin("Freq 27 Mod", 27, PinDataType::CV), AudioPin("Freq 28 Mod", 28, PinDataType::CV),
            AudioPin("Freq 29 Mod", 29, PinDataType::CV), AudioPin("Freq 30 Mod", 30, PinDataType::CV),
            AudioPin("Freq 31 Mod", 31, PinDataType::CV), AudioPin("Freq 32 Mod", 32, PinDataType::CV),
            
            // Waveform modulation inputs (channels 33-64)
            AudioPin("Wave 1 Mod", 33, PinDataType::CV), AudioPin("Wave 2 Mod", 34, PinDataType::CV),
            AudioPin("Wave 3 Mod", 35, PinDataType::CV), AudioPin("Wave 4 Mod", 36, PinDataType::CV),
            AudioPin("Wave 5 Mod", 37, PinDataType::CV), AudioPin("Wave 6 Mod", 38, PinDataType::CV),
            AudioPin("Wave 7 Mod", 39, PinDataType::CV), AudioPin("Wave 8 Mod", 40, PinDataType::CV),
            AudioPin("Wave 9 Mod", 41, PinDataType::CV), AudioPin("Wave 10 Mod", 42, PinDataType::CV),
            AudioPin("Wave 11 Mod", 43, PinDataType::CV), AudioPin("Wave 12 Mod", 44, PinDataType::CV),
            AudioPin("Wave 13 Mod", 45, PinDataType::CV), AudioPin("Wave 14 Mod", 46, PinDataType::CV),
            AudioPin("Wave 15 Mod", 47, PinDataType::CV), AudioPin("Wave 16 Mod", 48, PinDataType::CV),
            AudioPin("Wave 17 Mod", 49, PinDataType::CV), AudioPin("Wave 18 Mod", 50, PinDataType::CV),
            AudioPin("Wave 19 Mod", 51, PinDataType::CV), AudioPin("Wave 20 Mod", 52, PinDataType::CV),
            AudioPin("Wave 21 Mod", 53, PinDataType::CV), AudioPin("Wave 22 Mod", 54, PinDataType::CV),
            AudioPin("Wave 23 Mod", 55, PinDataType::CV), AudioPin("Wave 24 Mod", 56, PinDataType::CV),
            AudioPin("Wave 25 Mod", 57, PinDataType::CV), AudioPin("Wave 26 Mod", 58, PinDataType::CV),
            AudioPin("Wave 27 Mod", 59, PinDataType::CV), AudioPin("Wave 28 Mod", 60, PinDataType::CV),
            AudioPin("Wave 29 Mod", 61, PinDataType::CV), AudioPin("Wave 30 Mod", 62, PinDataType::CV),
            AudioPin("Wave 31 Mod", 63, PinDataType::CV), AudioPin("Wave 32 Mod", 64, PinDataType::CV),
            
            // Gate modulation inputs (channels 65-96)
            AudioPin("Gate 1 Mod", 65, PinDataType::Gate), AudioPin("Gate 2 Mod", 66, PinDataType::Gate),
            AudioPin("Gate 3 Mod", 67, PinDataType::Gate), AudioPin("Gate 4 Mod", 68, PinDataType::Gate),
            AudioPin("Gate 5 Mod", 69, PinDataType::Gate), AudioPin("Gate 6 Mod", 70, PinDataType::Gate),
            AudioPin("Gate 7 Mod", 71, PinDataType::Gate), AudioPin("Gate 8 Mod", 72, PinDataType::Gate),
            AudioPin("Gate 9 Mod", 73, PinDataType::Gate), AudioPin("Gate 10 Mod", 74, PinDataType::Gate),
            AudioPin("Gate 11 Mod", 75, PinDataType::Gate), AudioPin("Gate 12 Mod", 76, PinDataType::Gate),
            AudioPin("Gate 13 Mod", 77, PinDataType::Gate), AudioPin("Gate 14 Mod", 78, PinDataType::Gate),
            AudioPin("Gate 15 Mod", 79, PinDataType::Gate), AudioPin("Gate 16 Mod", 80, PinDataType::Gate),
            AudioPin("Gate 17 Mod", 81, PinDataType::Gate), AudioPin("Gate 18 Mod", 82, PinDataType::Gate),
            AudioPin("Gate 19 Mod", 83, PinDataType::Gate), AudioPin("Gate 20 Mod", 84, PinDataType::Gate),
            AudioPin("Gate 21 Mod", 85, PinDataType::Gate), AudioPin("Gate 22 Mod", 86, PinDataType::Gate),
            AudioPin("Gate 23 Mod", 87, PinDataType::Gate), AudioPin("Gate 24 Mod", 88, PinDataType::Gate),
            AudioPin("Gate 25 Mod", 89, PinDataType::Gate), AudioPin("Gate 26 Mod", 90, PinDataType::Gate),
            AudioPin("Gate 27 Mod", 91, PinDataType::Gate), AudioPin("Gate 28 Mod", 92, PinDataType::Gate),
            AudioPin("Gate 29 Mod", 93, PinDataType::Gate), AudioPin("Gate 30 Mod", 94, PinDataType::Gate),
            AudioPin("Gate 31 Mod", 95, PinDataType::Gate), AudioPin("Gate 32 Mod", 96, PinDataType::Gate)
        },
        {
            // Audio outputs (channels 0-31)
            AudioPin("Out 1", 0, PinDataType::Audio), AudioPin("Out 2", 1, PinDataType::Audio),
            AudioPin("Out 3", 2, PinDataType::Audio), AudioPin("Out 4", 3, PinDataType::Audio),
            AudioPin("Out 5", 4, PinDataType::Audio), AudioPin("Out 6", 5, PinDataType::Audio),
            AudioPin("Out 7", 6, PinDataType::Audio), AudioPin("Out 8", 7, PinDataType::Audio),
            AudioPin("Out 9", 8, PinDataType::Audio), AudioPin("Out 10", 9, PinDataType::Audio),
            AudioPin("Out 11", 10, PinDataType::Audio), AudioPin("Out 12", 11, PinDataType::Audio),
            AudioPin("Out 13", 12, PinDataType::Audio), AudioPin("Out 14", 13, PinDataType::Audio),
            AudioPin("Out 15", 14, PinDataType::Audio), AudioPin("Out 16", 15, PinDataType::Audio),
            AudioPin("Out 17", 16, PinDataType::Audio), AudioPin("Out 18", 17, PinDataType::Audio),
            AudioPin("Out 19", 18, PinDataType::Audio), AudioPin("Out 20", 19, PinDataType::Audio),
            AudioPin("Out 21", 20, PinDataType::Audio), AudioPin("Out 22", 21, PinDataType::Audio),
            AudioPin("Out 23", 22, PinDataType::Audio), AudioPin("Out 24", 23, PinDataType::Audio),
            AudioPin("Out 25", 24, PinDataType::Audio), AudioPin("Out 26", 25, PinDataType::Audio),
            AudioPin("Out 27", 26, PinDataType::Audio), AudioPin("Out 28", 27, PinDataType::Audio),
            AudioPin("Out 29", 28, PinDataType::Audio), AudioPin("Out 30", 29, PinDataType::Audio),
            AudioPin("Out 31", 30, PinDataType::Audio), AudioPin("Out 32", 31, PinDataType::Audio)
        },
        {}
    );
    
    // Add missing modules
    db["Quantizer"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("CV In", 0, PinDataType::CV), AudioPin("Scale Mod", 1, PinDataType::CV), AudioPin("Root Mod", 2, PinDataType::CV) },
        { AudioPin("Out", 0, PinDataType::CV) },
        {}
    );
    
    db["TimePitch"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("Audio In", 0, PinDataType::Audio), AudioPin("Speed Mod", 1, PinDataType::CV), AudioPin("Pitch Mod", 2, PinDataType::CV) },
        { AudioPin("Out", 0, PinDataType::Audio) },
        {}
    );
    
    // Note: TTS Performer pin database is defined earlier in this function (around line 378)
    // Duplicate entry removed to avoid conflicts

    
    // Add TrackMixer module alias (main definition is "track mixer" above)
    db["trackmixer"] = db["track mixer"];
    
    
    // Add MIDI Player module
    db["midiplayer"] = ModulePinInfo(
        NodeWidth::ExtraWide,
        {},
        {},
        {}
    );
    
    // Add converter modules
    db["Attenuverter"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio), AudioPin("Amount Mod", 2, PinDataType::CV) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );
    
    // Add lowercase alias for Attenuverter
    db["attenuverter"] = db["Attenuverter"];
    
    // Add Sample & Hold module
    db["s&h"] = ModulePinInfo(
        NodeWidth::Small,
        { 
            AudioPin("Signal In L", 0, PinDataType::Audio),
            AudioPin("Signal In R", 1, PinDataType::Audio),
            AudioPin("Trig In L", 2, PinDataType::Gate),
            AudioPin("Trig In R", 3, PinDataType::Gate),
            AudioPin("Threshold Mod", 4, PinDataType::CV),
            AudioPin("Edge Mod", 5, PinDataType::CV),
            AudioPin("Slew Mod", 6, PinDataType::CV)
        },
        { 
            AudioPin("Out L", 0, PinDataType::Audio),
            AudioPin("Out R", 1, PinDataType::Audio)
        },
        {}
    );
    
    db["MapRange"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("Raw In", 0, PinDataType::Raw) },
        { AudioPin("CV Out", 0, PinDataType::CV), AudioPin("Audio Out", 1, PinDataType::Audio) },
        { ModPin("Min In", "minIn", PinDataType::Raw), ModPin("Max In", "maxIn", PinDataType::Raw), ModPin("Min Out", "minOut", PinDataType::Raw), ModPin("Max Out", "maxOut", PinDataType::Raw) }
    );
    
    db["Lag Processor"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("Signal In", 0, PinDataType::CV), AudioPin("Rise Mod", 1, PinDataType::CV), AudioPin("Fall Mod", 2, PinDataType::CV) },
        { AudioPin("Smoothed Out", 0, PinDataType::CV) },
        {}
    );
    
    db["De-Crackle"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In L", 0, PinDataType::Audio), AudioPin("In R", 1, PinDataType::Audio) },
        { AudioPin("Out L", 0, PinDataType::Audio), AudioPin("Out R", 1, PinDataType::Audio) },
        {}
    );

    // ADD MISSING MODULES FOR COLOR-CODED CHAINING

    db["Scope"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("In", 0, PinDataType::Audio) },
        { AudioPin("Out", 0, PinDataType::Audio) },
        {}
    );

    db["Logic"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In A", 0, PinDataType::Gate), AudioPin("In B", 1, PinDataType::Gate) },
        {
            AudioPin("AND", 0, PinDataType::Gate),
            AudioPin("OR", 1, PinDataType::Gate),
            AudioPin("XOR", 2, PinDataType::Gate),
            AudioPin("NOT A", 3, PinDataType::Gate)
        },
        {}
    );

    db["ClockDivider"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("Clock In", 0, PinDataType::Gate), AudioPin("Reset", 1, PinDataType::Gate) },
        {
            AudioPin("/2", 0, PinDataType::Gate), AudioPin("/4", 1, PinDataType::Gate),
            AudioPin("/8", 2, PinDataType::Gate), AudioPin("x2", 3, PinDataType::Gate),
            AudioPin("x3", 4, PinDataType::Gate), AudioPin("x4", 5, PinDataType::Gate)
        },
        {}
    );

    db["Rate"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("Rate Mod", 0, PinDataType::CV) },
        { AudioPin("Out", 0, PinDataType::CV) },
        {}
    );

    // ADD REMAINING MISSING MODULES FROM CMAKE LISTS

    db["Math"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In A", 0, PinDataType::CV), AudioPin("In B", 1, PinDataType::CV) },
        { AudioPin("Add", 0, PinDataType::CV), AudioPin("Subtract", 1, PinDataType::CV),
          AudioPin("Multiply", 2, PinDataType::CV), AudioPin("Divide", 3, PinDataType::CV) },
        {}
    );

    db["SequentialSwitch"] = ModulePinInfo(
        NodeWidth::Small,
        { 
            AudioPin("Gate In", 0, PinDataType::Audio),
            AudioPin("Thresh 1 CV", 1, PinDataType::CV),
            AudioPin("Thresh 2 CV", 2, PinDataType::CV),
            AudioPin("Thresh 3 CV", 3, PinDataType::CV),
            AudioPin("Thresh 4 CV", 4, PinDataType::CV)
        },
        { 
            AudioPin("Out 1", 0, PinDataType::Audio),
            AudioPin("Out 2", 1, PinDataType::Audio),
            AudioPin("Out 3", 2, PinDataType::Audio),
            AudioPin("Out 4", 3, PinDataType::Audio)
        },
        {}
    );

    db["snapshot_sequencer"] = ModulePinInfo(
        NodeWidth::ExtraWide,
        { AudioPin("Clock", 0, PinDataType::Gate), AudioPin("Reset", 1, PinDataType::Gate) },
        {}, // No audio outputs
        {}
    );

    db["midi cv"] = ModulePinInfo(
        NodeWidth::Medium,
        {}, // No inputs - receives MIDI messages
        {
            AudioPin("Pitch", 0, PinDataType::CV),
            AudioPin("Gate", 1, PinDataType::Gate),
            AudioPin("Velocity", 2, PinDataType::CV),
            AudioPin("Mod Wheel", 3, PinDataType::CV),
            AudioPin("Pitch Bend", 4, PinDataType::CV),
            AudioPin("Aftertouch", 5, PinDataType::CV)
        },
        {}
    );

    // MIDI Family - New Modules with Correct Pin Types
    {
        // MIDI Faders: All outputs are CV (blue)
        db["midi faders"] = ModulePinInfo();
        db["midi faders"].defaultWidth = NodeWidth::Big;
        for (int i = 0; i < 16; ++i)
            db["midi faders"].audioOuts.emplace_back("Fader " + juce::String(i+1), i, PinDataType::CV);

        // MIDI Knobs: All outputs are CV (blue)
        db["midi knobs"] = ModulePinInfo();
        db["midi knobs"].defaultWidth = NodeWidth::Big;
        for (int i = 0; i < 16; ++i)
            db["midi knobs"].audioOuts.emplace_back("Knob " + juce::String(i+1), i, PinDataType::CV);

        // MIDI Buttons: All outputs are Gate/Trigger (yellow)
        db["midi buttons"] = ModulePinInfo();
        db["midi buttons"].defaultWidth = NodeWidth::Big;
        for (int i = 0; i < 32; ++i)
            db["midi buttons"].audioOuts.emplace_back("Button " + juce::String(i+1), i, PinDataType::Gate);

        // MIDI Jog Wheel: Output is CV (blue)
        db["midi jog wheel"] = ModulePinInfo(
            NodeWidth::Small,
            {},
            { AudioPin("Value", 0, PinDataType::CV) },
            {}
        );
    }

    db["Debug"] = ModulePinInfo(
        NodeWidth::Small,
        { AudioPin("In", 0, PinDataType::Audio) },
        {}, // No outputs
        {}
    );

    db["InputDebug"] = ModulePinInfo(
        NodeWidth::Small,
        {}, // No inputs
        { AudioPin("Out", 0, PinDataType::Audio) },
        {}
    );

    // Tempo Clock
    db["tempo_clock"] = ModulePinInfo(
        NodeWidth::ExtraWide,
        {
            AudioPin("BPM Mod", 0, PinDataType::CV),
            AudioPin("Tap", 1, PinDataType::Gate),
            AudioPin("Nudge+", 2, PinDataType::Gate),
            AudioPin("Nudge-", 3, PinDataType::Gate),
            AudioPin("Play", 4, PinDataType::Gate),
            AudioPin("Stop", 5, PinDataType::Gate),
            AudioPin("Reset", 6, PinDataType::Gate),
            AudioPin("Swing Mod", 7, PinDataType::CV)
        },
        {
            AudioPin("Clock", 0, PinDataType::Gate),
            AudioPin("Beat Trig", 1, PinDataType::Gate),
            AudioPin("Bar Trig", 2, PinDataType::Gate),
            AudioPin("Beat Gate", 3, PinDataType::Gate),
            AudioPin("Phase", 4, PinDataType::CV),
            AudioPin("BPM CV", 5, PinDataType::CV),
            AudioPin("Downbeat", 6, PinDataType::Gate)
        },
        {
            ModPin("BPM", "bpm_mod", PinDataType::CV),
            ModPin("Tap", "tap_mod", PinDataType::Gate),
            ModPin("Nudge+", "nudge_up_mod", PinDataType::Gate),
            ModPin("Nudge-", "nudge_down_mod", PinDataType::Gate),
            ModPin("Play", "play_mod", PinDataType::Gate),
            ModPin("Stop", "stop_mod", PinDataType::Gate),
            ModPin("Reset", "reset_mod", PinDataType::Gate),
            ModPin("Swing", "swing_mod", PinDataType::CV)
        }
    );

    // BPM Monitor - Uses dynamic pins based on detected rhythm sources
    db["bpm_monitor"] = ModulePinInfo(
        NodeWidth::Big,
        {}, // Dynamic inputs defined by module (beat detection inputs)
        {}, // Dynamic outputs defined by module (per-source BPM/CV/Active)
        {}
    );

    // Physics Module - Exception size (custom dimensions defined by module)
    db["physics"] = ModulePinInfo(
        NodeWidth::Exception,
        {}, // Dynamic inputs defined by module
        {}, // Dynamic outputs defined by module
        {}
    );

    db["webcam_loader"] = ModulePinInfo(
        NodeWidth::Exception, // Custom size for video display
        {}, // No inputs
        { 
            AudioPin("Source ID", 0, PinDataType::Raw)
        },
        {}
    );

    db["video_file_loader"] = ModulePinInfo(
        NodeWidth::Exception, // Custom size for video display
        {}, // No inputs
        { 
            AudioPin("Source ID", 0, PinDataType::Raw)
        },
        {}
    );

    db["movement_detector"] = ModulePinInfo(
        NodeWidth::Medium,
        { 
            AudioPin("Source In", 0, PinDataType::Raw)
        },
        { 
            AudioPin("Motion X", 0, PinDataType::CV),
            AudioPin("Motion Y", 1, PinDataType::CV),
            AudioPin("Amount", 2, PinDataType::CV),
            AudioPin("Trigger", 3, PinDataType::Gate)
        },
        {}
    );

    db["human_detector"] = ModulePinInfo(
        NodeWidth::Medium,
        { 
            AudioPin("Source In", 0, PinDataType::Raw)
        },
        { 
            AudioPin("X", 0, PinDataType::CV),
            AudioPin("Y", 1, PinDataType::CV),
            AudioPin("Width", 2, PinDataType::CV),
            AudioPin("Height", 3, PinDataType::CV),
            AudioPin("Gate", 4, PinDataType::Gate)
        },
        {}
    );

    // Object Detector (YOLOv3) - 1 input (Source ID) and 5 outputs (X,Y,Width,Height,Gate)
    db["object_detector"] = ModulePinInfo(
        NodeWidth::Medium,
        {
            AudioPin("Source In", 0, PinDataType::Raw)
        },
        {
            AudioPin("X", 0, PinDataType::CV),
            AudioPin("Y", 1, PinDataType::CV),
            AudioPin("Width", 2, PinDataType::CV),
            AudioPin("Height", 3, PinDataType::CV),
            AudioPin("Gate", 4, PinDataType::Gate)
        },
        {}
    );

    // Color Tracker: dynamic outputs (3 per color). Only declare input here.
    db["color_tracker"] = ModulePinInfo(
        NodeWidth::Exception, // custom node width with zoom
        {
            AudioPin("Source In", 0, PinDataType::Raw)
        },
        {},
        {}
    );

    // Pose Estimator: 15 keypoints x 2 coordinates = 30 output pins
    db["pose_estimator"] = ModulePinInfo();
    db["pose_estimator"].defaultWidth = NodeWidth::Exception; // Custom size with zoom support
    db["pose_estimator"].audioIns.emplace_back("Source In", 0, PinDataType::Raw);
    // Programmatically add all 30 output pins (15 keypoints x 2 coordinates)
    const std::vector<std::string> keypointNames = {
        "Head", "Neck", "R Shoulder", "R Elbow", "R Wrist",
        "L Shoulder", "L Elbow", "L Wrist", "R Hip", "R Knee",
        "R Ankle", "L Hip", "L Knee", "L Ankle", "Chest"
    };
    for (size_t i = 0; i < keypointNames.size(); ++i)
    {
        db["pose_estimator"].audioOuts.emplace_back(keypointNames[i] + " X", i * 2, PinDataType::CV);
        db["pose_estimator"].audioOuts.emplace_back(keypointNames[i] + " Y", i * 2 + 1, PinDataType::CV);
    }

    // Hand Tracker: 21 keypoints x 2 = 42 outs
    db["hand_tracker"] = ModulePinInfo();
    db["hand_tracker"].defaultWidth = NodeWidth::Exception;
    db["hand_tracker"].audioIns.emplace_back("Source In", 0, PinDataType::Raw);
    const char* handNames[21] = {
        "Wrist",
        "Thumb 1","Thumb 2","Thumb 3","Thumb 4",
        "Index 1","Index 2","Index 3","Index 4",
        "Middle 1","Middle 2","Middle 3","Middle 4",
        "Ring 1","Ring 2","Ring 3","Ring 4",
        "Pinky 1","Pinky 2","Pinky 3","Pinky 4"
    };
    for (int i=0;i<21;++i)
    {
        db["hand_tracker"].audioOuts.emplace_back(std::string(handNames[i]) + " X", i*2, PinDataType::CV);
        db["hand_tracker"].audioOuts.emplace_back(std::string(handNames[i]) + " Y", i*2+1, PinDataType::CV);
    }

    // Face Tracker: 70 * 2 = 140 outs
    db["face_tracker"] = ModulePinInfo();
    db["face_tracker"].defaultWidth = NodeWidth::Exception;
    db["face_tracker"].audioIns.emplace_back("Source In", 0, PinDataType::Raw);
    for (int i=0;i<70;++i)
    {
        std::string base = std::string("Pt ") + std::to_string(i+1);
        db["face_tracker"].audioOuts.emplace_back(base + " X", i*2, PinDataType::CV);
        db["face_tracker"].audioOuts.emplace_back(base + " Y", i*2+1, PinDataType::CV);
    }

    // Add aliases for nodes with underscore naming convention
    db["clock_divider"] = db["ClockDivider"];
    db["sequential_switch"] = db["SequentialSwitch"];
    db["s_and_h"] = db["s&h"];

    // Contour Detector: 1 input, 3 outputs
    db["contour_detector"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("Source In", 0, PinDataType::Raw) },
        { AudioPin("Area", 0, PinDataType::CV), AudioPin("Complexity", 1, PinDataType::CV), AudioPin("Aspect Ratio", 2, PinDataType::CV) },
        {}
    );

    // Semantic Segmentation: 1 input, 4 outputs (Area, Center X, Center Y, Gate)
    db["semantic_segmentation"] = ModulePinInfo(
        NodeWidth::Medium,
        { AudioPin("Source In", 0, PinDataType::Raw) },
        { AudioPin("Area", 0, PinDataType::CV), AudioPin("Center X", 1, PinDataType::CV), AudioPin("Center Y", 2, PinDataType::CV), AudioPin("Gate", 3, PinDataType::Gate) },
        {}
    );

}





================================================================================
FILE: juce\\Source\\preset_creator\\ImGuiNodeEditorComponent.cpp
================================================================================


#include "ImGuiNodeEditorComponent.h"
#include "PinDatabase.h"

#include <imgui.h>
#include <imnodes.h>
#include <juce_audio_utils/juce_audio_utils.h>
#include <unordered_map>
#include <unordered_set>
#include <cstdint>
#include <algorithm>
#include "../audio/graph/ModularSynthProcessor.h"
#include "../audio/modules/ModuleProcessor.h"
#include "../audio/modules/AudioInputModuleProcessor.h"
#include "../audio/modules/AttenuverterModuleProcessor.h"
#include "../audio/modules/MapRangeModuleProcessor.h"
#include "../audio/modules/RandomModuleProcessor.h"
#include "../audio/modules/ValueModuleProcessor.h"
#include "../audio/modules/SampleLoaderModuleProcessor.h"
#include "../audio/modules/MIDIPlayerModuleProcessor.h"
#include "../audio/modules/PolyVCOModuleProcessor.h"
#include "../audio/modules/TrackMixerModuleProcessor.h"
#include "../audio/modules/MathModuleProcessor.h"
#include "../audio/modules/StepSequencerModuleProcessor.h"
#include "../audio/modules/MultiSequencerModuleProcessor.h"
#include "../audio/modules/StrokeSequencerModuleProcessor.h"
#include "../audio/modules/AnimationModuleProcessor.h"
#include "../audio/modules/TempoClockModuleProcessor.h"
#include "../audio/modules/WebcamLoaderModule.h"
#include "../audio/modules/VideoFileLoaderModule.h"
#include "../audio/modules/MovementDetectorModule.h"
#include "../audio/modules/HumanDetectorModule.h"
#include "../audio/modules/PoseEstimatorModule.h"
#include "../audio/modules/ColorTrackerModule.h"
#include "../audio/modules/ContourDetectorModule.h"
#include "../audio/modules/SemanticSegmentationModule.h"
#include "../audio/modules/ObjectDetectorModule.h"
#include "../audio/modules/HandTrackerModule.h"
#include "../audio/modules/FaceTrackerModule.h"
#include "../audio/modules/MapRangeModuleProcessor.h"
#include "../audio/modules/LagProcessorModuleProcessor.h"
#include "../audio/modules/DeCrackleModuleProcessor.h"
#include "../audio/modules/GraphicEQModuleProcessor.h"
#include "../audio/modules/FrequencyGraphModuleProcessor.h"
#include "../audio/modules/ChorusModuleProcessor.h"
#include "../audio/modules/PhaserModuleProcessor.h"
#include "../audio/modules/CompressorModuleProcessor.h"
#include "../audio/modules/RecordModuleProcessor.h"
#include "../audio/modules/CommentModuleProcessor.h"
#include "../audio/modules/LimiterModuleProcessor.h"
#include "../audio/modules/GateModuleProcessor.h"
#include "../audio/modules/DriveModuleProcessor.h"
#include "../audio/modules/VstHostModuleProcessor.h"
// #include "../audio/modules/SnapshotSequencerModuleProcessor.h"  // Commented out - causing build errors
#include "../audio/modules/MIDICVModuleProcessor.h"
#include "../audio/modules/ScopeModuleProcessor.h"
#include "../audio/modules/MetaModuleProcessor.h"
#include "../audio/modules/InletModuleProcessor.h"
#include "../audio/modules/OutletModuleProcessor.h"
#include "PresetCreatorApplication.h"
#include "PresetCreatorComponent.h"
#include <juce_audio_processors/juce_audio_processors.h>
#include <imgui_impl_juce/imgui_impl_juce.h>
#include <backends/imgui_impl_opengl2.h>
#include <juce_opengl/juce_opengl.h>

#define NODE_DEBUG 1

// --- Module Descriptions for Tooltips ---
static const char* toString(PinDataType t)
{
    switch (t)
    {
        case PinDataType::Audio: return "Audio";
        case PinDataType::CV: return "CV";
        case PinDataType::Gate: return "Gate";
        case PinDataType::Raw: return "Raw";
        default: return "Unknown";
    }
}

#define LOG_LINK(msg) do { if (NODE_DEBUG) juce::Logger::writeToLog("[LINK] " + juce::String(msg)); } while(0)

struct Range { float min; float max; };

// Forward declarations
class ModularSynthProcessor;
class RandomModuleProcessor;
class ValueModuleProcessor;
class StepSequencerModuleProcessor;
class MapRangeModuleProcessor;

// Helper methods for MapRange configuration
ImGuiNodeEditorComponent::Range getSourceRange(const ImGuiNodeEditorComponent::PinID& srcPin, ModularSynthProcessor* synth)
{
    if (synth == nullptr) return {0.0f, 1.0f};
    
    auto* module = synth->getModuleForLogical(srcPin.logicalId);
    if (auto* random = dynamic_cast<RandomModuleProcessor*>(module))
    {
        auto& ap = random->getAPVTS();
        float min = 0.0f, max = 1.0f;
        if (auto* minParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("min")))
            min = minParam->get();
        if (auto* maxParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("max")))
            max = maxParam->get();
        return {min, max};
    }
    else if (auto* value = dynamic_cast<ValueModuleProcessor*>(module))
    {
        auto& ap = value->getAPVTS();
        float min = 0.0f, max = 1.0f;
        if (auto* minParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("min")))
            min = minParam->get();
        if (auto* maxParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("max")))
            max = maxParam->get();
        return {min, max};
    }
    else if (auto* stepSeq = dynamic_cast<StepSequencerModuleProcessor*>(module))
    {
        // StepSequencer outputs CV range
        return {0.0f, 1.0f};
    }
    // Fallback: estimate from source's lastOutputValues
    // TODO: implement fallback estimation
    return {0.0f, 1.0f};
}

void configureMapRangeFor(PinDataType srcType, PinDataType dstType, MapRangeModuleProcessor& m, ImGuiNodeEditorComponent::Range inRange)
{
    auto& ap = m.getAPVTS();
    
    // Set input range
    if (auto* inMinParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("inMin")))
        *inMinParam = inRange.min;
    if (auto* inMaxParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("inMax")))
        *inMaxParam = inRange.max;
    
    // Set output range based on destination type
    if (dstType == PinDataType::Audio)
    {
        if (auto* outMinParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("outMin")))
            *outMinParam = -1.0f;
        if (auto* outMaxParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("outMax")))
            *outMaxParam = 1.0f;
    }
    else // CV or Gate
    {
        if (auto* outMinParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("outMin")))
            *outMinParam = 0.0f;
        if (auto* outMaxParam = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("outMax")))
            *outMaxParam = 1.0f;
    }
}




ImGuiNodeEditorComponent::ImGuiNodeEditorComponent(juce::AudioDeviceManager& dm)
    : deviceManager(dm)
{
    juce::Logger::writeToLog("ImGuiNodeEditorComponent constructor starting...");
    
    // --- THIS WILL BE THE SMOKING GUN ---
    juce::Logger::writeToLog("About to populate pin database...");
    populatePinDatabase(); // Initialize the pin database for color coding
    juce::Logger::writeToLog("Pin database populated.");
    
    glContext.setRenderer (this);
    glContext.setContinuousRepainting (true);
    glContext.setComponentPaintingEnabled (false);
    glContext.attachTo (*this);
    setWantsKeyboardFocus (true);
    
    // Initialize browser paths (load from saved settings or use defaults)
    if (auto* props = PresetCreatorApplication::getApp().getProperties())
    {
        // Load the last used paths, providing defaults if they don't exist
        auto appFile = juce::File::getSpecialLocation(juce::File::currentApplicationFile);
        juce::File defaultPresetPath = appFile.getParentDirectory().getChildFile("Presets");
        juce::File defaultSamplePath = appFile.getParentDirectory().getChildFile("Samples");

        m_presetScanPath = juce::File(props->getValue("presetScanPath", defaultPresetPath.getFullPathName()));
        m_sampleScanPath = juce::File(props->getValue("sampleScanPath", defaultSamplePath.getFullPathName()));
    }
    
    // Create these directories if they don't already exist
    if (!m_presetScanPath.exists())
        m_presetScanPath.createDirectory();
    if (!m_sampleScanPath.exists())
        m_sampleScanPath.createDirectory();
    
    juce::Logger::writeToLog("[UI] Preset path set to: " + m_presetScanPath.getFullPathName());
    juce::Logger::writeToLog("[UI] Sample path set to: " + m_sampleScanPath.getFullPathName());
    
    // --- MIDI BROWSER PATH INITIALIZATION ---
    if (auto* props = PresetCreatorApplication::getApp().getProperties())
    {
        auto appFile = juce::File::getSpecialLocation(juce::File::currentApplicationFile);
        juce::File defaultMidiPath = appFile.getParentDirectory().getChildFile("audio").getChildFile("MIDI");
        m_midiScanPath = juce::File(props->getValue("midiScanPath", defaultMidiPath.getFullPathName()));
    }
    if (!m_midiScanPath.exists())
        m_midiScanPath.createDirectory();
    juce::Logger::writeToLog("[UI] MIDI path set to: " + m_midiScanPath.getFullPathName());
    // --- END OF MIDI INITIALIZATION ---
}

ImGuiNodeEditorComponent::~ImGuiNodeEditorComponent()
{
    glContext.detach();
}

void ImGuiNodeEditorComponent::paint (juce::Graphics& g)
{
    juce::ignoreUnused (g);
}

void ImGuiNodeEditorComponent::resized()
{
    juce::Logger::writeToLog ("resized: " + juce::String (getWidth()) + "x" + juce::String (getHeight()));
}

// Input handled by imgui_juce backend

void ImGuiNodeEditorComponent::newOpenGLContextCreated()
{
    juce::Logger::writeToLog("ImGuiNodeEditor: newOpenGLContextCreated()");
    // Create ImGui context
    imguiContext = ImGui::CreateContext();
    imguiIO = &ImGui::GetIO();
    ImGui::StyleColorsDark();

    // --- FONT LOADING FOR CHINESE CHARACTERS ---
    ImGuiIO& io = ImGui::GetIO();
    io.Fonts->AddFontDefault(); // Load default English font

    // Define the path to your new font file
    auto appFile = juce::File::getSpecialLocation(juce::File::currentApplicationFile);
    auto fontFile = appFile.getParentDirectory().getChildFile("../../Source/assets/NotoSansSC-VariableFont_wght.ttf");

    if (fontFile.existsAsFile())
    {
        ImFontConfig config;
        config.MergeMode = true; // IMPORTANT: This merges the new font into the default one
        config.PixelSnapH = true;

        // Define the character ranges to load for Chinese
        static const ImWchar ranges[] = { 0x4e00, 0x9fbf, 0, }; // Basic CJK Unified Ideographs

        io.Fonts->AddFontFromFileTTF(fontFile.getFullPathName().toRawUTF8(), 16.0f, &config, ranges);
        juce::Logger::writeToLog("ImGuiNodeEditor: Chinese font loaded successfully");
    }
    else
    {
        juce::Logger::writeToLog("ImGuiNodeEditor: WARNING - Chinese font not found at: " + fontFile.getFullPathName());
    }
    
    // --- END OF FONT LOADING ---

    // imgui_juce backend handles key mapping internally (new IO API)

    // Setup JUCE platform backend and OpenGL2 renderer backend
    ImGui_ImplJuce_Init (*this, glContext);
    ImGui_ImplOpenGL2_Init();
    
    // Build fonts after renderer is initialized
    io.Fonts->Build();

    // Setup imnodes
    ImNodes::SetImGuiContext(ImGui::GetCurrentContext());
    editorContext = ImNodes::CreateContext();
    
    // Enable grid snapping
    ImNodes::GetStyle().GridSpacing = 64.0f;
    
    // Optional ergonomics: Alt = pan, Ctrl = detach link
    {
        auto& ioNodes = ImNodes::GetIO();
        auto& ioImgui = ImGui::GetIO();
        ioNodes.EmulateThreeButtonMouse.Modifier = &ioImgui.KeyAlt;
        ioNodes.LinkDetachWithModifierClick.Modifier = &ioImgui.KeyCtrl;
    }
    juce::Logger::writeToLog("ImGuiNodeEditor: ImNodes context created");
}

void ImGuiNodeEditorComponent::openGLContextClosing()
{
    juce::Logger::writeToLog("ImGuiNodeEditor: openGLContextClosing()");
    ImNodes::DestroyContext(editorContext);
    editorContext = nullptr;
    ImGui_ImplOpenGL2_Shutdown();
    ImGui_ImplJuce_Shutdown();
    ImGui::DestroyContext (imguiContext);
    imguiContext = nullptr; imguiIO = nullptr;
}

void ImGuiNodeEditorComponent::renderOpenGL()
{
    if (imguiContext == nullptr)
        return;

    ImGui::SetCurrentContext (imguiContext);

    // Clear background
    juce::OpenGLHelpers::clear (juce::Colours::darkgrey);

    // Ensure IO is valid and configured each frame (size, delta time, DPI scale, fonts)
    ImGuiIO& io = ImGui::GetIO();
    const float scale = (float) glContext.getRenderingScale();
    io.DisplaySize = ImVec2 ((float) getWidth(), (float) getHeight());
    io.DisplayFramebufferScale = ImVec2 (scale, scale);

    // imgui_juce will queue and apply key/mouse events; avoid manual KeysDown edits that break internal asserts
    io.MouseDrawCursor = false;

    // Mouse input comes via backend listeners; avoid overriding io.MousePos here

    const double nowMs = juce::Time::getMillisecondCounterHiRes();
    if (lastTime <= 0.0)
        lastTime = nowMs;
    const double dtMs = nowMs - lastTime;
    lastTime = nowMs;
    io.DeltaTime = (dtMs > 0.0 ? (float) (dtMs / 1000.0) : 1.0f / 60.0f);

    // Zoom/pan disabled: use default font scale and editor panning

    // Start a new frame for both backends
    ImGui_ImplOpenGL2_NewFrame();
    ImGui_ImplJuce_NewFrame();

    ImGui::NewFrame();
    // Demo is hidden by default; toggle can be added later if needed
    renderImGui();
    ImGui::Render();
    auto* dd = ImGui::GetDrawData();
    // Render via OpenGL2 backend
    ImGui_ImplOpenGL2_RenderDrawData (dd);
}

void ImGuiNodeEditorComponent::renderImGui()
{
    static int frameCounter = 0;
    frameCounter++;

    // ========================= THE DEFINITIVE FIX =========================
    //
    // Rebuild the audio graph at the START of the frame if a change is pending.
    // This ensures that the synth model is in a consistent state BEFORE we try
    // to draw the UI, eliminating the "lost frame" that caused nodes to jump.
    //
    if (graphNeedsRebuild.load())
    {
        juce::Logger::writeToLog("[GraphSync] Rebuild flag is set. Committing changes now...");
        if (synth)
        {
            synth->commitChanges();
        }
        graphNeedsRebuild = false; // Reset the flag immediately after committing.
        
        // CRITICAL: Invalidate hover state to prevent cable inspector from accessing
        // modules that were just deleted/recreated during commitChanges()
        lastHoveredLinkId = -1;
        lastHoveredNodeId = -1;
        hoveredLinkSrcId = 0;
        hoveredLinkDstId = 0;
        
        juce::Logger::writeToLog("[GraphSync] Graph rebuild complete.");
    }
    // ========================== END OF FIX ==========================

    // Frame start
    
    // --- Stateless Frame Rendering ---
    // Clear link registries at start of each frame for fully stateless rendering.
    // Pin IDs are now generated directly via bitmasking, no maps needed.
    linkIdToAttrs.clear();
    linkToId.clear();
    nextLinkId = 1000;

    // Handle F1 key for shortcuts window
    if (ImGui::IsKeyPressed(ImGuiKey_F1, false))
    {
        showShortcutsWindow = !showShortcutsWindow;
    }

    // Basic docking-like two-panels layout
    ImGui::SetNextWindowPos (ImVec2 (0, 0), ImGuiCond_Always);
    ImGui::SetNextWindowSize (ImVec2 ((float) getWidth(), (float) getHeight()), ImGuiCond_Always);
    ImGui::Begin ("Preset Creator", nullptr,
                  ImGuiWindowFlags_NoDecoration | ImGuiWindowFlags_NoMove | ImGuiWindowFlags_NoBringToFrontOnFocus | ImGuiWindowFlags_MenuBar);

    // --- DEFINITIVE STATUS OVERLAY ---
    // This code creates the small, semi-transparent window for the preset status.
    const float sidebarWidth = 260.0f;
    const float menuBarHeight = ImGui::GetFrameHeight();
    const float padding = 10.0f;

    ImGui::SetNextWindowPos(ImVec2(sidebarWidth + padding, menuBarHeight + padding));
    ImGui::SetNextWindowBgAlpha(0.5f);
    ImGui::Begin("Preset Status Overlay", nullptr, ImGuiWindowFlags_NoDecoration | ImGuiWindowFlags_NoMove | ImGuiWindowFlags_NoFocusOnAppearing | ImGuiWindowFlags_NoNav | ImGuiWindowFlags_AlwaysAutoResize);

    // Display the preset name or "Unsaved Patch"
    if (currentPresetFile.isNotEmpty()) {
        ImGui::Text("Preset: %s", currentPresetFile.toRawUTF8());
    } else {
        ImGui::Text("Preset: Unsaved Patch");
    }

    // Display the "Saved" or "Edited" status
    if (isPatchDirty) {
        ImGui::TextColored(ImVec4(1.0f, 1.0f, 0.0f, 1.0f), "Status: EDITED");
    } else {
        ImGui::TextColored(ImVec4(0.0f, 1.0f, 0.0f, 1.0f), "Status: SAVED");
    }

    ImGui::End();
    // --- END OF OVERLAY ---
    
    // === PROBE SCOPE OVERLAY ===
    if (synth != nullptr && showProbeScope)
    {
        if (auto* scope = dynamic_cast<ScopeModuleProcessor*>(synth->getProbeScopeProcessor()))
        {
            ImGui::SetNextWindowPos(ImVec2((float)getWidth() - 270.0f, menuBarHeight + padding), ImGuiCond_FirstUseEver);
            ImGui::SetNextWindowSize(ImVec2(260, 180), ImGuiCond_FirstUseEver);
            ImGui::SetNextWindowBgAlpha(0.85f);
            
            if (ImGui::Begin(" Probe Scope", &showProbeScope, ImGuiWindowFlags_NoFocusOnAppearing))
            {
                ImGui::Text("Signal Probe");
                ImGui::Separator();
                
                // Get scope buffer
                const auto& buffer = scope->getScopeBuffer();
                
                if (buffer.getNumSamples() > 0)
                {
                    // Create a simple waveform display
                    const int numSamples = buffer.getNumSamples();
                    const float* samples = buffer.getReadPointer(0);
                    
                    // Calculate min/max for this buffer
                    float minVal = 0.0f, maxVal = 0.0f;
                    for (int i = 0; i < numSamples; ++i)
                    {
                        minVal = juce::jmin(minVal, samples[i]);
                        maxVal = juce::jmax(maxVal, samples[i]);
                    }
                    
                    // Display stats
                    ImGui::Text("Min: %.3f  Max: %.3f", minVal, maxVal);
                    ImGui::Text("Peak: %.3f", juce::jmax(std::abs(minVal), std::abs(maxVal)));
                    
                    // Draw waveform with explicit width to avoid node expansion feedback
                    ImVec2 plotSize = ImVec2(ImGui::GetContentRegionAvail().x, 100);
                    ImGui::PlotLines("##Waveform", samples, numSamples, 0, nullptr, -1.0f, 1.0f, plotSize);
                    
                    // Button to clear probe connection
                    if (ImGui::Button("Clear Probe"))
                    {
                        synth->clearProbeConnection();
                    }
                }
                else
                {
                    ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "No signal probed");
                    ImGui::Text("Right-click > Probe Signal");
                    ImGui::Text("Then click any output pin");
                }
            }
            ImGui::End();
        }
    }
    // === END OF PROBE SCOPE OVERLAY ===

    // Clean up textures for deleted sample loaders
    if (synth != nullptr)
    {
        auto infos = synth->getModulesInfo();
        std::unordered_set<int> activeSampleLoaderIds;
        for (const auto& info : infos)
        {
            if (info.second.equalsIgnoreCase("sample loader"))
            {
                activeSampleLoaderIds.insert((int)info.first);
            }
        }

        for (auto it = sampleLoaderTextureIds.begin(); it != sampleLoaderTextureIds.end(); )
        {
            if (activeSampleLoaderIds.find(it->first) == activeSampleLoaderIds.end())
            {
                if (it->second)
                    it->second.reset();
                it = sampleLoaderTextureIds.erase(it);
            }
            else
            {
                ++it;
            }
        }
    }

    // ADD THIS BLOCK:
    if (ImGui::BeginMainMenuBar())
    {
        if (ImGui::BeginMenu("File"))
        {
            if (ImGui::MenuItem("Save Preset", "Ctrl+S")) { startSaveDialog(); }
            if (ImGui::MenuItem("Load Preset", "Ctrl+O")) { startLoadDialog(); }
            
            // ADD: Audio Settings menu item
            if (ImGui::MenuItem("Audio Settings..."))
            {
                if (onShowAudioSettings)
                    onShowAudioSettings();
            }
            
            // MIDI Device Manager menu item
            if (ImGui::MenuItem("MIDI Device Manager..."))
            {
                showMidiDeviceManager = !showMidiDeviceManager;
            }
            
            ImGui::Separator();
            
            // Plugin scanning menu item
            if (ImGui::MenuItem("Scan for Plugins..."))
            {
                // Get the application instance to access plugin management
                auto& app = PresetCreatorApplication::getApp();
                auto& formatManager = app.getPluginFormatManager();
                auto& knownPluginList = app.getKnownPluginList();

                // 1. Find the VST3 format
                juce::VST3PluginFormat* vst3Format = nullptr;
                for (int i = 0; i < formatManager.getNumFormats(); ++i)
                {
                    if (auto* format = formatManager.getFormat(i); format->getName() == "VST3")
                    {
                        vst3Format = dynamic_cast<juce::VST3PluginFormat*>(format);
                        break;
                    }
                }

                if (vst3Format != nullptr)
                {
                    // 2. Define the specific folder to scan
                    juce::File vstDir = juce::File::getSpecialLocation(juce::File::currentExecutableFile)
                                            .getParentDirectory().getChildFile("VST");

                    juce::FileSearchPath searchPath;
                    if (vstDir.isDirectory())
                    {
                        searchPath.add(vstDir);
                        juce::Logger::writeToLog("[VST Scan] Starting scan in: " + vstDir.getFullPathName());
                    }
                    else
                    {
                        vstDir.createDirectory();
                        searchPath.add(vstDir);
                        juce::Logger::writeToLog("[VST Scan] Created VST directory at: " + vstDir.getFullPathName());
                    }

                    // 3. Scan for plugins
                    auto appDataDir = juce::File::getSpecialLocation(juce::File::userApplicationDataDirectory)
                                        .getChildFile(app.getApplicationName());
                    
                    juce::PluginDirectoryScanner scanner(knownPluginList, *vst3Format, searchPath, true,
                                                         appDataDir.getChildFile("dead_plugins.txt"), true);

                    // 4. Perform the scan
                    juce::String pluginBeingScanned;
                    int numFound = 0;
                    while (scanner.scanNextFile(true, pluginBeingScanned))
                    {
                        juce::Logger::writeToLog("[VST Scan] Scanning: " + pluginBeingScanned);
                        ++numFound;
                    }
                    
                    juce::Logger::writeToLog("[VST Scan] Scan complete. Found " + juce::String(numFound) + " plugin(s).");
                    juce::Logger::writeToLog("[VST Scan] Total plugins in list: " + juce::String(knownPluginList.getNumTypes()));
                    
                    // 5. Save the updated plugin list
                    auto pluginListFile = appDataDir.getChildFile("known_plugins.xml");
                    if (auto pluginListXml = knownPluginList.createXml())
                    {
                        if (pluginListXml->writeTo(pluginListFile))
                        {
                            juce::Logger::writeToLog("[VST Scan] Saved plugin list to: " + pluginListFile.getFullPathName());
                        }
                    }
                }
                else
                {
                    juce::Logger::writeToLog("[VST Scan] ERROR: VST3 format not found in format manager.");
                }
            }
            
            ImGui::EndMenu();
        }
        
        // <<< ADD THIS ENTIRE "Edit" MENU BLOCK >>>
        if (ImGui::BeginMenu("Edit"))
        {
            if (ImGui::MenuItem("Clear Output Connections")) 
            {
                if (synth != nullptr)
                {
                    synth->clearOutputConnections();
                    pushSnapshot(); // Make the action undoable
                }
            }

            // <<< ADD THIS ENTIRE BLOCK >>>
            bool isNodeSelected = (ImNodes::NumSelectedNodes() > 0);
            if (ImGui::MenuItem("Clear Selected Node Connections", nullptr, false, isNodeSelected))
            {
                if (synth != nullptr)
                {
                    std::vector<int> selectedNodeIds(ImNodes::NumSelectedNodes());
                    ImNodes::GetSelectedNodes(selectedNodeIds.data());
                    if (!selectedNodeIds.empty())
                    {
                        // Act on the first selected node
                        juce::uint32 logicalId = (juce::uint32)selectedNodeIds[0];
                        auto nodeId = synth->getNodeIdForLogical(logicalId);
                        if (nodeId.uid != 0)
                        {
                            synth->clearConnectionsForNode(nodeId);
                            pushSnapshot(); // Make the action undoable
                        }
                    }
                }
            }
            // <<< END OF BLOCK >>>

            ImGui::EndMenu();
        }

        if (ImGui::BeginMenu("Actions"))
        {
            // This item should only be enabled if at least one node is selected
            bool anyNodesSelected = ImNodes::NumSelectedNodes() > 0;
            bool multipleNodesSelected = ImNodes::NumSelectedNodes() > 1;
            
            if (ImGui::MenuItem("Connect Selected to Track Mixer", nullptr, false, anyNodesSelected))
            {
                handleConnectSelectedToTrackMixer();
            }
            
            // Meta Module: Collapse selected nodes into a reusable sub-patch
            if (ImGui::MenuItem("Collapse to Meta Module", "Ctrl+Shift+M", false, multipleNodesSelected))
            {
                handleCollapseToMetaModule();
            }
            
            if (ImGui::MenuItem("Record Output", "Ctrl+R"))
            {
                handleRecordOutput();
            }
            
            if (ImGui::MenuItem("Beautify Layout", "Ctrl+B"))
            {
                handleBeautifyLayout();
            }
            
            ImGui::EndMenu();
        }

        if (ImGui::BeginMenu("Recording"))
        {
            if (synth != nullptr)
            {
                bool isAnyRecording = synth->isAnyModuleRecording();
                const char* label = isAnyRecording ? "Stop All Recordings" : "Start All Recordings";
                if (ImGui::MenuItem(label))
                {
                    if (isAnyRecording)
                    {
                        synth->stopAllRecorders();
                    }
                    else
                    {
                        synth->startAllRecorders();
                    }
                }
            }
            ImGui::EndMenu();
        }

        if (ImGui::BeginMenu("Generate"))
        {
            if (ImGui::MenuItem("Randomize Patch", "Ctrl+P")) { handleRandomizePatch(); }
            if (ImGui::MenuItem("Randomize Connections", "Ctrl+M")) { handleRandomizeConnections(); }
            ImGui::EndMenu();
        }

        if (ImGui::BeginMenu("Insert Node"))
        {
            bool isNodeSelected = (selectedLogicalId != 0);
            
            if (ImGui::BeginMenu("Effects", isNodeSelected))
            {
                if (ImGui::MenuItem("VCF")) { insertNodeBetween("vcf"); }
                if (ImGui::MenuItem("Delay")) { insertNodeBetween("delay"); }
                if (ImGui::MenuItem("Reverb")) { insertNodeBetween("reverb"); }
                if (ImGui::MenuItem("Chorus")) { insertNodeBetween("chorus"); }
                if (ImGui::MenuItem("Phaser")) { insertNodeBetween("phaser"); }
                if (ImGui::MenuItem("Compressor")) { insertNodeBetween("compressor"); }
                if (ImGui::MenuItem("Limiter")) { insertNodeBetween("limiter"); }
                if (ImGui::MenuItem("Noise Gate")) { insertNodeBetween("gate"); }
                if (ImGui::MenuItem("Drive")) { insertNodeBetween("drive"); }
                if (ImGui::MenuItem("Graphic EQ")) { insertNodeBetween("graphic_eq"); }
                if (ImGui::MenuItem("Waveshaper")) { insertNodeBetween("waveshaper"); }
                if (ImGui::MenuItem("8-Band Shaper")) { insertNodeBetween("8bandshaper"); }
                if (ImGui::MenuItem("Granulator")) { insertNodeBetween("granulator"); }
                if (ImGui::MenuItem("Harmonic Shaper")) { insertNodeBetween("harmonic_shaper"); }
                if (ImGui::MenuItem("Time/Pitch Shifter")) { insertNodeBetween("timepitch"); }
                if (ImGui::MenuItem("De-Crackle")) { insertNodeBetween("de_crackle"); }
                ImGui::EndMenu();
            }
            
            if (ImGui::BeginMenu("Modulators", isNodeSelected))
            {
                if (ImGui::MenuItem("LFO")) { insertNodeBetween("lfo"); }
                if (ImGui::MenuItem("ADSR")) { insertNodeBetween("adsr"); }
                if (ImGui::MenuItem("Random")) { insertNodeBetween("random"); }
                if (ImGui::MenuItem("S&H")) { insertNodeBetween("s_and_h"); }
                if (ImGui::MenuItem("Function Generator")) { insertNodeBetween("function_generator"); }
                if (ImGui::MenuItem("Shaping Oscillator")) { insertNodeBetween("shaping_oscillator"); }
                ImGui::EndMenu();
            }
            
            if (ImGui::BeginMenu("Utilities & Logic", isNodeSelected))
            {
                if (ImGui::MenuItem("VCA")) { insertNodeBetween("vca"); }
                if (ImGui::MenuItem("Mixer")) { insertNodeBetween("mixer"); }
                if (ImGui::MenuItem("CV Mixer")) { insertNodeBetween("cv_mixer"); }
                if (ImGui::MenuItem("Attenuverter")) { insertNodeBetween("attenuverter"); }
                if (ImGui::MenuItem("Lag Processor")) { insertNodeBetween("lag_processor"); }
                if (ImGui::MenuItem("Math")) { insertNodeBetween("math"); }
                if (ImGui::MenuItem("Map Range")) { insertNodeBetween("map_range"); }
                if (ImGui::MenuItem("Quantizer")) { insertNodeBetween("quantizer"); }
                if (ImGui::MenuItem("Rate")) { insertNodeBetween("rate"); }
                if (ImGui::MenuItem("Comparator")) { insertNodeBetween("comparator"); }
                if (ImGui::MenuItem("Logic")) { insertNodeBetween("logic"); }
                if (ImGui::MenuItem("Sequential Switch")) { insertNodeBetween("sequential_switch"); }
                ImGui::EndMenu();
            }
            
            if (ImGui::BeginMenu("TTS", isNodeSelected))
            {
                if (ImGui::MenuItem("TTS Performer")) { insertNodeBetween("tts_performer"); }
                if (ImGui::MenuItem("Vocal Tract Filter")) { insertNodeBetween("vocal_tract_filter"); }
                ImGui::EndMenu();
            }
            
            if (ImGui::BeginMenu("Analysis", isNodeSelected))
            {
                if (ImGui::MenuItem("Scope")) { insertNodeBetween("scope"); }
                if (ImGui::MenuItem("Frequency Graph")) { insertNodeBetween("frequency_graph"); }
                ImGui::EndMenu();
            }
            
            ImGui::EndMenu();
        }
        if (ImGui::BeginMenu("Inspector"))
        {
            ImGui::SliderFloat("Window (s)", &inspectorWindowSeconds, 0.5f, 20.0f, "%.1f s");
            ImGui::EndMenu();
        }
        
        // === DEBUG MENU ===
        if (ImGui::BeginMenu("Debug"))
        {
            if (ImGui::MenuItem("Show System Diagnostics", "Ctrl+Shift+D")) 
            {
                showDebugMenu = !showDebugMenu;
            }
            
            
            if (ImGui::MenuItem("Log System State"))
            {
                if (synth != nullptr)
                {
                    juce::Logger::writeToLog("=== SYSTEM DIAGNOSTICS ===");
                    juce::Logger::writeToLog(synth->getSystemDiagnostics());
                }
            }
            
            if (ImGui::MenuItem("Log Selected Module Diagnostics"))
            {
                if (synth != nullptr && selectedLogicalId != 0)
                {
                    juce::Logger::writeToLog("=== MODULE DIAGNOSTICS ===");
                    juce::Logger::writeToLog(synth->getModuleDiagnostics(selectedLogicalId));
                }
            }
            
            ImGui::EndMenu();
        }
        
        // === TRANSPORT CONTROLS ===
        if (synth != nullptr)
        {
            // Get current transport state
            auto transportState = synth->getTransportState();
            
            // Add some spacing before transport controls
            ImGui::Separator();
            ImGui::Spacing();
            
            // Play/Pause button
            if (transportState.isPlaying)
            {
                if (ImGui::Button("Pause"))
                    synth->setPlaying(false);
            }
            else
            {
                if (ImGui::Button("Play"))
                    synth->setPlaying(true);
            }
            
            ImGui::SameLine();
            
            // Stop button (resets position)
            if (ImGui::Button("Stop"))
            {
                synth->setPlaying(false);
                synth->resetTransportPosition();
            }
            
            ImGui::SameLine();
            
            // BPM control (greyed out if controlled by Tempo Clock module)
            float bpm = static_cast<float>(transportState.bpm);
            ImGui::SetNextItemWidth(80.0f);
            
            bool isControlled = transportState.isTempoControlledByModule.load();
            if (isControlled)
                ImGui::BeginDisabled();
                
            if (ImGui::DragFloat("BPM", &bpm, 0.1f, 20.0f, 999.0f, "%.1f"))
                synth->setBPM(static_cast<double>(bpm));
                
            if (isControlled)
            {
                ImGui::EndDisabled();
                if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenDisabled))
                {
                    ImGui::BeginTooltip();
                    ImGui::PushTextWrapPos(ImGui::GetFontSize() * 25.0f);
                    ImGui::TextColored(ImVec4(1.0f, 0.8f, 0.0f, 1.0f), "Tempo Clock Module Active");
                    ImGui::TextUnformatted("A Tempo Clock node with 'Sync to Host' disabled is controlling the global BPM.");
                    ImGui::PopTextWrapPos();
                    ImGui::EndTooltip();
                }
            }
            
            ImGui::SameLine();
            
            // Position display
            ImGui::Text("%.2f beats", transportState.songPositionBeats);
        }
        
        // === MULTI-MIDI DEVICE ACTIVITY INDICATOR ===
        ImGui::SameLine();
        ImGui::Separator();
        ImGui::SameLine();
        
        if (synth != nullptr)
        {
            auto activityState = synth->getMidiActivityState();
            
            if (activityState.deviceNames.empty())
            {
                // No MIDI devices connected
                ImGui::PushStyleColor(ImGuiCol_Text, IM_COL32(100, 100, 100, 255));
                ImGui::Text("MIDI: No Devices");
                ImGui::PopStyleColor();
            }
            else
            {
                ImGui::Text("MIDI:");
                ImGui::SameLine();
                
                // Display each device with active channels
                for (const auto& [deviceIndex, deviceName] : activityState.deviceNames)
                {
                    ImGui::SameLine();
                    
                    bool hasActivity = false;
                    if (activityState.deviceChannelActivity.count(deviceIndex) > 0)
                    {
                        const auto& channels = activityState.deviceChannelActivity.at(deviceIndex);
                        for (bool active : channels)
                        {
                            if (active)
                            {
                                hasActivity = true;
                                break;
                            }
                        }
                    }
                    
                    // Abbreviated device name (max 12 chars)
                    juce::String abbrevName = deviceName;
                    if (abbrevName.length() > 12)
                        abbrevName = abbrevName.substring(0, 12) + "...";
                    
                    // Color: bright green if active, dim gray if inactive
                    if (hasActivity)
                        ImGui::PushStyleColor(ImGuiCol_Text, IM_COL32(100, 255, 100, 255));
                    else
                        ImGui::PushStyleColor(ImGuiCol_Text, IM_COL32(100, 100, 100, 255));
                    
                    ImGui::Text("[%s]", abbrevName.toRawUTF8());
                    ImGui::PopStyleColor();
                    
                    // Tooltip with full name and active channels
                    if (ImGui::IsItemHovered())
                    {
                        ImGui::BeginTooltip();
                        ImGui::Text("%s", deviceName.toRawUTF8());
                        ImGui::Separator();
                        
                        if (activityState.deviceChannelActivity.count(deviceIndex) > 0)
                        {
                            const auto& channels = activityState.deviceChannelActivity.at(deviceIndex);
                            ImGui::Text("Active Channels:");
                            juce::String activeChannels;
                            for (int ch = 0; ch < 16; ++ch)
                            {
                                if (channels[ch])
                                {
                                    if (activeChannels.isNotEmpty())
                                        activeChannels += ", ";
                                    activeChannels += juce::String(ch + 1);
                                }
                            }
                            if (activeChannels.isEmpty())
                                activeChannels = "None";
                            ImGui::Text("%s", activeChannels.toRawUTF8());
                        }
                        
                        ImGui::EndTooltip();
                    }
                }
            }
        }
        else
        {
            ImGui::PushStyleColor(ImGuiCol_Text, IM_COL32(100, 100, 100, 255));
            ImGui::Text("MIDI: ---");
            ImGui::PopStyleColor();
        }
        // === END OF MULTI-MIDI INDICATOR ===
        
        ImGui::EndMainMenuBar();
    }

    // --- PRESET STATUS OVERLAY ---
    ImGui::SetNextWindowPos(ImVec2(sidebarWidth + padding, menuBarHeight + padding));
    ImGui::SetNextWindowBgAlpha(0.7f);
    ImGui::Begin("Preset Status", nullptr, 
                 ImGuiWindowFlags_NoDecoration | 
                 ImGuiWindowFlags_NoMove | 
                 ImGuiWindowFlags_NoFocusOnAppearing | 
                 ImGuiWindowFlags_NoNav | 
                 ImGuiWindowFlags_AlwaysAutoResize);

    if (currentPresetFile.isNotEmpty()) {
        ImGui::Text("Preset: %s", currentPresetFile.toRawUTF8());
    } else {
        ImGui::Text("Preset: Unsaved Patch");
    }

    if (isPatchDirty) {
        ImGui::TextColored(ImVec4(1.0f, 1.0f, 0.0f, 1.0f), "Status: EDITED");
    } else {
        ImGui::TextColored(ImVec4(0.0f, 1.0f, 0.0f, 1.0f), "Status: SAVED");
    }

    ImGui::End();
    // --- END OF PRESET STATUS OVERLAY ---

    ImGui::Columns (2, nullptr, true);
    ImGui::SetColumnWidth (0, 260.0f);

    // Zoom removed

    // ADD THIS BLOCK:
    ImGui::Text("Browser");
    
    // Create a scrolling child window to contain the entire browser
    ImGui::BeginChild("BrowserScrollRegion", ImVec2(0, 0), true);
    
    // Helper lambda to recursively draw the directory tree for presets
    std::function<void(const PresetManager::DirectoryNode*)> drawPresetTree = 
        [&](const PresetManager::DirectoryNode* node)
    {
        if (!node || (node->presets.empty() && node->subdirectories.empty())) return;

        // Draw subdirectories first
        for (const auto& subdir : node->subdirectories)
        {
            if (ImGui::TreeNode(subdir->name.toRawUTF8()))
            {
                drawPresetTree(subdir.get());
                ImGui::TreePop();
            }
        }
        
        // Then draw presets in this directory with drag-and-drop support
        for (const auto& preset : node->presets)
        {
            if (m_presetSearchTerm.isEmpty() || preset.name.containsIgnoreCase(m_presetSearchTerm))
            {
                // Draw the selectable item and capture its return value
                bool clicked = ImGui::Selectable(preset.name.toRawUTF8());

                // --- THIS IS THE FIX ---
                // Check if this item is the source of a drag operation
                if (ImGui::BeginDragDropSource(ImGuiDragDropFlags_None))
                {
                    // Set the payload type and data (the preset's file path)
                    const juce::String path = preset.file.getFullPathName();
                    const std::string pathStr = path.toStdString();
                    ImGui::SetDragDropPayload("DND_PRESET_PATH", pathStr.c_str(), pathStr.length() + 1);
                    
                    // Provide visual feedback while dragging
                    ImGui::SetMouseCursor(ImGuiMouseCursor_Hand);
                    ImGui::Text("Merge Preset: %s", preset.name.toRawUTF8());
                    
                    ImGui::EndDragDropSource();
                }
                // If a drag did NOT occur, and the item was clicked, load the preset
                else if (clicked)
                {
                    loadPresetFromFile(preset.file);
                }
                // --- END OF FIX ---
                
                // Tooltip (only shown when hovering, not dragging)
                if (ImGui::IsItemHovered() && !ImGui::IsMouseDragging(0) && preset.description.isNotEmpty())
                {
                    ImGui::BeginTooltip();
                    ImGui::TextUnformatted(preset.description.toRawUTF8());
                    if (!preset.tags.isEmpty())
                        ImGui::Text("Tags: %s", preset.tags.joinIntoString(", ").toRawUTF8());
                    ImGui::EndTooltip();
                }
            }
        }
    };

    // Helper to push category colors (used for all module category headers)
    auto pushCategoryColor = [&](ModuleCategory cat) {
        ImU32 color = getImU32ForCategory(cat);
        ImVec4 c = ImGui::ColorConvertU32ToFloat4(color);
        ImGui::PushStyleColor(ImGuiCol_Header, color);
        ImGui::PushStyleColor(ImGuiCol_HeaderHovered, ImGui::ColorConvertFloat4ToU32(ImVec4(c.x*1.2f, c.y*1.2f, c.z*1.2f, 1.0f)));
        ImGui::PushStyleColor(ImGuiCol_HeaderActive, ImGui::ColorConvertFloat4ToU32(ImVec4(c.x*1.4f, c.y*1.4f, c.z*1.4f, 1.0f)));
    };

    // === PRESET BROWSER ===
    ImGui::PushStyleColor(ImGuiCol_Header, IM_COL32(218, 165, 32, 255)); // Gold
    ImGui::PushStyleColor(ImGuiCol_HeaderHovered, IM_COL32(238, 185, 52, 255));
    ImGui::PushStyleColor(ImGuiCol_HeaderActive, IM_COL32(255, 205, 72, 255));
    bool presetsExpanded = ImGui::CollapsingHeader("Presets");
    ImGui::PopStyleColor(3);
    
    if (presetsExpanded)
    {
        // 1. Path Display (read-only)
        char pathBuf[1024];
        strncpy(pathBuf, m_presetScanPath.getFullPathName().toRawUTF8(), sizeof(pathBuf) - 1);
        ImGui::InputText("##presetpath", pathBuf, sizeof(pathBuf), ImGuiInputTextFlags_ReadOnly);

        // 2. "Change Path" Button
        if (ImGui::Button("Change Path##preset"))
        {
            presetPathChooser = std::make_unique<juce::FileChooser>("Select Preset Directory", m_presetScanPath);
            presetPathChooser->launchAsync(juce::FileBrowserComponent::openMode | juce::FileBrowserComponent::canSelectDirectories,
                [this](const juce::FileChooser& fc)
                {
                    auto dir = fc.getResult();
                    if (dir.isDirectory())
                    {
                        m_presetScanPath = dir;
                        // Save the new path to the properties file
                        if (auto* props = PresetCreatorApplication::getApp().getProperties())
                        {
                            props->setValue("presetScanPath", m_presetScanPath.getFullPathName());
                        }
                    }
                });
        }
        ImGui::SameLine();

        // 3. "Scan" Button
        if (ImGui::Button("Scan##preset"))
        {
            m_presetManager.clearCache();
            m_presetManager.scanDirectory(m_presetScanPath);
        }

        // 4. Search bar for filtering results
        char searchBuf[256] = {};
        strncpy(searchBuf, m_presetSearchTerm.toRawUTF8(), sizeof(searchBuf) - 1);
        if (ImGui::InputText("Search##preset", searchBuf, sizeof(searchBuf)))
            m_presetSearchTerm = juce::String(searchBuf);

        ImGui::Separator();

        // 5. Display hierarchical preset tree
        drawPresetTree(m_presetManager.getRootNode());
    }
    
    // Helper lambda to recursively draw the directory tree for samples
    std::function<void(const SampleManager::DirectoryNode*)> drawSampleTree = 
        [&](const SampleManager::DirectoryNode* node)
    {
        if (!node || (node->samples.empty() && node->subdirectories.empty())) return;

        // Draw subdirectories first
        for (const auto& subdir : node->subdirectories)
        {
            if (ImGui::TreeNode(subdir->name.toRawUTF8()))
            {
                drawSampleTree(subdir.get());
                ImGui::TreePop();
            }
        }
        
        // Then draw samples in this directory with drag-and-drop support
        for (const auto& sample : node->samples)
        {
            if (m_sampleSearchTerm.isEmpty() || sample.name.containsIgnoreCase(m_sampleSearchTerm))
            {
                // --- THIS IS THE HEROIC FIX ---

                // A. Draw the selectable item and capture its return value (which is true on mouse release).
                bool clicked = ImGui::Selectable(sample.name.toRawUTF8());

                // B. Check if this item is the source of a drag operation. This takes priority.
                if (ImGui::BeginDragDropSource(ImGuiDragDropFlags_None))
                {
                    // Set the payload (the data we are transferring is the sample's file path).
                    const juce::String path = sample.file.getFullPathName();
                    const std::string pathStr = path.toStdString();
                    ImGui::SetDragDropPayload("DND_SAMPLE_PATH", pathStr.c_str(), pathStr.length() + 1);
                    
                    // Provide visual feedback during the drag.
                    ImGui::SetMouseCursor(ImGuiMouseCursor_Hand);
                    ImGui::Text("Dragging: %s", sample.name.toRawUTF8());
                    
                    ImGui::EndDragDropSource();
                }
                // C. If a drag did NOT occur, and the item was clicked (mouse released on it), then create the node.
                else if (clicked)
                {
                    if (synth != nullptr)
                    {
                        auto newNodeId = synth->addModule("sample_loader");
                        auto newLogicalId = synth->getLogicalIdForNode(newNodeId);
                        pendingNodeScreenPositions[(int)newLogicalId] = ImGui::GetMousePos();
                        if (auto* sampleLoader = dynamic_cast<SampleLoaderModuleProcessor*>(synth->getModuleForLogical(newLogicalId)))
                        {
                            sampleLoader->loadSample(sample.file);
                        }
                        snapshotAfterEditor = true;
                    }
                }
                
                // --- END OF FIX ---

                // (Existing tooltip for sample info remains the same)
                if (ImGui::IsItemHovered() && !ImGui::IsMouseDragging(0))
                {
                    ImGui::BeginTooltip();
                    ImGui::Text("Duration: %.2f s", sample.durationSeconds);
                    ImGui::Text("Rate: %d Hz", sample.sampleRate);
                    ImGui::EndTooltip();
                }
            }
        }
    };

    // === SAMPLE BROWSER ===
    ImGui::PushStyleColor(ImGuiCol_Header, IM_COL32(0, 180, 180, 255)); // Cyan
    ImGui::PushStyleColor(ImGuiCol_HeaderHovered, IM_COL32(20, 200, 200, 255));
    ImGui::PushStyleColor(ImGuiCol_HeaderActive, IM_COL32(40, 220, 220, 255));
    bool samplesExpanded = ImGui::CollapsingHeader("Samples");
    ImGui::PopStyleColor(3);
    
    if (samplesExpanded)
    {
        // 1. Path Display (read-only)
        char pathBuf[1024];
        strncpy(pathBuf, m_sampleScanPath.getFullPathName().toRawUTF8(), sizeof(pathBuf) - 1);
        ImGui::InputText("##samplepath", pathBuf, sizeof(pathBuf), ImGuiInputTextFlags_ReadOnly);

        // 2. "Change Path" Button
        if (ImGui::Button("Change Path##sample"))
        {
            samplePathChooser = std::make_unique<juce::FileChooser>("Select Sample Directory", m_sampleScanPath);
            samplePathChooser->launchAsync(juce::FileBrowserComponent::openMode | juce::FileBrowserComponent::canSelectDirectories,
                [this](const juce::FileChooser& fc)
                {
                    auto dir = fc.getResult();
                    if (dir.isDirectory())
                    {
                        m_sampleScanPath = dir;
                        // Save the new path to the properties file
                        if (auto* props = PresetCreatorApplication::getApp().getProperties())
                        {
                            props->setValue("sampleScanPath", m_sampleScanPath.getFullPathName());
                        }
                    }
                });
        }
        ImGui::SameLine();

        // 3. "Scan" Button
        if (ImGui::Button("Scan##sample"))
        {
            m_sampleManager.clearCache();
            m_sampleManager.scanDirectory(m_sampleScanPath);
        }

        // 4. Search bar for filtering results
        char searchBuf[256] = {};
        strncpy(searchBuf, m_sampleSearchTerm.toRawUTF8(), sizeof(searchBuf) - 1);
        if (ImGui::InputText("Search##sample", searchBuf, sizeof(searchBuf)))
            m_sampleSearchTerm = juce::String(searchBuf);

        ImGui::Separator();

        // 5. Display hierarchical sample tree
        drawSampleTree(m_sampleManager.getRootNode());
    }
    
    ImGui::Separator();
    
    // === MIDI BROWSER ===
    ImGui::PushStyleColor(ImGuiCol_Header, IM_COL32(180, 120, 255, 255)); // Purple
    ImGui::PushStyleColor(ImGuiCol_HeaderHovered, IM_COL32(200, 140, 255, 255));
    ImGui::PushStyleColor(ImGuiCol_HeaderActive, IM_COL32(220, 160, 255, 255));
    bool midiExpanded = ImGui::CollapsingHeader("MIDI Files");
    ImGui::PopStyleColor(3);
    
    if (midiExpanded)
    {
        // 1. Path Display (read-only)
        char pathBuf[1024];
        strncpy(pathBuf, m_midiScanPath.getFullPathName().toRawUTF8(), sizeof(pathBuf) - 1);
        ImGui::InputText("##midipath", pathBuf, sizeof(pathBuf), ImGuiInputTextFlags_ReadOnly);

        // 2. "Change Path" Button
        if (ImGui::Button("Change Path##midi"))
        {
            midiPathChooser = std::make_unique<juce::FileChooser>("Select MIDI Directory", m_midiScanPath);
            midiPathChooser->launchAsync(juce::FileBrowserComponent::openMode | juce::FileBrowserComponent::canSelectDirectories,
                [this](const juce::FileChooser& fc)
                {
                    auto dir = fc.getResult();
                    if (dir.isDirectory())
                    {
                        m_midiScanPath = dir;
                        // Save the new path to the properties file
                        if (auto* props = PresetCreatorApplication::getApp().getProperties())
                        {
                            props->setValue("midiScanPath", m_midiScanPath.getFullPathName());
                        }
                    }
                });
        }
        ImGui::SameLine();

        // 3. "Scan" Button
        if (ImGui::Button("Scan##midi"))
        {
            m_midiManager.clearCache();
            m_midiManager.scanDirectory(m_midiScanPath);
        }

        // 4. Search bar for filtering results
        char searchBuf[256] = {};
        strncpy(searchBuf, m_midiSearchTerm.toRawUTF8(), sizeof(searchBuf) - 1);
        if (ImGui::InputText("Search##midi", searchBuf, sizeof(searchBuf)))
            m_midiSearchTerm = juce::String(searchBuf);

        ImGui::Separator();
        
        // 5. Display hierarchical MIDI tree
        std::function<void(const MidiManager::DirectoryNode*)> drawMidiTree = 
            [&](const MidiManager::DirectoryNode* node)
        {
            if (!node || (node->midiFiles.empty() && node->subdirectories.empty())) return;

            // Draw subdirectories first
            for (const auto& subdir : node->subdirectories)
            {
                if (ImGui::TreeNode(subdir->name.toRawUTF8()))
                {
                    drawMidiTree(subdir.get());
                    ImGui::TreePop();
                }
            }
            
            // Then draw MIDI files in this directory with drag-and-drop support
            for (const auto& midi : node->midiFiles)
            {
                if (m_midiSearchTerm.isEmpty() || midi.name.containsIgnoreCase(m_midiSearchTerm))
                {
                    // Draw the selectable item and capture its return value
                    bool clicked = ImGui::Selectable(midi.name.toRawUTF8());

                    // Check if this item is the source of a drag operation
                    if (ImGui::BeginDragDropSource(ImGuiDragDropFlags_None))
                    {
                        // Set the payload (the MIDI file path)
                        const juce::String path = midi.file.getFullPathName();
                        const std::string pathStr = path.toStdString();
                        ImGui::SetDragDropPayload("DND_MIDI_PATH", pathStr.c_str(), pathStr.length() + 1);
                        
                        // Provide visual feedback during the drag
                        ImGui::SetMouseCursor(ImGuiMouseCursor_Hand);
                        ImGui::Text("Dragging: %s", midi.name.toRawUTF8());
                        
                        ImGui::EndDragDropSource();
                    }
                    // If a drag did NOT occur, and the item was clicked, create a new MIDI Player node
                    else if (clicked)
                    {
                        if (synth != nullptr)
                        {
                            auto newNodeId = synth->addModule("midi_player");
                            auto newLogicalId = synth->getLogicalIdForNode(newNodeId);
                            pendingNodeScreenPositions[(int)newLogicalId] = ImGui::GetMousePos();
                            
                            // Load the MIDI file into the new player
                            if (auto* midiPlayer = dynamic_cast<MIDIPlayerModuleProcessor*>(synth->getModuleForLogical(newLogicalId)))
                            {
                                midiPlayer->loadMIDIFile(midi.file);
                            }
                            
                            snapshotAfterEditor = true;
                        }
                    }
                    
                    // Tooltip for MIDI info (only shown when hovering, not dragging)
                    if (ImGui::IsItemHovered() && !ImGui::IsMouseDragging(0))
                    {
                        ImGui::BeginTooltip();
                        ImGui::Text("MIDI File: %s", midi.file.getFileName().toRawUTF8());
                        ImGui::EndTooltip();
                    }
                }
            }
        };
        
        drawMidiTree(m_midiManager.getRootNode());
    }
    
    ImGui::Separator();
    
    // === MODULE BROWSER ===
    ImGui::PushStyleColor(ImGuiCol_Header, IM_COL32(80, 80, 80, 255)); // Neutral Grey
    ImGui::PushStyleColor(ImGuiCol_HeaderHovered, IM_COL32(100, 100, 100, 255));
    ImGui::PushStyleColor(ImGuiCol_HeaderActive, IM_COL32(120, 120, 120, 255));
    bool modulesExpanded = ImGui::CollapsingHeader("Modules", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    
    if (modulesExpanded)
    {
    
    auto addModuleButton = [this](const char* label, const char* type)
    {
        if (ImGui::Selectable(label, false))
        {
            if (synth != nullptr)
            {
                auto nodeId = synth->addModule(type);
                const ImVec2 mouse = ImGui::GetMousePos();
                // queue screen-space placement after node is drawn to avoid assertions
                const int logicalId = (int) synth->getLogicalIdForNode (nodeId);
                pendingNodeScreenPositions[logicalId] = mouse;
                // Defer snapshot until after EndNodeEditor so the node exists in this frame
                snapshotAfterEditor = true;
            }
        }
        
        // --- FIX: Show tooltip with module description on hover ---
        if (ImGui::IsItemHovered())
        {
            ImGui::BeginTooltip();
            
            // Find the description in our list using the module's internal 'type'
            bool found = false;
            for (const auto& pair : getModuleDescriptions())
            {
                if (pair.first.equalsIgnoreCase(type))
                {
                    // If found, display it
                    ImGui::TextUnformatted(pair.second);
                    found = true;
                    break;
                }
            }
            if (!found)
            {
                // Fallback text if a description is missing
                ImGui::TextUnformatted("No description available.");
            }
            
            ImGui::EndTooltip();
        }
    };
    
    // 
    // MODULE NAMING CONVENTION:
    //  
    // ALL module type names MUST follow this strict naming convention:
    //    Use ONLY lowercase letters (a-z)
    //    Use ONLY numbers (0-9) where appropriate
    //    Replace ALL spaces with underscores (_)
    //    NO capital letters allowed
    //    NO hyphens or other special characters
    //
    // Examples:
    //    CORRECT:   "midi_player", "sample_loader", "graphic_eq", "vco"
    //    INCORRECT: "MIDI Player", "Sample Loader", "Graphic EQ", "VCO"
    //
    // This ensures consistent module identification across the system.
    // 
    
    // 
    // 1. SOURCES - Signal generators and inputs
    // 
    pushCategoryColor(ModuleCategory::Source);
    bool sourcesExpanded = ImGui::CollapsingHeader("Sources", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (sourcesExpanded) {
        addModuleButton("VCO", "vco");
        addModuleButton("Polyphonic VCO", "polyvco");
        addModuleButton("Noise", "noise");
        addModuleButton("Audio Input", "audio_input");
        addModuleButton("Sample Loader", "sample_loader");
        addModuleButton("Value", "value");
    }
    
    // 
    // 2. EFFECTS - Audio processing and tone shaping
    // 
    pushCategoryColor(ModuleCategory::Effect);
    bool effectsExpanded = ImGui::CollapsingHeader("Effects", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (effectsExpanded) {
        addModuleButton("VCF", "vcf");
        addModuleButton("Delay", "delay");
        addModuleButton("Reverb", "reverb");
        addModuleButton("Chorus", "chorus");
        addModuleButton("Phaser", "phaser");
        addModuleButton("Compressor", "compressor");
        addModuleButton("Limiter", "limiter");
        addModuleButton("Noise Gate", "gate");
        addModuleButton("Drive", "drive");
        addModuleButton("Graphic EQ", "graphic_eq");
        addModuleButton("Waveshaper", "waveshaper");
        addModuleButton("8-Band Shaper", "8bandshaper");
        addModuleButton("Granulator", "granulator");
        addModuleButton("Harmonic Shaper", "harmonic_shaper");
        addModuleButton("Time/Pitch Shifter", "timepitch");
        addModuleButton("De-Crackle", "de_crackle");
    }
    
    // 
    // 3. MODULATORS - CV generation and modulation sources
    // 
    pushCategoryColor(ModuleCategory::Modulator);
    bool modulatorsExpanded = ImGui::CollapsingHeader("Modulators", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (modulatorsExpanded) {
        addModuleButton("LFO", "lfo");
        addModuleButton("ADSR", "adsr");
        addModuleButton("Random", "random");
        addModuleButton("S&H", "s_and_h");
        addModuleButton("Function Generator", "function_generator");
        addModuleButton("Shaping Oscillator", "shaping_oscillator");
    }
    
    // 
    // 4. UTILITIES & LOGIC - Signal processing and routing
    // 
    pushCategoryColor(ModuleCategory::Utility);
    bool utilitiesExpanded = ImGui::CollapsingHeader("Utilities & Logic", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (utilitiesExpanded) {
        addModuleButton("VCA", "vca");
        addModuleButton("Mixer", "mixer");
        addModuleButton("CV Mixer", "cv_mixer");
        addModuleButton("Track Mixer", "track_mixer");
        addModuleButton("Attenuverter", "attenuverter");
        addModuleButton("Lag Processor", "lag_processor");
        addModuleButton("Math", "math");
        addModuleButton("Map Range", "map_range");
        addModuleButton("Quantizer", "quantizer");
        addModuleButton("Rate", "rate");
        addModuleButton("Comparator", "comparator");
        addModuleButton("Logic", "logic");
        addModuleButton("Clock Divider", "clock_divider");
        addModuleButton("Sequential Switch", "sequential_switch");
    }
    
    // 
    // 5. SEQUENCERS - Pattern and rhythm generation
    // 
    pushCategoryColor(ModuleCategory::Seq);
    bool sequencersExpanded = ImGui::CollapsingHeader("Sequencers", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (sequencersExpanded) {
        addModuleButton("Sequencer", "sequencer");
        addModuleButton("Multi Sequencer", "multi_sequencer");
        addModuleButton("Tempo Clock", "tempo_clock");
        addModuleButton("Snapshot Sequencer", "snapshot_sequencer");
        addModuleButton("Stroke Sequencer", "stroke_sequencer");
    }
    
    // 
    // 6. MIDI - MIDI input/output and controllers
    // 
    pushCategoryColor(ModuleCategory::MIDI);
    bool midiExpanded = ImGui::CollapsingHeader("MIDI", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (midiExpanded) {
        addModuleButton("MIDI CV", "midi_cv");
        addModuleButton("MIDI Player", "midi_player");
        ImGui::Separator();
        addModuleButton("MIDI Faders", "midi_faders");
        addModuleButton("MIDI Knobs", "midi_knobs");
        addModuleButton("MIDI Buttons", "midi_buttons");
        addModuleButton("MIDI Jog Wheel", "midi_jog_wheel");
        addModuleButton("MIDI Pads", "midi_pads");
        ImGui::Separator();
        addModuleButton("MIDI Logger", "midi_logger");
    }
    
    // 
    // 7. ANALYSIS - Signal visualization and debugging
    // 
    pushCategoryColor(ModuleCategory::Analysis);
    bool analysisExpanded = ImGui::CollapsingHeader("Analysis", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (analysisExpanded) {
        addModuleButton("Scope", "scope");
        addModuleButton("Debug", "debug");
        addModuleButton("Input Debug", "input_debug");
        addModuleButton("Frequency Graph", "frequency_graph");
    }
    
    // 
    // 8. TTS - Text-to-Speech and vocal synthesis
    // 
    pushCategoryColor(ModuleCategory::TTS_Voice);
    bool ttsExpanded = ImGui::CollapsingHeader("TTS", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (ttsExpanded) {
        addModuleButton("TTS Performer", "tts_performer");
        addModuleButton("Vocal Tract Filter", "vocal_tract_filter");
    }
    
    // 
    // 9. SPECIAL - Physics, animation, and experimental
    // 
    pushCategoryColor(ModuleCategory::Special_Exp);
    bool specialExpanded = ImGui::CollapsingHeader("Special", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (specialExpanded) {
        addModuleButton("Physics", "physics");
        addModuleButton("Animation", "animation");
    }
    
    // 
    // 10. COMPUTER VISION - Video processing and analysis
    // 
    pushCategoryColor(ModuleCategory::OpenCV);
    bool openCVExpanded = ImGui::CollapsingHeader("Computer Vision", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (openCVExpanded) {
        ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "Sources:");
        addModuleButton("Webcam Loader", "webcam_loader");
        addModuleButton("Video File Loader", "video_file_loader");
        ImGui::Spacing();
        ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "Processors:");
        addModuleButton("Movement Detector", "movement_detector");
        addModuleButton("Human Detector", "human_detector");
        addModuleButton("Object Detector", "object_detector");
        addModuleButton("Pose Estimator", "pose_estimator");
        addModuleButton("Hand Tracker", "hand_tracker");
        addModuleButton("Face Tracker", "face_tracker");
        addModuleButton("Color Tracker", "color_tracker");
        addModuleButton("Contour Detector", "contour_detector");
        addModuleButton("Semantic Segmentation", "semantic_segmentation");
    }
    
    // 
    // 11. PLUGINS / VST - Third-party audio plugins
    // 
    pushCategoryColor(ModuleCategory::Plugin);
    bool pluginsExpanded = ImGui::CollapsingHeader("Plugins / VST", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (pluginsExpanded) {
        addPluginModules();
    }
    
    // 
    // 12. SYSTEM - Patch organization and system utilities
    // 
    pushCategoryColor(ModuleCategory::Sys);
    bool systemExpanded = ImGui::CollapsingHeader("System", ImGuiTreeNodeFlags_DefaultOpen);
    ImGui::PopStyleColor(3);
    if (systemExpanded) {
        addModuleButton("Meta", "meta");
        addModuleButton("Inlet", "inlet");
        addModuleButton("Outlet", "outlet");
        addModuleButton("Comment", "comment");
        addModuleButton("Recorder", "recorder");
        addModuleButton("VST Host", "vst_host");
        ImGui::Separator();
        addModuleButton("Best Practice", "best_practice");
    }
    
    } // End of Modules collapsing header

    // End the scrolling region
    ImGui::EndChild();

    ImGui::NextColumn();

    // --- DEFINITIVE FIX FOR PRESET DRAG-AND-DROP WITH VISUAL FEEDBACK ---
    // Step 1: Define canvas dimensions first (needed for the drop target)
    const ImU32 GRID_COLOR = IM_COL32(50, 50, 50, 255);
    const ImU32 GRID_ORIGIN_COLOR = IM_COL32(80, 80, 80, 255);
    const float GRID_SIZE = 64.0f;
    ImVec2 canvas_p0 = ImGui::GetCursorScreenPos();
    ImVec2 canvas_sz = ImGui::GetContentRegionAvail();
    ImVec2 canvas_p1 = ImVec2(canvas_p0.x + canvas_sz.x, canvas_p0.y + canvas_sz.y);

    // Step 2: Create a full-canvas invisible button to act as our drop area
    ImGui::SetCursorScreenPos(canvas_p0);
    ImGui::InvisibleButton("##canvas_drop_target", canvas_sz);

    // Step 3: Make this area a drop target with visual feedback
    if (ImGui::BeginDragDropTarget())
    {
        // Check if a preset payload is being hovered over the canvas
        if (const ImGuiPayload* payload = ImGui::AcceptDragDropPayload("DND_PRESET_PATH", ImGuiDragDropFlags_AcceptBeforeDelivery))
        {
            // Draw a semi-transparent overlay to show the canvas is a valid drop zone
            ImDrawList* drawList = ImGui::GetForegroundDrawList();
            drawList->AddRectFilled(canvas_p0, canvas_p1, IM_COL32(218, 165, 32, 80)); // Preset Gold color
            
            // Check if the mouse button was released to complete the drop
            if (payload->IsDelivery())
            {
                const char* path = (const char*)payload->Data;
                ImVec2 dropPos = ImGui::GetMousePos(); // Get the exact drop position
                mergePresetFromFile(juce::File(path), dropPos);
            }
        }
        ImGui::EndDragDropTarget();
    }
    // --- END OF DEFINITIVE FIX ---

    // Reset cursor position for subsequent drawing
    ImGui::SetCursorScreenPos(canvas_p0);

    // <<< ADD THIS ENTIRE BLOCK TO CACHE CONNECTION STATUS >>>
    std::unordered_set<int> connectedInputAttrs;
    std::unordered_set<int> connectedOutputAttrs;
    if (synth != nullptr)
    {
        for (const auto& c : synth->getConnectionsInfo())
        {
            int srcAttr = encodePinId({c.srcLogicalId, c.srcChan, false});
            connectedOutputAttrs.insert(srcAttr);

            int dstAttr = c.dstIsOutput ? 
                encodePinId({0, c.dstChan, true}) : 
                encodePinId({c.dstLogicalId, c.dstChan, true});
            connectedInputAttrs.insert(dstAttr);
        }
    }
    // <<< END OF BLOCK >>>

    // <<< ADD THIS BLOCK TO DEFINE COLORS >>>
    const ImU32 colPin = IM_COL32(150, 150, 150, 255); // Grey for disconnected
    const ImU32 colPinConnected = IM_COL32(120, 255, 120, 255); // Green for connected
    // <<< END OF BLOCK >>>

    // Pre-register is no longer needed - stateless encoding generates IDs on-the-fly
    // (Removed the old pre-registration loop)

    // --- BACKGROUND GRID AND COORDINATE DISPLAY ---
    // (Canvas dimensions already defined above in the drop target code)
    ImDrawList* draw_list = ImGui::GetBackgroundDrawList();
    ImVec2 panning = ImNodes::EditorContextGetPanning();

    // Draw grid lines
    for (float x = fmodf(panning.x, GRID_SIZE); x < canvas_sz.x; x += GRID_SIZE)
        draw_list->AddLine(ImVec2(canvas_p0.x + x, canvas_p0.y), ImVec2(canvas_p0.x + x, canvas_p0.y + canvas_sz.y), GRID_COLOR);
    for (float y = fmodf(panning.y, GRID_SIZE); y < canvas_sz.y; y += GRID_SIZE)
        draw_list->AddLine(ImVec2(canvas_p0.x, canvas_p0.y + y), ImVec2(canvas_p0.x + canvas_sz.x, canvas_p0.y + y), GRID_COLOR);

    // Draw thicker lines for the origin (0,0)
    ImVec2 origin_on_screen = ImVec2(canvas_p0.x + panning.x, canvas_p0.y + panning.y);
    draw_list->AddLine(ImVec2(origin_on_screen.x, canvas_p0.y), ImVec2(origin_on_screen.x, canvas_p1.y), GRID_ORIGIN_COLOR, 2.0f);
    draw_list->AddLine(ImVec2(canvas_p0.x, origin_on_screen.y), ImVec2(canvas_p1.x, origin_on_screen.y), GRID_ORIGIN_COLOR, 2.0f);

    // Draw scale markers every 400 grid units as a grid (not a cross)
    const float SCALE_INTERVAL = 400.0f;
    const ImU32 SCALE_TEXT_COLOR = IM_COL32(150, 150, 150, 80); // Reduced opacity
    ImDrawList* fg_draw_list = ImGui::GetForegroundDrawList();
    
    // X-axis scale markers - always at the bottom edge
    float gridLeft = -panning.x;
    float gridRight = canvas_sz.x - panning.x;
    int startX = (int)std::floor(gridLeft / SCALE_INTERVAL);
    int endX = (int)std::ceil(gridRight / SCALE_INTERVAL);
    
    for (int i = startX; i <= endX; ++i)
    {
        float gridX = i * SCALE_INTERVAL;
        float screenX = canvas_p0.x + panning.x + gridX;
        
        // Only draw if visible on screen
        if (screenX >= canvas_p0.x && screenX <= canvas_p1.x)
        {
            char label[16];
            snprintf(label, sizeof(label), "%.0f", gridX);
            // Always draw at bottom edge
            fg_draw_list->AddText(ImVec2(screenX + 2, canvas_p1.y - 45), SCALE_TEXT_COLOR, label);
        }
    }
    
    // Y-axis scale markers - always at the left edge
    float gridTop = -panning.y;
    float gridBottom = canvas_sz.y - panning.y;
    int startY = (int)std::floor(gridTop / SCALE_INTERVAL);
    int endY = (int)std::ceil(gridBottom / SCALE_INTERVAL);
    
    for (int i = startY; i <= endY; ++i)
    {
        float gridY = i * SCALE_INTERVAL;
        float screenY = canvas_p0.y + panning.y + gridY;
        
        // Only draw if visible on screen
        if (screenY >= canvas_p0.y && screenY <= canvas_p1.y)
        {
            char label[16];
            snprintf(label, sizeof(label), "%.0f", gridY);
            // Always draw at left edge
            fg_draw_list->AddText(ImVec2(canvas_p0.x + 5, screenY + 2), SCALE_TEXT_COLOR, label);
        }
    }

    // Mouse coordinate display overlay (bottom-left)
    ImVec2 mouseScreenPos = ImGui::GetMousePos();
    ImVec2 mouseGridPos = ImVec2(mouseScreenPos.x - canvas_p0.x - panning.x, mouseScreenPos.y - canvas_p0.y - panning.y);
    char posStr[32];
    snprintf(posStr, sizeof(posStr), "%.0f, %.0f", mouseGridPos.x, mouseGridPos.y);
    // Use the foreground draw list to ensure text is on top of everything
    // Position at bottom-left: canvas_p1.y is bottom edge, subtract text height plus padding
    ImGui::GetForegroundDrawList()->AddText(ImVec2(canvas_p0.x + 10, canvas_p1.y - 25), IM_COL32(200, 200, 200, 150), posStr);
    // --- END OF BACKGROUND GRID AND COORDINATE DISPLAY ---

    // Node canvas bound to the underlying model if available
    ImNodes::BeginNodeEditor();
    // Begin the editor

    // +++ ADD THIS LINE AT THE START OF THE RENDER LOOP +++
    attrPositions.clear(); // Clear the cache at the beginning of each frame.
    // Rebuild mod attribute mapping from currently drawn nodes only
    // modAttrToParam.clear(); // TODO: Remove when fully migrated
    // Track which attribute IDs were actually registered this frame
    std::unordered_set<int> availableAttrs;
    // Track duplicates to diagnose disappearing pins
    std::unordered_set<int> seenAttrs;
    auto linkIdOf = [this] (int srcAttr, int dstAttr) -> int
    {
        return getLinkId(srcAttr, dstAttr);
    };

    if (synth != nullptr)
    {
        // Apply any pending UI state restore (first frame after load)
        if (uiPending.isValid())
        {
            // Cache target positions to ensure they stick even if nodes are created later this frame
            auto nodes = uiPending;
for (int i = 0; i < nodes.getNumChildren(); ++i)
            {
                auto n = nodes.getChild(i);
if (! n.hasType("node")) continue;
                const int nid = (int) n.getProperty("id", 0);
                const float x = (float) n.getProperty("x", 0.0f);
const float y = (float) n.getProperty("y", 0.0f);
                if (!(x == 0.0f && y == 0.0f))
                    pendingNodePositions[nid] = ImVec2(x, y);
}
            uiPending = {};
}

        // Draw module nodes (exactly once per logical module)
        // Graph is now always in consistent state since we rebuild at frame start
        std::unordered_set<int> drawnNodes;
        for (const auto& mod : synth->getModulesInfo())
        {
            const juce::uint32 lid = mod.first;
const juce::String& type = mod.second;

            // Color-code modules by category (base colors)
            const auto moduleCategory = getModuleCategory(type);
            ImNodes::PushColorStyle(ImNodesCol_TitleBar, getImU32ForCategory(moduleCategory));
            ImNodes::PushColorStyle(ImNodesCol_TitleBarHovered, getImU32ForCategory(moduleCategory, true));
            ImNodes::PushColorStyle(ImNodesCol_TitleBarSelected, getImU32ForCategory(moduleCategory, true));

            // Highlight nodes participating in the hovered link (overrides category color)
            const bool isHoveredSource = (hoveredLinkSrcId != 0 && hoveredLinkSrcId == (juce::uint32) lid);
            const bool isHoveredDest   = (hoveredLinkDstId != 0 && hoveredLinkDstId == (juce::uint32) lid);
            if (isHoveredSource || isHoveredDest)
                ImNodes::PushColorStyle(ImNodesCol_TitleBar, IM_COL32(255, 220, 0, 255));

            // Visual feedback for muted nodes (overrides category color and hover)
            const bool isMuted = mutedNodeStates.count(lid) > 0;
            if (isMuted) {
                ImNodes::PushStyleVar(ImNodesStyleVar_NodePadding, ImVec2(8, 8));
                ImGui::PushStyleVar(ImGuiStyleVar_Alpha, 0.5f);
                ImNodes::PushColorStyle(ImNodesCol_TitleBar, IM_COL32(80, 80, 80, 255));
            }

            ImNodes::BeginNode ((int) lid);
            ImNodes::BeginNodeTitleBar();
            ImGui::TextUnformatted (type.toRawUTF8());
            ImNodes::EndNodeTitleBar();

            // Get node content width - check if module has custom size, otherwise use default
            float nodeContentWidth = 240.0f; // Default width
            if (auto* mp = synth->getModuleForLogical(lid))
            {
                ImVec2 customSize = mp->getCustomNodeSize();
                if (customSize.x > 0.0f) // Module specified a custom width
                {
                    nodeContentWidth = customSize.x;
                }
            }

            // Inline parameter controls per module type
            if (synth != nullptr)
            {
if (auto* mp = synth->getModuleForLogical (lid))
{
    ImGui::PushID ((int) lid);

    // This new lambda function checks if a parameter is being modulated
    auto isParamModulated = [&](const juce::String& paramId) -> bool {
        if (!synth) return false;
        if (auto* mp = synth->getModuleForLogical(lid))
        {
            int busIdx = -1, chInBus = -1;
            // Use the new standardized routing API on the module itself
            if (!mp->getParamRouting(paramId, busIdx, chInBus)) 
                return false;

            // Calculate the absolute channel index that the graph uses for this bus/channel pair
            const int absoluteChannelIndex = mp->getChannelIndexInProcessBlockBuffer(true, busIdx, chInBus);
            if (absoluteChannelIndex < 0) return false;
            
            // Scan the simple graph connections for a match
            for (const auto& c : synth->getConnectionsInfo())
            {
                if (c.dstLogicalId == lid && c.dstChan == absoluteChannelIndex)
                    return true;
            }
        }
        return false;
    };

    // Helper to read a live, modulated value if available (respects _mod alias)
    auto getLiveValueOr = [&](const juce::String& paramId, float fallback) -> float
    {
        if (!synth) return fallback;
        if (auto* mp = synth->getModuleForLogical(lid))
            return mp->getLiveParamValueFor(paramId + "_mod", paramId + "_live", fallback);
        return fallback;
    };

    // Create a new function that calls pushSnapshot
    auto onModificationEnded = [&](){ this->pushSnapshot(); };

    // --- SPECIAL RENDERING FOR SAMPLE LOADER ---
    if (auto* sampleLoader = dynamic_cast<SampleLoaderModuleProcessor*>(mp))
    {
        // First, draw the standard parameters (buttons, sliders, etc.)
        // We pass a modified onModificationEnded to avoid creating undo states while dragging.
        sampleLoader->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);

        // Now, handle the spectrogram texture and drawing
        juce::OpenGLTexture* texturePtr = nullptr;
        if (auto it = sampleLoaderTextureIds.find((int)lid); it != sampleLoaderTextureIds.end())
            texturePtr = it->second.get();

        juce::Image spectrogram = sampleLoader->getSpectrogramImage();
        if (spectrogram.isValid())
        {
            if (texturePtr == nullptr)
            {
                auto tex = std::make_unique<juce::OpenGLTexture>();
                texturePtr = tex.get();
                sampleLoaderTextureIds[(int)lid] = std::move(tex);
            }
            // Upload or update texture from JUCE image (handles format & parameters internally)
            texturePtr->loadImage(spectrogram);

            ImGui::Image((void*)(intptr_t) texturePtr->getTextureID(), ImVec2(nodeContentWidth, 100.0f));

            // Drag state is tracked per Sample Loader node to avoid cross-node interference
            static std::unordered_map<int,int> draggedHandleByNode; // lid -> -1,0,1
            int& draggedHandle = draggedHandleByNode[(int) lid];
            if (draggedHandle != 0 && draggedHandle != 1) draggedHandle = -1;
            ImGui::SetCursorScreenPos(ImGui::GetItemRectMin());
            ImGui::InvisibleButton("##spectrogram_interaction", ImVec2(nodeContentWidth, 100.0f));

            auto* drawList = ImGui::GetWindowDrawList();
            const ImVec2 rectMin = ImGui::GetItemRectMin();
            const ImVec2 rectMax = ImGui::GetItemRectMax();

            float startNorm = sampleLoader->getAPVTS().getRawParameterValue("rangeStart")->load();
            float endNorm = sampleLoader->getAPVTS().getRawParameterValue("rangeEnd")->load();

            // Use live telemetry values when modulated
            startNorm = sampleLoader->getLiveParamValueFor("rangeStart_mod", "rangeStart_live", startNorm);
            endNorm = sampleLoader->getLiveParamValueFor("rangeEnd_mod", "rangeEnd_live", endNorm);

            // Visual guard even when modulated
            const float kMinGap = 0.001f;
            startNorm = juce::jlimit(0.0f, 1.0f, startNorm);
            endNorm   = juce::jlimit(0.0f, 1.0f, endNorm);
            if (startNorm >= endNorm)
            {
                if (startNorm <= 1.0f - kMinGap)
                    endNorm = juce::jmin(1.0f, startNorm + kMinGap);
                else
                    startNorm = juce::jmax(0.0f, endNorm - kMinGap);
            }

            // --- FIX FOR BUG 1: Separate modulation checks for each handle ---
            bool startIsModulated = isParamModulated("rangeStart_mod");
            bool endIsModulated = isParamModulated("rangeEnd_mod");

            const bool itemHovered = ImGui::IsItemHovered();
            const bool itemActive  = ImGui::IsItemActive();
            if (itemHovered)
            {
                ImVec2 mousePos = ImGui::GetMousePos();
                float startHandleX = rectMin.x + startNorm * nodeContentWidth;
                float endHandleX = rectMin.x + endNorm * nodeContentWidth;

                bool canDragStart = !startIsModulated && (std::abs(mousePos.x - startHandleX) < 5);
                bool canDragEnd = !endIsModulated && (std::abs(mousePos.x - endHandleX) < 5);

                if (draggedHandle == -1 && (canDragStart || canDragEnd))
                {
                    ImGui::SetMouseCursor(ImGuiMouseCursor_ResizeEW);
                }

                if (ImGui::IsItemClicked())
                {
                    // Only allow dragging to start if the corresponding handle is not modulated
                    if (canDragStart && canDragEnd)
                        draggedHandle = (std::abs(mousePos.x - startHandleX) < std::abs(mousePos.x - endHandleX)) ? 0 : 1;
                    else if (canDragStart)
                        draggedHandle = 0;
                    else if (canDragEnd)
                        draggedHandle = 1;
                }
            }

            if (itemActive && ImGui::IsMouseReleased(0))
            {
                if (draggedHandle != -1) onModificationEnded();
                draggedHandle = -1;
            }

            // Handle the drag update, checking the specific modulation flag for the active handle
            if (itemActive && draggedHandle != -1 && ImGui::IsMouseDragging(0))
            {
                float newNormX = juce::jlimit(0.0f, 1.0f, (ImGui::GetMousePos().x - rectMin.x) / nodeContentWidth);
                if (draggedHandle == 0 && !startIsModulated)
                {
                    // Guard: start cannot be >= end
                    startNorm = juce::jmin(newNormX, endNorm - 0.001f);
                    sampleLoader->getAPVTS().getParameter("rangeStart")->setValueNotifyingHost(startNorm);
                }
                else if (draggedHandle == 1 && !endIsModulated)
                {
                    // Guard: end cannot be <= start
                    endNorm = juce::jmax(newNormX, startNorm + 0.001f);
                    sampleLoader->getAPVTS().getParameter("rangeEnd")->setValueNotifyingHost(endNorm);
                }
            }

            float startX = rectMin.x + startNorm * nodeContentWidth;
            float endX = rectMin.x + endNorm * nodeContentWidth;
            drawList->AddRectFilled(rectMin, ImVec2(startX, rectMax.y), IM_COL32(0, 0, 0, 120));
            drawList->AddRectFilled(ImVec2(endX, rectMin.y), rectMax, IM_COL32(0, 0, 0, 120));
            drawList->AddLine(ImVec2(startX, rectMin.y), ImVec2(startX, rectMax.y), IM_COL32(255, 255, 0, 255), 3.0f);
            drawList->AddLine(ImVec2(endX, rectMin.y), ImVec2(endX, rectMax.y), IM_COL32(255, 255, 0, 255), 3.0f);
        }
    }
    // --- SPECIAL RENDERING FOR AUDIO INPUT (MULTI-CHANNEL) ---
    else if (auto* audioIn = dynamic_cast<AudioInputModuleProcessor*>(mp))
    {
        auto& apvts = audioIn->getAPVTS();

        // --- Device Selectors ---
        juce::AudioDeviceManager::AudioDeviceSetup setup;
        deviceManager.getAudioDeviceSetup(setup);
        
        // Input Device
        juce::StringArray availableInputDevices;
        if (auto* deviceType = deviceManager.getAvailableDeviceTypes().getFirst()) {
            availableInputDevices = deviceType->getDeviceNames(true);
        }
        std::vector<const char*> inputDeviceItems;
        for (const auto& name : availableInputDevices) inputDeviceItems.push_back(name.toRawUTF8());
        int currentInputDeviceIndex = availableInputDevices.indexOf(setup.inputDeviceName);
        if (currentInputDeviceIndex < 0) currentInputDeviceIndex = 0;

        ImGui::PushItemWidth(nodeContentWidth);
        if (ImGui::Combo("Input Device", &currentInputDeviceIndex, inputDeviceItems.data(), (int)inputDeviceItems.size())) {
            if (currentInputDeviceIndex < availableInputDevices.size()) {
                setup.inputDeviceName = availableInputDevices[currentInputDeviceIndex];
                deviceManager.setAudioDeviceSetup(setup, true);
                onModificationEnded();
            }
        }

        // Output Device
        juce::StringArray availableOutputDevices;
        if (auto* deviceType = deviceManager.getAvailableDeviceTypes().getFirst()) {
            availableOutputDevices = deviceType->getDeviceNames(false);
        }
        std::vector<const char*> outputDeviceItems;
        for (const auto& name : availableOutputDevices) outputDeviceItems.push_back(name.toRawUTF8());
        int currentOutputDeviceIndex = availableOutputDevices.indexOf(setup.outputDeviceName);
        if (currentOutputDeviceIndex < 0) currentOutputDeviceIndex = 0;
        
        if (ImGui::Combo("Output Device", &currentOutputDeviceIndex, outputDeviceItems.data(), (int)outputDeviceItems.size())) {
            if (currentOutputDeviceIndex < availableOutputDevices.size()) {
                setup.outputDeviceName = availableOutputDevices[currentOutputDeviceIndex];
                deviceManager.setAudioDeviceSetup(setup, true);
                onModificationEnded();
            }
        }
        
        // --- Channel Count ---
        auto* numChannelsParam = static_cast<juce::AudioParameterInt*>(apvts.getParameter("numChannels"));
        int numChannels = numChannelsParam->get();
        if (ImGui::SliderInt("Channels", &numChannels, 1, AudioInputModuleProcessor::MAX_CHANNELS)) {
            *numChannelsParam = numChannels;
            onModificationEnded();
        }
        
        // --- Threshold Sliders ---
        auto* gateThreshParam = static_cast<juce::AudioParameterFloat*>(apvts.getParameter("gateThreshold"));
        float gateThresh = gateThreshParam->get();
        if (ImGui::SliderFloat("Gate Threshold", &gateThresh, 0.0f, 1.0f, "%.3f")) {
            *gateThreshParam = gateThresh;
            onModificationEnded();
        }
        
        auto* trigThreshParam = static_cast<juce::AudioParameterFloat*>(apvts.getParameter("triggerThreshold"));
        float trigThresh = trigThreshParam->get();
        if (ImGui::SliderFloat("Trigger Threshold", &trigThresh, 0.0f, 1.0f, "%.3f")) {
            *trigThreshParam = trigThresh;
            onModificationEnded();
        }
        
        ImGui::PopItemWidth();

        // --- Dynamic Channel Selectors & VU Meters ---
        auto hardwareChannels = deviceManager.getCurrentAudioDevice() ? deviceManager.getCurrentAudioDevice()->getInputChannelNames() : juce::StringArray{};
        if (!hardwareChannels.isEmpty())
        {
            std::vector<const char*> hwChannelItems;
            for (const auto& name : hardwareChannels) hwChannelItems.push_back(name.toRawUTF8());
            
            for (int i = 0; i < numChannels; ++i) {
                auto* mappingParam = static_cast<juce::AudioParameterInt*>(apvts.getParameter("channelMap" + juce::String(i)));
                int selectedHwChannel = mappingParam->get();
                selectedHwChannel = juce::jlimit(0, (int)hwChannelItems.size() - 1, selectedHwChannel);

                ImGui::PushID(i);
                ImGui::PushItemWidth(nodeContentWidth * 0.6f);
                if (ImGui::Combo(("Input for Out " + juce::String(i + 1)).toRawUTF8(), &selectedHwChannel, hwChannelItems.data(), (int)hwChannelItems.size())) {
                    *mappingParam = selectedHwChannel;
                    std::vector<int> newMapping(numChannels);
                    for (int j = 0; j < numChannels; ++j) {
                        auto* p = static_cast<juce::AudioParameterInt*>(apvts.getParameter("channelMap" + juce::String(j)));
                        newMapping[j] = p->get();
                    }
                    synth->setAudioInputChannelMapping(synth->getNodeIdForLogical(lid), newMapping);
                    onModificationEnded();
                }
                ImGui::PopItemWidth();

                ImGui::SameLine();
                
                // --- VU Meter with Threshold Lines ---
                float level = (i < (int)audioIn->channelLevels.size() && audioIn->channelLevels[i]) ? audioIn->channelLevels[i]->load() : 0.0f;
                ImVec2 meterSize(nodeContentWidth * 0.38f, ImGui::GetTextLineHeightWithSpacing() * 0.8f);
                ImGui::ProgressBar(level, meterSize, "");

                // Draw threshold lines on top of the progress bar
                ImVec2 p_min = ImGui::GetItemRectMin();
                ImVec2 p_max = ImGui::GetItemRectMax();
                ImDrawList* draw_list = ImGui::GetWindowDrawList();

                // Gate Threshold (Yellow)
                float gateLineX = p_min.x + gateThresh * (p_max.x - p_min.x);
                draw_list->AddLine(ImVec2(gateLineX, p_min.y), ImVec2(gateLineX, p_max.y), IM_COL32(255, 255, 0, 200), 2.0f);

                // Trigger Threshold (Orange)
                float trigLineX = p_min.x + trigThresh * (p_max.x - p_min.x);
                draw_list->AddLine(ImVec2(trigLineX, p_min.y), ImVec2(trigLineX, p_max.y), IM_COL32(255, 165, 0, 200), 2.0f);
                
                ImGui::PopID();
            }
        }
    }
    // --- SPECIAL RENDERING FOR SNAPSHOT SEQUENCER ---
    // Commented out - SnapshotSequencerModuleProcessor causing build errors
    /*else if (auto* snapshotSeq = dynamic_cast<SnapshotSequencerModuleProcessor*>(mp))
    {
        // First, draw the standard parameters (number of steps, etc.)
        snapshotSeq->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
        
        ImGui::Separator();
        ImGui::Text("Snapshot Management:");
        
        const int numSteps = 8; // Default, could read from parameter
        const int currentStepIndex = 0; // TODO: Get from module if exposed
        
        // Draw capture/clear buttons for each step
        for (int i = 0; i < numSteps; ++i)
        {
            ImGui::PushID(i);
            
            bool stored = snapshotSeq->isSnapshotStored(i);
            
            // Capture button
            if (ImGui::Button("Capture"))
            {
                // Get the current state of the whole synth
                juce::MemoryBlock currentState;
                synth->getStateInformation(currentState);
                
                // Store it in the snapshot sequencer
                snapshotSeq->setSnapshotForStep(i, currentState);
                
                // Create undo state
                pushSnapshot();
                
                juce::Logger::writeToLog("[SnapshotSeq UI] Captured snapshot for step " + juce::String(i));
            }
            
            ImGui::SameLine();
            
            // Clear button (only enabled if snapshot exists)
            if (!stored)
            {
                ImGui::BeginDisabled();
            }
            
            if (ImGui::Button("Clear"))
            {
                snapshotSeq->clearSnapshotForStep(i);
                pushSnapshot();
                juce::Logger::writeToLog("[SnapshotSeq UI] Cleared snapshot for step " + juce::String(i));
            }
            
            if (!stored)
            {
                ImGui::EndDisabled();
            }
            
            ImGui::PopID();
        }
    }*/
    // --- SPECIAL RENDERING FOR OPENCV MODULES (WITH VIDEO FEED) ---
    else if (auto* webcamModule = dynamic_cast<WebcamLoaderModule*>(mp))
    {
        juce::Image frame = webcamModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
            {
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            }
            juce::OpenGLTexture* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                // Calculate aspect ratio dynamically from the actual frame dimensions
                float nativeWidth = (float)frame.getWidth();
                float nativeHeight = (float)frame.getHeight();
                
                // Preserve the video's native aspect ratio (handles portrait, landscape, square, etc.)
                float aspectRatio = (nativeWidth > 0.0f) ? nativeHeight / nativeWidth : 0.75f; // Default to 4:3
                
                // Width is fixed at itemWidth (480px for video modules), height scales proportionally
                ImVec2 renderSize = ImVec2(nodeContentWidth, nodeContentWidth * aspectRatio);
                
                // Flip Y-coordinates to fix upside-down video (OpenCV uses top-left origin, OpenGL uses bottom-left)
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), renderSize, ImVec2(0, 1), ImVec2(1, 0));
            }
        }
        webcamModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* videoFileModule = dynamic_cast<VideoFileLoaderModule*>(mp))
    {
        juce::Image frame = videoFileModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
            {
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            }
            juce::OpenGLTexture* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                // Calculate aspect ratio dynamically from the actual frame dimensions
                float nativeWidth = (float)frame.getWidth();
                float nativeHeight = (float)frame.getHeight();
                
                // Preserve the video's native aspect ratio (handles portrait, landscape, square, etc.)
                float aspectRatio = (nativeWidth > 0.0f) ? nativeHeight / nativeWidth : 0.75f; // Default to 4:3
                
                // Width is fixed at itemWidth (480px for video modules), height scales proportionally
                ImVec2 renderSize = ImVec2(nodeContentWidth, nodeContentWidth * aspectRatio);
                
                // Flip Y-coordinates to fix upside-down video (OpenCV uses top-left origin, OpenGL uses bottom-left)
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), renderSize, ImVec2(0, 1), ImVec2(1, 0));
            }
        }
        videoFileModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* movementModule = dynamic_cast<MovementDetectorModule*>(mp))
    {
        juce::Image frame = movementModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
            {
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            }
            juce::OpenGLTexture* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                // Calculate aspect ratio dynamically from the actual frame dimensions
                float nativeWidth = (float)frame.getWidth();
                float nativeHeight = (float)frame.getHeight();
                
                // Preserve the video's native aspect ratio (handles portrait, landscape, square, etc.)
                float aspectRatio = (nativeWidth > 0.0f) ? nativeHeight / nativeWidth : 0.75f; // Default to 4:3
                
                // Width is fixed at itemWidth (480px for video modules), height scales proportionally
                ImVec2 renderSize = ImVec2(nodeContentWidth, nodeContentWidth * aspectRatio);
                
                // Flip Y-coordinates to fix upside-down video (OpenCV uses top-left origin, OpenGL uses bottom-left)
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), renderSize, ImVec2(0, 1), ImVec2(1, 0));
            }
        }
        movementModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* humanModule = dynamic_cast<HumanDetectorModule*>(mp))
    {
        juce::Image frame = humanModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
            {
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            }
            juce::OpenGLTexture* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                // Calculate aspect ratio dynamically from the actual frame dimensions
                float nativeWidth = (float)frame.getWidth();
                float nativeHeight = (float)frame.getHeight();
                
                // Preserve the video's native aspect ratio (handles portrait, landscape, square, etc.)
                float aspectRatio = (nativeWidth > 0.0f) ? nativeHeight / nativeWidth : 0.75f; // Default to 4:3
                
                // Width is fixed at itemWidth (480px for video modules), height scales proportionally
                ImVec2 renderSize = ImVec2(nodeContentWidth, nodeContentWidth * aspectRatio);
                
                // Flip Y-coordinates to fix upside-down video (OpenCV uses top-left origin, OpenGL uses bottom-left)
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), renderSize, ImVec2(0, 1), ImVec2(1, 0));
            }
        }
        humanModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* poseModule = dynamic_cast<PoseEstimatorModule*>(mp))
    {
        juce::Image frame = poseModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
            {
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            }
            juce::OpenGLTexture* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                // Calculate aspect ratio dynamically from the actual frame dimensions
                float nativeWidth = (float)frame.getWidth();
                float nativeHeight = (float)frame.getHeight();
                
                // Preserve the video's native aspect ratio (handles portrait, landscape, square, etc.)
                float aspectRatio = (nativeWidth > 0.0f) ? nativeHeight / nativeWidth : 0.75f; // Default to 4:3
                
                // Width is fixed at itemWidth (480px for video modules), height scales proportionally
                ImVec2 renderSize = ImVec2(nodeContentWidth, nodeContentWidth * aspectRatio);
                
                // Flip Y-coordinates to fix upside-down video (OpenCV uses top-left origin, OpenGL uses bottom-left)
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), renderSize, ImVec2(0, 1), ImVec2(1, 0));
            }
        }
        poseModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* colorModule = dynamic_cast<ColorTrackerModule*>(mp))
    {
        juce::Image frame = colorModule->getLatestFrame();
        if (!frame.isNull())
        {
            static std::map<int, int> hoverRadiusByNode; // logicalId -> radius (half-size), default 2 => 5x5
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            auto* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                float ar = (float)frame.getHeight() / juce::jmax(1.0f, (float)frame.getWidth());
                ImVec2 size(nodeContentWidth, nodeContentWidth * ar);
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), size, ImVec2(0,1), ImVec2(1,0));

                // Handle color picker clicks when active
                if (colorModule->isPickerActive() && ImGui::IsItemHovered())
                {
                    ImGui::SetTooltip("Click to pick a color from the video");
                    if (ImGui::IsMouseClicked(ImGuiMouseButton_Left))
                    {
                        ImVec2 mousePos = ImGui::GetMousePos();
                        ImVec2 itemMin = ImGui::GetItemRectMin();
                        ImVec2 itemSize = ImGui::GetItemRectSize();
                        float nx = (mousePos.x - itemMin.x) / itemSize.x;
                        float ny = (mousePos.y - itemMin.y) / itemSize.y;
                        nx = juce::jlimit(0.0f, 1.0f, nx);
                        ny = juce::jlimit(0.0f, 1.0f, ny);
                        // Use ny directly (no flip) to align clicks with displayed image
                        int px = (int)juce::jlimit(0.0f, (float)frame.getWidth()  - 1.0f, nx * (float)frame.getWidth());
                        int py = (int)juce::jlimit(0.0f, (float)frame.getHeight() - 1.0f, ny * (float)frame.getHeight());
                        juce::Logger::writeToLog(juce::String("[ColorTracker][UI] nx=") + juce::String(nx, 3) + ", ny=" + juce::String(ny, 3) +
                                                  ", px=" + juce::String(px) + ", py=" + juce::String(py));
                        colorModule->addColorAt(px, py);
                        colorModule->exitPickerMode();
                    }
                }

                // Hover preview: median/average color swatch and scroll-wheel radius control
                if (ImGui::IsItemHovered())
                {
                    // Update radius by mouse wheel
                    int& rad = hoverRadiusByNode[(int)lid]; if (rad <= 0) rad = 2;
                    float wheel = ImGui::GetIO().MouseWheel;
                    if (wheel != 0.0f)
                    {
                        rad += (wheel > 0) ? 1 : -1;
                        rad = juce::jlimit(1, 30, rad); // (2*rad+1)^2 window, max 61x61
                    }

                    // Map mouse to pixel
                    ImVec2 mousePos = ImGui::GetMousePos();
                    ImVec2 itemMin = ImGui::GetItemRectMin();
                    ImVec2 itemSize = ImGui::GetItemRectSize();
                    float nx = (mousePos.x - itemMin.x) / itemSize.x;
                    float ny = (mousePos.y - itemMin.y) / itemSize.y;
                    nx = juce::jlimit(0.0f, 1.0f, nx);
                    ny = juce::jlimit(0.0f, 1.0f, ny);
                    int cx = (int)juce::jlimit(0.0f, (float)frame.getWidth()  - 1.0f, nx * (float)frame.getWidth());
                    int cy = (int)juce::jlimit(0.0f, (float)frame.getHeight() - 1.0f, ny * (float)frame.getHeight());

                    // Sample ROI from juce::Image
                    std::vector<int> vr, vg, vb; vr.reserve((2*rad+1)*(2*rad+1)); vg.reserve(vr.capacity()); vb.reserve(vr.capacity());
                    juce::Image::BitmapData bd(frame, juce::Image::BitmapData::readOnly);
                    auto clampi = [](int v, int lo, int hi){ return (v < lo) ? lo : (v > hi ? hi : v); };
                    for (int y = cy - rad; y <= cy + rad; ++y)
                    {
                        int yy = clampi(y, 0, frame.getHeight()-1);
                        const juce::PixelARGB* row = (const juce::PixelARGB*)(bd.getLinePointer(yy));
                        for (int x = cx - rad; x <= cx + rad; ++x)
                        {
                            int xx = clampi(x, 0, frame.getWidth()-1);
                            const juce::PixelARGB& p = row[xx];
                            vr.push_back(p.getRed());
                            vg.push_back(p.getGreen());
                            vb.push_back(p.getBlue());
                        }
                    }
                    auto median = [](std::vector<int>& v){ std::nth_element(v.begin(), v.begin()+v.size()/2, v.end()); return v[v.size()/2]; };
                    int mr = median(vr), mg = median(vg), mb = median(vb);
                    juce::Colour mc((juce::uint8)mr, (juce::uint8)mg, (juce::uint8)mb);
                    float h = mc.getHue(), s = mc.getSaturation(), b = mc.getBrightness();

                    // Tooltip near cursor with swatch and numbers
                    ImGui::BeginTooltip();
                    ImGui::Text("(%d,%d) rad=%d", cx, cy, rad);
                    ImGui::ColorButton("##hoverSwatch", ImVec4(mc.getFloatRed(), mc.getFloatGreen(), mc.getFloatBlue(), 1.0f), 0, ImVec2(22,22));
                    ImGui::SameLine();
                    ImGui::Text("RGB %d,%d,%d\nHSV %d,%d,%d", mr, mg, mb, (int)(h*180.0f), (int)(s*255.0f), (int)(b*255.0f));
                    ImGui::EndTooltip();

                    // Textual summary under the image (lightweight)
                    ImGui::TextDisabled("Hover RGB %d,%d,%d  HSV %d,%d,%d  rad=%d", mr, mg, mb, (int)(h*180.0f), (int)(s*255.0f), (int)(b*255.0f), rad);
                }
            }
        }
        colorModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* contourModule = dynamic_cast<ContourDetectorModule*>(mp))
    {
        juce::Image frame = contourModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            auto* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                float ar = (float)frame.getHeight() / juce::jmax(1.0f, (float)frame.getWidth());
                ImVec2 size(nodeContentWidth, nodeContentWidth * ar);
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), size, ImVec2(0,1), ImVec2(1,0));
            }
        }
        contourModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* segModule = dynamic_cast<SemanticSegmentationModule*>(mp))
    {
        juce::Image frame = segModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            auto* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                float ar = (float)frame.getHeight() / juce::jmax(1.0f, (float)frame.getWidth());
                ImVec2 size(nodeContentWidth, nodeContentWidth * ar);
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), size, ImVec2(0,1), ImVec2(1,0));
            }
        }
        segModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* objModule = dynamic_cast<ObjectDetectorModule*>(mp))
    {
        juce::Image frame = objModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            auto* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                float ar = (float)frame.getHeight() / juce::jmax(1.0f, (float)frame.getWidth());
                ImVec2 size(nodeContentWidth, nodeContentWidth * ar);
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), size, ImVec2(0,1), ImVec2(1,0));
            }
        }
        objModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* handModule = dynamic_cast<HandTrackerModule*>(mp))
    {
        juce::Image frame = handModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
            {
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            }
            juce::OpenGLTexture* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                float nativeWidth = (float)frame.getWidth();
                float nativeHeight = (float)frame.getHeight();
                float aspectRatio = (nativeWidth > 0.0f) ? nativeHeight / nativeWidth : 0.75f;
                ImVec2 renderSize = ImVec2(nodeContentWidth, nodeContentWidth * aspectRatio);
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), renderSize, ImVec2(0, 1), ImVec2(1, 0));
            }
        }
        handModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else if (auto* faceModule = dynamic_cast<FaceTrackerModule*>(mp))
    {
        juce::Image frame = faceModule->getLatestFrame();
        if (!frame.isNull())
        {
            if (visionModuleTextures.find((int)lid) == visionModuleTextures.end())
            {
                visionModuleTextures[(int)lid] = std::make_unique<juce::OpenGLTexture>();
            }
            juce::OpenGLTexture* texture = visionModuleTextures[(int)lid].get();
            texture->loadImage(frame);
            if (texture->getTextureID() != 0)
            {
                float nativeWidth = (float)frame.getWidth();
                float nativeHeight = (float)frame.getHeight();
                float aspectRatio = (nativeWidth > 0.0f) ? nativeHeight / nativeWidth : 0.75f;
                ImVec2 renderSize = ImVec2(nodeContentWidth, nodeContentWidth * aspectRatio);
                ImGui::Image((void*)(intptr_t)texture->getTextureID(), renderSize, ImVec2(0, 1), ImVec2(1, 0));
            }
        }
        faceModule->drawParametersInNode(nodeContentWidth, isParamModulated, onModificationEnded);
    }
    else
    {
        mp->drawParametersInNode (nodeContentWidth, isParamModulated, onModificationEnded);
    }
    ImGui::Spacing();
    ImGui::PopID();
}
            }

            // IO per module type via helpers
            NodePinHelpers helpers;
            
            // Helper to draw right-aligned text within a node's content width
            // From imnodes examples (color_node_editor.cpp:353, save_load.cpp:77, multi_editor.cpp:73):
            // Use ImGui::Indent() for right-alignment - this is the CORRECT ImNodes pattern!
            auto rightLabelWithinWidth = [&](const char* txt, float nodeContentWidth)
            {
                const ImVec2 textSize = ImGui::CalcTextSize(txt);
                
                // Indent by (nodeWidth - textWidth) to right-align the text
                // CRITICAL: Must call Unindent() to prevent indent from persisting!
                const float indentAmount = juce::jmax(0.0f, nodeContentWidth - textSize.x);
                ImGui::Indent(indentAmount);
                ImGui::TextUnformatted(txt);
                ImGui::Unindent(indentAmount);  // Reset indent!
            };
            helpers.drawAudioInputPin = [&](const char* label, int channel)
            {
                int attr = encodePinId({lid, channel, true});
                seenAttrs.insert(attr);
                availableAttrs.insert(attr);

                // Get pin data type for color coding
                PinID pinId = { lid, channel, true, false, "" };
                PinDataType pinType = this->getPinDataTypeForPin(pinId);
                unsigned int pinColor = this->getImU32ForType(pinType);

                bool isConnected = connectedInputAttrs.count(attr) > 0;
                ImNodes::PushColorStyle(ImNodesCol_Pin, isConnected ? colPinConnected : pinColor);

                ImNodes::BeginInputAttribute(attr); ImGui::TextUnformatted(label); ImNodes::EndInputAttribute();

                // --- THIS IS THE DEFINITIVE FIX ---
                // Get the bounding box of the pin circle that was just drawn.
                ImVec2 pinMin = ImGui::GetItemRectMin();
                ImVec2 pinMax = ImGui::GetItemRectMax();
                // Calculate the exact center and cache it.
                float centerX = (pinMin.x + pinMax.x) * 0.5f;
                float centerY = (pinMin.y + pinMax.y) * 0.5f;
                attrPositions[attr] = ImVec2(centerX, centerY);
                // --- END OF FIX ---

                ImNodes::PopColorStyle(); // Restore default color

                if (ImGui::IsItemHovered())
                {
                    ImGui::BeginTooltip();
                    if (isConnected) {
                        ImGui::TextColored(ImVec4(0.5f, 1.0f, 0.5f, 1.0f), "Connected");
                        // Find which output this input is connected to and show source info
                        for (const auto& c : synth->getConnectionsInfo())
                        {
                            bool isConnectedToThisPin = (!c.dstIsOutput && c.dstLogicalId == lid && c.dstChan == channel) || (c.dstIsOutput && lid == 0 && c.dstChan == channel);
                            if (isConnectedToThisPin)
                            {
                                if (auto* srcMod = synth->getModuleForLogical(c.srcLogicalId))
                                {
                                    float value = srcMod->getOutputChannelValue(c.srcChan);
                                    ImGui::Text("From %u:%d", c.srcLogicalId, c.srcChan);
                                    ImGui::Text("Value: %.3f", value);
                                }
                                break; 
                            }
                        }
                    } else {
                        ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "Not Connected");
                    }
                    // Show pin data type
                    ImGui::Text("Type: %s", this->pinDataTypeToString(pinType));
                    ImGui::EndTooltip();
                }
            };

                // NEW CLEAN OUTPUT PIN TEXT FUNCTION - FIXED SPACING
                helpers.drawAudioOutputPin = [&](const char* label, int channel)
                {
                    const int attr = encodePinId({(juce::uint32)lid, channel, false});
                    seenAttrs.insert(attr);
                    availableAttrs.insert(attr);

                    PinID pinId = {(juce::uint32)lid, channel, false, false, ""};
                    PinDataType pinType = this->getPinDataTypeForPin(pinId);
                    unsigned int pinColor = this->getImU32ForType(pinType);
                    bool isConnected = connectedOutputAttrs.count(attr) > 0;

                    ImNodes::PushColorStyle(ImNodesCol_Pin, isConnected ? colPinConnected : pinColor);

                    // EXACT OFFICIAL PATTERN: Text right-aligned, pin touches text edge
                    ImNodes::BeginOutputAttribute(attr);
                    const float label_width = ImGui::CalcTextSize(label).x;
                    ImGui::Indent(nodeContentWidth - label_width);  // Right-align to content width
                    ImGui::TextUnformatted(label);
                    ImGui::Unindent(nodeContentWidth - label_width);
                    ImNodes::EndOutputAttribute();

                    // Cache pin center
                    {
                        ImVec2 pinMin = ImGui::GetItemRectMin();
                        ImVec2 pinMax = ImGui::GetItemRectMax();
                        float centerY = (pinMin.y + pinMax.y) * 0.5f;
                        float x_pos   = pinMax.x;
                        attrPositions[attr] = ImVec2(x_pos, centerY);
                    }

                    ImNodes::PopColorStyle();

                    if (ImGui::IsItemHovered())
                    {
                        ImGui::BeginTooltip();
                        if (isConnected) {
                            ImGui::TextColored(ImVec4(0.5f, 1.0f, 0.5f, 1.0f), "Connected");
                        } else {
                            ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "Not Connected");
                        }
                        ImGui::Text("Type: %s", this->pinDataTypeToString(pinType));
                        if (auto* mp = synth->getModuleForLogical(lid))
                        {
                            float value = mp->getOutputChannelValue(channel);
                            ImGui::Text("Value: %.3f", value);
                        }
                        ImGui::EndTooltip();
                    }
                };

            // ADD THE NEW drawParallelPins HELPER
            helpers.drawParallelPins = [&](const char* inLabel, int inChannel, const char* outLabel, int outChannel)
            {
                // 3-column layout: [InputPin] [Right-aligned Output Label] [Output Pin]
                ImGui::PushID((inChannel << 16) ^ outChannel ^ lid);
                ImGui::Columns(3, "parallel_io_layout", false);

                const float pinW = 18.0f;
                const float spacing = ImGui::GetStyle().ItemSpacing.x;
                // CRITICAL FIX: Use stable nodeContentWidth to set ALL column widths explicitly
                // This prevents the feedback loop that causes position-dependent node scaling
                
                // Calculate column widths to fill exactly nodeContentWidth
                float inTextW = inLabel ? ImGui::CalcTextSize(inLabel).x : 0.0f;
                float inColW = inLabel ? (inTextW + pinW + spacing) : 0.0f;  // Input label + pin + spacing
                float outPinColW = 20.0f;  // Output pin column (fixed narrow width)
                float labelColW = nodeContentWidth - inColW - outPinColW - spacing;  // Middle fills remaining space

                ImGui::SetColumnWidth(0, inColW);
                ImGui::SetColumnWidth(1, labelColW);
                ImGui::SetColumnWidth(2, outPinColW);

                // Column 0: Input pin with label
                if (inLabel != nullptr)
                {
                    int inAttr = encodePinId({lid, inChannel, true});
                    seenAttrs.insert(inAttr);
                    availableAttrs.insert(inAttr);
                    PinID pinId = { lid, inChannel, true, false, "" };
                    PinDataType pinType = this->getPinDataTypeForPin(pinId);
                    unsigned int pinColor = this->getImU32ForType(pinType);
                    bool isConnected = connectedInputAttrs.count(inAttr) > 0;
                    ImNodes::PushColorStyle(ImNodesCol_Pin, isConnected ? colPinConnected : pinColor);
                    ImNodes::BeginInputAttribute(inAttr);
                    ImGui::TextUnformatted(inLabel);
                    ImNodes::EndInputAttribute();
                    ImNodes::PopColorStyle();
                }

                // Column 1: Output label (right-aligned within this column)
                ImGui::NextColumn();
                if (outLabel != nullptr)
                {
                    // EXACT OFFICIAL PATTERN: Same as regular output pins
                    const float textW = ImGui::CalcTextSize(outLabel).x;
                    ImGui::Indent(labelColW - textW);  // Right-align to column width
                    ImGui::TextUnformatted(outLabel);
                    ImGui::Unindent(labelColW - textW);
                }

                // Column 2: Output pin
                ImGui::NextColumn();
                if (outLabel != nullptr)
                {
                    int outAttr = encodePinId({lid, outChannel, false});
                    seenAttrs.insert(outAttr);
                    availableAttrs.insert(outAttr);
                    PinID pinId = { lid, outChannel, false, false, "" };
                    PinDataType pinType = this->getPinDataTypeForPin(pinId);
                    unsigned int pinColor = this->getImU32ForType(pinType);
                    bool isConnected = connectedOutputAttrs.count(outAttr) > 0;
                    ImNodes::PushColorStyle(ImNodesCol_Pin, isConnected ? colPinConnected : pinColor);
                    ImNodes::BeginOutputAttribute(outAttr);
                    ImGui::Dummy(ImVec2(1.0f, ImGui::GetTextLineHeight()));
                    ImNodes::EndOutputAttribute();

                    // Cache pin center
                    ImVec2 pinMin = ImGui::GetItemRectMin();
                    ImVec2 pinMax = ImGui::GetItemRectMax();
                    float yCenter = pinMin.y + (pinMax.y - pinMin.y) * 0.5f;
                    float xPos = pinMax.x;
                    attrPositions[outAttr] = ImVec2(xPos, yCenter);
                    ImNodes::PopColorStyle();
                }

                // Restore to single column for the next row
                ImGui::Columns(1);
                ImGui::PopID();
            };

            // --- DYNAMIC PIN FIX ---
            // Add a new helper that uses dynamic pin information from modules
            helpers.drawIoPins = [&](ModuleProcessor* module) {
                if (!module) return;
                const auto logicalId = module->getLogicalId();
                const auto moduleType = synth->getModuleTypeForLogical(logicalId);

                // 1. Get dynamic pins from the module itself.
                auto dynamicInputs = module->getDynamicInputPins();
                auto dynamicOutputs = module->getDynamicOutputPins();

                // 2. Get static pins from the database as a fallback.
                const auto& pinDb = getModulePinDatabase();
                auto pinInfoIt = pinDb.find(moduleType.toLowerCase());
                const bool hasStaticPinInfo = (pinInfoIt != pinDb.end());
                const auto& staticPinInfo = hasStaticPinInfo ? pinInfoIt->second : ModulePinInfo{};

                // 3. If the module has dynamic pins, use the new system
                const bool hasDynamicPins = !dynamicInputs.empty() || !dynamicOutputs.empty();
                
                if (hasDynamicPins)
                {
                    // Draw inputs (dynamic if available, otherwise static)
                    if (!dynamicInputs.empty())
                    {
                        for (const auto& pin : dynamicInputs)
                        {
                            helpers.drawAudioInputPin(pin.name.toRawUTF8(), pin.channel);
                        }
                    }
                    else
                    {
                        for (const auto& pin : staticPinInfo.audioIns)
                        {
                            helpers.drawAudioInputPin(pin.name.toRawUTF8(), pin.channel);
                        }
                    }
                    
                    // Draw outputs (dynamic if available, otherwise static)
                    if (!dynamicOutputs.empty())
                    {
                        for (const auto& pin : dynamicOutputs)
                        {
                            helpers.drawAudioOutputPin(pin.name.toRawUTF8(), pin.channel);
                        }
                    }
                    else
                    {
                        for (const auto& pin : staticPinInfo.audioOuts)
                        {
                            helpers.drawAudioOutputPin(pin.name.toRawUTF8(), pin.channel);
                        }
                    }
                }
                else
                {
                    // 4. Otherwise, fall back to the module's custom drawIoPins implementation
                    module->drawIoPins(helpers);
                }
            };
            // --- END OF DYNAMIC PIN FIX ---

            // Delegate per-module IO pin drawing
            if (synth != nullptr)
                if (auto* mp = synth->getModuleForLogical (lid))
                    helpers.drawIoPins(mp);

            // Optional per-node right-click popup
            if (ImGui::IsItemHovered() && ImGui::IsMouseReleased(ImGuiMouseButton_Right))
            {
                selectedLogicalId = (int) lid;
                ImGui::OpenPopup("NodeActionPopup");
            }

            // Legacy per-type IO drawing removed; delegated to module implementations via helpers

            ImNodes::EndNode();
            
            // Cache position for snapshot safety
            // Graph is always in consistent state since we rebuild at frame start
            lastKnownNodePositions[(int)lid] = ImNodes::GetNodeGridSpacePos((int)lid);
            
            // Pop muted node styles (in reverse order of push)
            if (isMuted) {
                ImNodes::PopColorStyle();      // Mute TitleBar
                ImGui::PopStyleVar();          // Alpha
                ImNodes::PopStyleVar();        // NodePadding
            }
            
            // Pop hover highlight color
            if (isHoveredSource || isHoveredDest)
                ImNodes::PopColorStyle();      // Hover TitleBar
            
            // Pop category colors (in reverse order of push)
            ImNodes::PopColorStyle();          // TitleBarSelected
            ImNodes::PopColorStyle();          // TitleBarHovered
            ImNodes::PopColorStyle();          // TitleBar
            
            // Apply pending placement if queued
            if (auto itS = pendingNodeScreenPositions.find((int) lid); itS != pendingNodeScreenPositions.end())
            {
                ImNodes::SetNodeScreenSpacePos((int) lid, itS->second);
                pendingNodeScreenPositions.erase(itS);
            }
        if (auto it = pendingNodePositions.find((int) lid); it != pendingNodePositions.end())
        {
            // Apply saved position once; do not write (0,0) defaults
            const ImVec2 p = it->second;
            if (!(p.x == 0.0f && p.y == 0.0f))
            {
                ImNodes::SetNodeGridSpacePos((int) lid, p);
                juce::Logger::writeToLog("[PositionRestore] Applied pending position for node " + juce::String((int)lid) + ": (" + juce::String(p.x) + ", " + juce::String(p.y) + ")");
            }
            pendingNodePositions.erase(it);
        }
            // Apply pending size if queued (for Comment nodes to prevent feedback loop)
            if (auto itSize = pendingNodeSizes.find((int) lid); itSize != pendingNodeSizes.end())
            {
                // Store the desired size in the Comment module itself
                if (auto* comment = dynamic_cast<CommentModuleProcessor*>(synth->getModuleForLogical((juce::uint32)lid)))
                {
                    comment->nodeWidth = itSize->second.x;
                    comment->nodeHeight = itSize->second.y;
                }
                pendingNodeSizes.erase(itSize);
            }
            drawnNodes.insert((int) lid);
        }

        // Node action popup (Delete / Duplicate)
        bool triggerInsertMixer = false;
        if (ImGui::BeginPopup("NodeActionPopup"))
        {
            if (ImGui::MenuItem("Delete") && selectedLogicalId != 0 && selectedLogicalId != 999)
            {
                mutedNodeStates.erase((juce::uint32)selectedLogicalId); // Clean up muted state if exists
                synth->removeModule (synth->getNodeIdForLogical ((juce::uint32) selectedLogicalId));
                graphNeedsRebuild = true;
                // Post-state snapshot
                pushSnapshot();
                selectedLogicalId = 0;
            }
            if (ImGui::MenuItem("Duplicate") && selectedLogicalId != 0)
            {
                const juce::String type = getTypeForLogical ((juce::uint32) selectedLogicalId);
                if (! type.isEmpty())
                {
                    auto newNodeId = synth->addModule (type);
                    graphNeedsRebuild = true;
                    if (auto* src = synth->getModuleForLogical ((juce::uint32) selectedLogicalId))
                        if (auto* dst = synth->getModuleForLogical (synth->getLogicalIdForNode(newNodeId)))
                            dst->getAPVTS().replaceState (src->getAPVTS().copyState());
                    ImVec2 pos = ImNodes::GetNodeGridSpacePos (selectedLogicalId);
                    ImNodes::SetNodeGridSpacePos ((int) synth->getLogicalIdForNode(newNodeId), ImVec2 (pos.x + 40.0f, pos.y + 40.0f));
                    // Post-state snapshot after duplication and position
                    pushSnapshot();
                }
            }
            if (ImGui::MenuItem("Insert Mixer", "Ctrl+T") && selectedLogicalId != 0) { triggerInsertMixer = true; }
            ImGui::EndPopup();
        }

        // Shortcut: Ctrl+T to insert a Mixer after selected node and reroute
        // Debounced Ctrl+T
        const bool ctrlDown = ImGui::GetIO().KeyCtrl;
        if (!ctrlDown) {
            mixerShortcutCooldown = false;
            insertNodeShortcutCooldown = false;
        }
        // Ctrl+R: Record Output
        if (ctrlDown && ImGui::IsKeyPressed(ImGuiKey_R, false))
        {
            handleRecordOutput();
        }
        
        if ((triggerInsertMixer || (selectedLogicalId != 0 && ctrlDown && ImGui::IsKeyPressed(ImGuiKey_T))) && !mixerShortcutCooldown)
        {
            mixerShortcutCooldown = true; // Prevent re-triggering in the same frame
            const juce::uint32 srcLid = (juce::uint32) selectedLogicalId;

            juce::Logger::writeToLog("--- [InsertMixer] Start ---");
            juce::Logger::writeToLog("[InsertMixer] Selected Node Logical ID: " + juce::String(srcLid));

            auto srcNodeId = synth->getNodeIdForLogical(srcLid);
            if (srcNodeId.uid == 0) 
            {
                juce::Logger::writeToLog("[InsertMixer] ABORT: Source node with logical ID " + juce::String(srcLid) + " is invalid or could not be found.");
            } 
            else 
            {
                // 1. Collect all outgoing connections from the selected node
                std::vector<ModularSynthProcessor::ConnectionInfo> outgoingConnections;
                for (const auto& c : synth->getConnectionsInfo()) {
                    if (c.srcLogicalId == srcLid) {
                        outgoingConnections.push_back(c);
                    }
                }
                juce::Logger::writeToLog("[InsertMixer] Found " + juce::String(outgoingConnections.size()) + " outgoing connections to reroute.");
                for (const auto& c : outgoingConnections) {
                    juce::String destStr = c.dstIsOutput ? "Main Output" : "Node " + juce::String(c.dstLogicalId);
                    juce::Logger::writeToLog("  - Stored connection: [Src: " + juce::String(c.srcLogicalId) + ":" + juce::String(c.srcChan) + "] -> [Dst: " + destStr + ":" + juce::String(c.dstChan) + "]");
                }

                // 2. Create and position the new mixer node intelligently
                auto mixNodeIdGraph = synth->addModule("mixer");
                const juce::uint32 mixLid = synth->getLogicalIdForNode(mixNodeIdGraph);
                
                ImVec2 srcPos = ImNodes::GetNodeGridSpacePos(selectedLogicalId);
                ImVec2 avgDestPos = srcPos; // Default to source pos if no outputs
                
                if (!outgoingConnections.empty())
                {
                    float totalX = 0.0f, totalY = 0.0f;
                    for (const auto& c : outgoingConnections)
                    {
                        int destId = c.dstIsOutput ? 0 : (int)c.dstLogicalId;
                        ImVec2 pos = ImNodes::GetNodeGridSpacePos(destId);
                        totalX += pos.x;
                        totalY += pos.y;
                    }
                    avgDestPos = ImVec2(totalX / outgoingConnections.size(), totalY / outgoingConnections.size());
                }
                else
                {
                    // If there are no outgoing connections, place it to the right
                    avgDestPos.x += 600.0f;
                }
                
                // Place the new mixer halfway between the source and the average destination
                pendingNodePositions[(int)mixLid] = ImVec2((srcPos.x + avgDestPos.x) * 0.5f, (srcPos.y + avgDestPos.y) * 0.5f);
                juce::Logger::writeToLog("[InsertMixer] Added new Mixer. Logical ID: " + juce::String(mixLid) + ", Node ID: " + juce::String(mixNodeIdGraph.uid));

                // 3. Disconnect all original outgoing links
                juce::Logger::writeToLog("[InsertMixer] Disconnecting original links...");
                for (const auto& c : outgoingConnections) {
                    auto currentSrcNodeId = synth->getNodeIdForLogical(c.srcLogicalId);
                    auto dstNodeId = c.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(c.dstLogicalId);

                    if (currentSrcNodeId.uid != 0 && dstNodeId.uid != 0) {
                        bool success = synth->disconnect(currentSrcNodeId, c.srcChan, dstNodeId, c.dstChan);
                        juce::Logger::writeToLog("  - Disconnecting [" + juce::String(currentSrcNodeId.uid) + ":" + juce::String(c.srcChan) + "] -> [" + juce::String(dstNodeId.uid) + ":" + juce::String(c.dstChan) + "]... " + (success ? "SUCCESS" : "FAILED"));
                    } else {
                        juce::Logger::writeToLog("  - SKIPPING Disconnect due to invalid node ID.");
                    }
                }

                // 4. Connect the source node to the new mixer's first input
                juce::Logger::writeToLog("[InsertMixer] Connecting source node to new mixer...");
                bool c1 = synth->connect(srcNodeId, 0, mixNodeIdGraph, 0); // L to In A L
                juce::Logger::writeToLog("  - Connecting [" + juce::String(srcNodeId.uid) + ":0] -> [" + juce::String(mixNodeIdGraph.uid) + ":0]... " + (c1 ? "SUCCESS" : "FAILED"));
                bool c2 = synth->connect(srcNodeId, 1, mixNodeIdGraph, 1); // R to In A R
                juce::Logger::writeToLog("  - Connecting [" + juce::String(srcNodeId.uid) + ":1] -> [" + juce::String(mixNodeIdGraph.uid) + ":1]... " + (c2 ? "SUCCESS" : "FAILED"));


                // 5. Connect the mixer's output to all the original destinations (maintaining the chain)
                juce::Logger::writeToLog("[InsertMixer] Connecting mixer to original destinations to maintain chain...");
                if (outgoingConnections.empty()) {
                    juce::Logger::writeToLog("  - No original outgoing connections. Connecting mixer to Main Output by default.");
                    auto outNode = synth->getOutputNodeID();
                    if (outNode.uid != 0) {
                        bool o1 = synth->connect(mixNodeIdGraph, 0, outNode, 0);
                        juce::Logger::writeToLog("  - Connecting [" + juce::String(mixNodeIdGraph.uid) + ":0] -> [Output:0]... " + (o1 ? "SUCCESS" : "FAILED"));
                        bool o2 = synth->connect(mixNodeIdGraph, 1, outNode, 1);
                        juce::Logger::writeToLog("  - Connecting [" + juce::String(mixNodeIdGraph.uid) + ":1] -> [Output:1]... " + (o2 ? "SUCCESS" : "FAILED"));
                    }
                } else {
                    for (const auto& c : outgoingConnections) {
                        auto dstNodeId = c.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(c.dstLogicalId);
                        if (dstNodeId.uid != 0) {
                            // Connect mixer output to the same destination the original node was connected to
                            // This maintains the chain: original -> mixer -> destination
                            bool success = synth->connect(mixNodeIdGraph, c.srcChan, dstNodeId, c.dstChan);
                            juce::String destStr = c.dstIsOutput ? "Main Output" : "Node " + juce::String(c.dstLogicalId);
                            juce::Logger::writeToLog("  - Maintaining chain: Mixer [" + juce::String(mixNodeIdGraph.uid) + ":" + juce::String(c.srcChan) + "] -> " + destStr + "[" + juce::String(dstNodeId.uid) + ":" + juce::String(c.dstChan) + "]... " + (success ? "SUCCESS" : "FAILED"));
                        } else {
                            juce::Logger::writeToLog("  - SKIPPING Reconnect due to invalid destination node ID for original logical ID " + juce::String(c.dstLogicalId));
                        }
                    }
                }

                graphNeedsRebuild = true;
                pushSnapshot(); // Make the entire operation undoable
                juce::Logger::writeToLog("[InsertMixer] Rerouting complete. Flagging for graph rebuild.");
            }
            juce::Logger::writeToLog("--- [InsertMixer] End ---");
        }

        // Shortcut: Ctrl+I to show Insert Node popup menu
        if (selectedLogicalId != 0 && ctrlDown && ImGui::IsKeyPressed(ImGuiKey_I) && !insertNodeShortcutCooldown)
        {
            insertNodeShortcutCooldown = true;
            showInsertNodePopup = true;
        }

        // Insert Node popup menu
        if (showInsertNodePopup)
        {
            ImGui::OpenPopup("InsertNodePopup");
            showInsertNodePopup = false;
        }

        if (ImGui::BeginPopup("InsertNodePopup"))
        {
            ImGui::Text("Insert Node Between Connections");
            
            // Audio Path
            if (ImGui::MenuItem("VCF")) { insertNodeBetween("VCF"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("VCA")) { insertNodeBetween("VCA"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Delay")) { insertNodeBetween("Delay"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Reverb")) { insertNodeBetween("Reverb"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Mixer")) { insertNodeBetween("Mixer"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Recorder")) { insertNodeBetween("recorder"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Shaping Oscillator")) { insertNodeBetween("shaping oscillator"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("8-Band Shaper")) { insertNodeBetween("8bandshaper"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Granulator")) { insertNodeBetween("Granulator"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Harmonic Shaper")) { insertNodeBetween("harmonic shaper"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Vocal Tract Filter")) { insertNodeBetween("Vocal Tract Filter"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Scope")) { insertNodeBetween("Scope"); ImGui::CloseCurrentPopup(); }
            
            ImGui::Separator();
            
            // Modulation Path
            if (ImGui::MenuItem("Attenuverter")) { insertNodeBetween("Attenuverter"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Math")) { insertNodeBetween("Math"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Comparator")) { insertNodeBetween("Comparator"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("CV Mixer")) { insertNodeBetween("CV Mixer"); ImGui::CloseCurrentPopup(); }
            if (ImGui::MenuItem("Sequential Switch")) { insertNodeBetween("Sequential Switch"); ImGui::CloseCurrentPopup(); }
            
            ImGui::EndPopup();
        }

        // Output sink node with stereo inputs (single, fixed ID 0)
        const bool isOutputHovered = (hoveredLinkDstId == kOutputHighlightId);
        if (isOutputHovered)
            ImNodes::PushColorStyle(ImNodesCol_TitleBar, IM_COL32(255, 220, 0, 255));
        ImNodes::BeginNode (0);
        ImNodes::BeginNodeTitleBar();
        ImGui::TextUnformatted ("Output");
        ImNodes::EndNodeTitleBar();
        if (isOutputHovered)
            ImNodes::PopColorStyle();
        
        // In L pin with proper Audio type coloring (green)
        { 
            int a = encodePinId({0, 0, true}); 
            seenAttrs.insert(a); 
            availableAttrs.insert(a); 
            bool isConnected = connectedInputAttrs.count(a) > 0;
            PinID pinId = {0, 0, true, false, ""};
            PinDataType pinType = getPinDataTypeForPin(pinId);
            unsigned int pinColor = getImU32ForType(pinType);
            ImNodes::PushColorStyle(ImNodesCol_Pin, isConnected ? colPinConnected : pinColor);
            ImNodes::BeginInputAttribute (a);
            ImGui::Text ("In L");
            ImNodes::EndInputAttribute();
            ImNodes::PopColorStyle();
        }
        
        // In R pin with proper Audio type coloring (green)
        { 
            int a = encodePinId({0, 1, true}); 
            seenAttrs.insert(a); 
            availableAttrs.insert(a); 
            bool isConnected = connectedInputAttrs.count(a) > 0;
            PinID pinId = {0, 1, true, false, ""};
            PinDataType pinType = getPinDataTypeForPin(pinId);
            unsigned int pinColor = getImU32ForType(pinType);
            ImNodes::PushColorStyle(ImNodesCol_Pin, isConnected ? colPinConnected : pinColor);
            ImNodes::BeginInputAttribute (a);
            ImGui::Text ("In R");
            ImNodes::EndInputAttribute();
            ImNodes::PopColorStyle();
        }
        
        ImNodes::EndNode();
        
        // Cache output node position for snapshot safety
        // Graph is always in consistent state since we rebuild at frame start
        lastKnownNodePositions[0] = ImNodes::GetNodeGridSpacePos(0);
        
        if (auto it = pendingNodePositions.find(0); it != pendingNodePositions.end())
        {
            ImNodes::SetNodeGridSpacePos(0, it->second);
            juce::Logger::writeToLog("[PositionRestore] Applied pending position for output node 0: (" + juce::String(it->second.x) + ", " + juce::String(it->second.y) + ")");
            pendingNodePositions.erase(it);
        }
        drawnNodes.insert(0);

        // Use last frame's hovered node id for highlighting (queried after EndNodeEditor)
        int hoveredNodeId = lastHoveredNodeId;

        // Draw existing audio connections (IDs stable via bitmasking)
        int cableIdx = 0;
        for (const auto& c : synth->getConnectionsInfo())
        {
            
            // Skip links whose nodes weren't drawn this frame (e.g., just deleted)
            if (c.srcLogicalId != 0 && ! drawnNodes.count((int) c.srcLogicalId)) {
                continue;
            }
            if (! c.dstIsOutput && c.dstLogicalId != 0 && ! drawnNodes.count((int) c.dstLogicalId)) {
                continue;
            }
            
            const int srcAttr = encodePinId({c.srcLogicalId, c.srcChan, false});
            const int dstAttr = c.dstIsOutput ? encodePinId({0, c.dstChan, true}) : encodePinId({c.dstLogicalId, c.dstChan, true});
            
            if (! availableAttrs.count(srcAttr) || ! availableAttrs.count(dstAttr))
            {
                static std::unordered_set<std::string> skipOnce;
                const std::string key = std::to_string((int)c.srcLogicalId) + ":" + std::to_string(c.srcChan) + "->" +
                                         (c.dstIsOutput? std::string("0") : std::to_string((int)c.dstLogicalId)) + ":" + std::to_string(c.dstChan);
                if (skipOnce.insert(key).second)
                {
                    juce::Logger::writeToLog(
                        juce::String("[ImNodes][SKIP] missing attr: srcPresent=") + (availableAttrs.count(srcAttr)?"1":"0") +
                        " dstPresent=" + (availableAttrs.count(dstAttr)?"1":"0") +
                        " srcKey=(lid=" + juce::String((int)c.srcLogicalId) + ",ch=" + juce::String(c.srcChan) + ")" +
                        " dstKey=(lid=" + juce::String(c.dstIsOutput?0:(int)c.dstLogicalId) + ",ch=" + juce::String(c.dstChan) + ",in=1) id(s)=" +
                        juce::String(srcAttr) + "," + juce::String(dstAttr));
                }
                continue;
            }
            
            const int linkId = linkIdOf(srcAttr, dstAttr);
            linkIdToAttrs[linkId] = { srcAttr, dstAttr };
            
            // --- THIS IS THE DEFINITIVE FIX ---
            // 1. Determine the base color and check for signal activity.
            auto srcPin = decodePinId(srcAttr);
            PinDataType linkDataType = getPinDataTypeForPin(srcPin);
            ImU32 linkColor = getImU32ForType(linkDataType);
            float magnitude = 0.0f;
            bool hasThicknessModification = false;

            if (auto* srcModule = synth->getModuleForLogical(srcPin.logicalId))
            {
                magnitude = srcModule->getOutputChannelValue(srcPin.channel);
            }

            // 2. If the signal is active, calculate a glowing/blinking color.
            if (magnitude > 0.01f)
            {
                const float blinkSpeed = 8.0f;
                float blinkFactor = (std::sin((float)ImGui::GetTime() * blinkSpeed) + 1.0f) * 0.5f;
                float glowIntensity = juce::jlimit(0.0f, 1.0f, blinkFactor * magnitude * 2.0f);

                // Brighten the base color and modulate alpha for glow effect
                ImVec4 colorVec = ImGui::ColorConvertU32ToFloat4(linkColor);
                colorVec.x = juce::jmin(1.0f, colorVec.x + glowIntensity * 0.4f);
                colorVec.y = juce::jmin(1.0f, colorVec.y + glowIntensity * 0.4f);
                colorVec.z = juce::jmin(1.0f, colorVec.z + glowIntensity * 0.4f);
                colorVec.w = juce::jlimit(0.5f, 1.0f, 0.5f + glowIntensity * 0.5f);
                linkColor = ImGui::ColorConvertFloat4ToU32(colorVec);

                // Make active cables slightly thicker
                ImNodes::PushStyleVar(ImNodesStyleVar_LinkThickness, 3.0f);
                hasThicknessModification = true;
            }

            // 3. Push the chosen color (either normal or glowing) to the style stack.
            ImNodes::PushColorStyle(ImNodesCol_Link, linkColor);
            ImNodes::PushColorStyle(ImNodesCol_LinkHovered, IM_COL32(255, 255, 0, 255));
            ImNodes::PushColorStyle(ImNodesCol_LinkSelected, IM_COL32(255, 255, 0, 255));

            // 4. Check for node hover highlight (this should override the glow).
            const bool hl = (hoveredNodeId != -1) && ((int) c.srcLogicalId == hoveredNodeId || (! c.dstIsOutput && (int) c.dstLogicalId == hoveredNodeId) || (c.dstIsOutput && hoveredNodeId == 0));
            if (hl)
            {
                ImNodes::PushColorStyle(ImNodesCol_Link, IM_COL32(255, 255, 0, 255));
            }
            
            // 5. Tell imnodes to draw the link. It will use the color we just pushed.
            ImNodes::Link(linkId, srcAttr, dstAttr);
            
            // 6. Pop ALL style modifications to restore the defaults for the next link.
            if (hl) ImNodes::PopColorStyle();
            ImNodes::PopColorStyle(); // LinkSelected
            ImNodes::PopColorStyle(); // LinkHovered
            ImNodes::PopColorStyle(); // Link
            if (hasThicknessModification) ImNodes::PopStyleVar(); // LinkThickness
            
            // --- END OF FIX ---
        }

        // Drag detection for node movement: snapshot once on mouse release (post-state)
        const bool hoveringNode = (lastHoveredNodeId != -1);
        if (hoveringNode && ImGui::IsMouseDragging(ImGuiMouseButton_Left))
        {
            isDraggingNode = true;
        }
        if (isDraggingNode && ImGui::IsMouseReleased(ImGuiMouseButton_Left))
        {
            isDraggingNode = false;
            // Capture positions after a move so subsequent operations (e.g. delete) undo to the moved location
            pushSnapshot();
        }
    }

    // --- Handle Auto-Connect Requests from MIDI Players ---
    for (const auto& modInfo : synth->getModulesInfo())
    {
        if (auto* midiPlayer = dynamic_cast<MIDIPlayerModuleProcessor*>(synth->getModuleForLogical(modInfo.first)))
        {
            // Check for initial button presses
            if (midiPlayer->autoConnectTriggered.exchange(false))
            {
                midiPlayer->lastAutoConnectState = MIDIPlayerModuleProcessor::AutoConnectState::Samplers;
                handleMidiPlayerAutoConnect(midiPlayer, modInfo.first);
                pushSnapshot();
            }
            else if (midiPlayer->autoConnectVCOTriggered.exchange(false))
            {
                midiPlayer->lastAutoConnectState = MIDIPlayerModuleProcessor::AutoConnectState::PolyVCO;
                handleMidiPlayerAutoConnectVCO(midiPlayer, modInfo.first);
                pushSnapshot();
            }
            else if (midiPlayer->autoConnectHybridTriggered.exchange(false))
            {
                midiPlayer->lastAutoConnectState = MIDIPlayerModuleProcessor::AutoConnectState::Hybrid;
                handleMidiPlayerAutoConnectHybrid(midiPlayer, modInfo.first);
                pushSnapshot();
            }
            // --- THIS IS THE NEW LOGIC ---
            // Check if an update was requested after a new file was loaded
            else if (midiPlayer->connectionUpdateRequested.exchange(false))
            {
                // Re-run the correct handler based on the saved state
                switch (midiPlayer->lastAutoConnectState.load())
                {
                    case MIDIPlayerModuleProcessor::AutoConnectState::Samplers:
                        handleMidiPlayerAutoConnect(midiPlayer, modInfo.first);
                        pushSnapshot();
                        break;
                    case MIDIPlayerModuleProcessor::AutoConnectState::PolyVCO:
                        handleMidiPlayerAutoConnectVCO(midiPlayer, modInfo.first);
                        pushSnapshot();
                        break;
                    case MIDIPlayerModuleProcessor::AutoConnectState::Hybrid:
                        handleMidiPlayerAutoConnectHybrid(midiPlayer, modInfo.first);
                        pushSnapshot();
                        break;
                    case MIDIPlayerModuleProcessor::AutoConnectState::None:
                    default:
                        // Do nothing if it wasn't auto-connected before
                        break;
                }
            }
            // --- END OF NEW LOGIC ---
        }
    }

    // --- Handle Auto-Connect Requests using new intelligent system ---
    handleAutoConnectionRequests();

    ImNodes::MiniMap (0.2f, ImNodesMiniMapLocation_BottomRight);

    ImNodes::EndNodeEditor();
    
    // ================== MIDI PLAYER QUICK CONNECT LOGIC ==================
    // Poll all MIDI Player modules for connection requests
    if (synth != nullptr)
    {
        for (const auto& modInfo : synth->getModulesInfo())
        {
            if (auto* midiPlayer = dynamic_cast<MIDIPlayerModuleProcessor*>(synth->getModuleForLogical(modInfo.first)))
            {
                int requestType = midiPlayer->getAndClearConnectionRequest();
                if (requestType > 0)
                {
                    handleMIDIPlayerConnectionRequest(modInfo.first, midiPlayer, requestType);
                    break; // Only handle one request per frame
                }
            }
        }
    }
    // ================== END MIDI PLAYER QUICK CONNECT ==================
    
    // ================== META MODULE EDITING LOGIC ==================
    // Check if any Meta Module has requested to be edited
    if (synth != nullptr && metaModuleToEditLid == 0) // Only check if not already editing one
    {
        for (const auto& modInfo : synth->getModulesInfo())
        {
            if (auto* metaModule = dynamic_cast<MetaModuleProcessor*>(synth->getModuleForLogical(modInfo.first)))
            {
                // Atomically check and reset the flag
                if (metaModule->editRequested.exchange(false))
                {
                    metaModuleToEditLid = modInfo.first;
                    juce::Logger::writeToLog("[MetaEdit] Opening editor for Meta Module L-ID " + juce::String((int)metaModuleToEditLid));
                    ImGui::OpenPopup("Edit Meta Module");
                    break; // Only handle one request per frame
                }
            }
        }
    }
    
    // Draw the modal popup for the internal editor if one is selected
    if (metaModuleToEditLid != 0)
    {
        ImGui::SetNextWindowSize(ImVec2(1200, 800), ImGuiCond_FirstUseEver);
        if (ImGui::BeginPopupModal("Edit Meta Module", nullptr, ImGuiWindowFlags_MenuBar))
        {
            // Get the internal synth processor from the meta module
            auto* metaModule = dynamic_cast<MetaModuleProcessor*>(synth->getModuleForLogical(metaModuleToEditLid));
            if (metaModule && metaModule->getInternalGraph())
            {
                // Display a placeholder for now
                // TODO: Full recursive editor implementation would go here
                ImGui::Text("Editing internal graph of Meta Module %d", (int)metaModuleToEditLid);
                ImGui::Separator();
                
                auto* internalGraph = metaModule->getInternalGraph();
                auto modules = internalGraph->getModulesInfo();
                
                ImGui::Text("Internal modules: %d", (int)modules.size());
                if (ImGui::BeginChild("ModuleList", ImVec2(0, -30), true))
                {
                    for (const auto& [lid, type] : modules)
                    {
                        ImGui::Text("  [%d] %s", (int)lid, type.toRawUTF8());
                    }
                }
                ImGui::EndChild();
                
                ImGui::Text("NOTE: Full nested editor UI is a TODO");
                ImGui::Text("For now, you can inspect the internal graph structure above.");
            }
            
            if (ImGui::Button("Close"))
            {
                ImGui::CloseCurrentPopup();
                metaModuleToEditLid = 0;
                // When closing, the meta module might have new/removed inlets/outlets,
                // so we need to rebuild the main graph to update its pins
                graphNeedsRebuild = true;
            }
            ImGui::EndPopup();
        }
        else
        {
            // If the popup was closed by the user (e.g., pressing ESC)
            metaModuleToEditLid = 0;
            graphNeedsRebuild = true;
        }
    }
    // ======================= END OF META MODULE LOGIC =======================

    // --- CONSOLIDATED HOVERED LINK DETECTION ---
    // Declare these variables ONCE, immediately after the editor has ended.
    // All subsequent features that need to know about hovered links can now
    // safely reuse these results without causing redefinition or scope errors.
    // Graph is always in consistent state since we rebuild at frame start
    int hoveredLinkId = -1;
    bool isLinkHovered = ImNodes::IsLinkHovered(&hoveredLinkId);
    // --- END OF CONSOLIDATED DECLARATION ---
    
    // Smart cable visualization is now integrated directly into the link drawing loop above.
    // No separate overlay needed - cables glow by modifying their own color.
    
    // === PROBE TOOL MODE HANDLING ===
    if (isProbeModeActive)
    {
        // Change cursor to indicate probe mode is active
        ImGui::SetMouseCursor(ImGuiMouseCursor_Hand);
        
        // Draw "PROBE ACTIVE" indicator at mouse position
        auto* drawList = ImGui::GetForegroundDrawList();
        ImVec2 mousePos = ImGui::GetMousePos();
        const char* text = "PROBE MODE: Click output pin";
        auto textSize = ImGui::CalcTextSize(text);
        ImVec2 textPos = ImVec2(mousePos.x + 20, mousePos.y - 20);
        drawList->AddRectFilled(
            ImVec2(textPos.x - 5, textPos.y - 2),
            ImVec2(textPos.x + textSize.x + 5, textPos.y + textSize.y + 2),
            IM_COL32(50, 50, 50, 200)
        );
        drawList->AddText(textPos, IM_COL32(255, 255, 100, 255), text);
        
        // Check for pin clicks
        if (ImGui::IsMouseClicked(ImGuiMouseButton_Left))
        {
            int hoveredPinId = -1;
            if (ImNodes::IsPinHovered(&hoveredPinId) && hoveredPinId != -1)
            {
                auto pinId = decodePinId(hoveredPinId);
                // Check if it's an output pin (not input, not mod)
                if (!pinId.isInput && !pinId.isMod && pinId.logicalId != 0)
                {
                    juce::Logger::writeToLog("[PROBE_UI] Probe clicked on valid output pin. LogicalID: " + juce::String(pinId.logicalId) + ", Channel: " + juce::String(pinId.channel));
                    auto nodeId = synth->getNodeIdForLogical(pinId.logicalId);
                    synth->setProbeConnection(nodeId, pinId.channel);
                    isProbeModeActive = false; // Deactivate after probing
                }
                else
                {
                    juce::Logger::writeToLog("[PROBE_UI] Probe clicked on an invalid pin (input or output node). Cancelling.");
                    isProbeModeActive = false;
                }
            }
            else
            {
                // Clicked on empty space, cancel probe mode
                juce::Logger::writeToLog("[PROBE_UI] Probe clicked on empty space. Cancelling.");
                isProbeModeActive = false;
            }
        }
        
        // Allow ESC to cancel probe mode
        if (ImGui::IsKeyPressed(ImGuiKey_Escape))
        {
            isProbeModeActive = false;
            juce::Logger::writeToLog("[PROBE_UI] Cancelled with ESC");
        }
    }

    // --- CONTEXTUAL RIGHT-CLICK HANDLER ---
    // A cable was right-clicked. Store its info and open the insert popup.
    if (isLinkHovered && hoveredLinkId != -1 && ImGui::IsMouseClicked(ImGuiMouseButton_Right))
    {
        juce::Logger::writeToLog("[InsertNode][RC] Hovered link id=" + juce::String(hoveredLinkId));
        // A cable was right-clicked. Store its info and open the insert popup.
        linkToInsertOn = {}; // Reset previous info
        linkToInsertOn.linkId = hoveredLinkId;

        bool captured = false;
        // TODO: Implement modulation link detection for new bus-based system
        // if (modLinkIdToRoute.count(hoveredLinkId))
        // {
        //     linkToInsertOn.isMod = true;
        //     auto& route = modLinkIdToRoute[hoveredLinkId];
        //     linkToInsertOn.srcLogicalId = std::get<0>(route);
        //     linkToInsertOn.srcChan = std::get<1>(route);
        //     linkToInsertOn.dstLogicalId = std::get<2>(route);
        //     linkToInsertOn.paramId = std::get<3>(route);
        //     juce::Logger::writeToLog("[InsertNode][RC] Mod link captured: srcLID=" + juce::String((int)linkToInsertOn.srcLogicalId) +
        //                               " srcChan=" + juce::String(linkToInsertOn.srcChan) +
        //                               " dstLID=" + juce::String((int)linkToInsertOn.dstLogicalId) +
        //                               " param='" + linkToInsertOn.paramId + "'");
        //     captured = true;
        // }
        if (linkIdToAttrs.count(hoveredLinkId))
        {
            linkToInsertOn.isMod = false;
            auto& attrs = linkIdToAttrs[hoveredLinkId];
            juce::Logger::writeToLog("[InsertNode][RC] Audio link attrs: srcAttr=" + juce::String(attrs.first) +
                                      " dstAttr=" + juce::String(attrs.second));
            linkToInsertOn.srcPin = decodePinId(attrs.first);
            linkToInsertOn.dstPin = decodePinId(attrs.second);
            // Decide list based on pin data types (treat CV/Gate/Raw as modulation list)
            const PinDataType srcType = getPinDataTypeForPin(linkToInsertOn.srcPin);
            const PinDataType dstType = getPinDataTypeForPin(linkToInsertOn.dstPin);
            if (srcType == PinDataType::CV || dstType == PinDataType::CV ||
                srcType == PinDataType::Gate || dstType == PinDataType::Gate ||
                srcType == PinDataType::Raw || dstType == PinDataType::Raw)
            {
                linkToInsertOn.isMod = true;
            }
            juce::Logger::writeToLog("[InsertNode][RC] Audio pins: src(lid=" + juce::String((int)linkToInsertOn.srcPin.logicalId) +
                                      ",ch=" + juce::String(linkToInsertOn.srcPin.channel) +
                                      ",in=" + juce::String((int)linkToInsertOn.srcPin.isInput) + ") -> dst(lid=" +
                                      juce::String((int)linkToInsertOn.dstPin.logicalId) + ",ch=" +
                                      juce::String(linkToInsertOn.dstPin.channel) + ",in=" +
                                      juce::String((int)linkToInsertOn.dstPin.isInput) + ")");
            captured = true;
        }
        else
        {
            juce::Logger::writeToLog("[InsertNode][RC] Link id not found in maps");
        }

        if (captured)
        {
            showInsertNodePopup = true; // defer opening until after EndNodeEditor
            pendingInsertLinkId = hoveredLinkId;
            juce::Logger::writeToLog("[InsertNode][RC] Will open popup after EndNodeEditor");
        }
        else
        {
            linkToInsertOn.linkId = -1; // nothing recognized; do not open
        }
    }

    // --- Keyboard Shortcuts for Node Chaining ---
    // Check if multiple nodes are selected and no modifiers are held
    if (ImNodes::NumSelectedNodes() > 1 && !ImGui::GetIO().KeyCtrl && !ImGui::GetIO().KeyShift && !ImGui::GetIO().KeyAlt)
    {
        // C: Standard stereo chaining (channels 0->0, 1->1)
        if (ImGui::IsKeyPressed(ImGuiKey_C))
        {
            handleNodeChaining();
        }
        // G: Audio type chaining
        else if (ImGui::IsKeyPressed(ImGuiKey_G))
        {
            handleColorCodedChaining(PinDataType::Audio);
        }
        // B: CV type chaining
        else if (ImGui::IsKeyPressed(ImGuiKey_B))
        {
            handleColorCodedChaining(PinDataType::CV);
        }
        // R: Raw type chaining
        else if (ImGui::IsKeyPressed(ImGuiKey_R))
        {
            handleColorCodedChaining(PinDataType::Raw);
        }
        // Y: Gate type chaining
        else if (ImGui::IsKeyPressed(ImGuiKey_Y))
        {
            handleColorCodedChaining(PinDataType::Gate);
        }
    }
    // --- END OF KEYBOARD SHORTCUTS ---

    // --- Cable Splitting (Ctrl+Middle-Click) ---
    if (isLinkHovered && hoveredLinkId != -1)
    {
        if (ImGui::GetIO().KeyCtrl && ImGui::IsMouseClicked(ImGuiMouseButton_Middle))
        {
            // User initiated a split. Find the source pin of the hovered link.
            if (auto it = linkIdToAttrs.find(hoveredLinkId); it != linkIdToAttrs.end())
            {
                splittingFromAttrId = it->second.first; // The source attribute ID
                juce::Logger::writeToLog("[CableSplit] Starting split from attr ID: " + juce::String(splittingFromAttrId));
            }
        }
    }
    // --- END OF CABLE SPLITTING ---

    // 2. If a split-drag is active, handle drawing and completion.
    if (splittingFromAttrId != -1)
    {
        // Draw a line from the source pin to the mouse cursor for visual feedback.
        if (auto it = attrPositions.find(splittingFromAttrId); it != attrPositions.end())
        {
            ImVec2 sourcePos = it->second;
            ImVec2 mousePos = ImGui::GetMousePos();
            ImGui::GetForegroundDrawList()->AddLine(sourcePos, mousePos, IM_COL32(255, 255, 0, 200), 3.0f);
        }

        // 3. Handle completion or cancellation of the drag.
        // We use Left-click to complete the link, matching ImNodes' default behavior.
        if (ImGui::IsMouseReleased(ImGuiMouseButton_Left))
        {
            int hoveredPinId = -1;
            if (ImNodes::IsPinHovered(&hoveredPinId) && hoveredPinId != -1)
            {
                // User dropped the link on a pin.
                auto srcPin = decodePinId(splittingFromAttrId);
                auto dstPin = decodePinId(hoveredPinId);

                // Ensure the connection is valid (Output -> Input).
                if (!srcPin.isInput && dstPin.isInput)
                {
                    auto srcNode = synth->getNodeIdForLogical(srcPin.logicalId);
                    auto dstNode = (dstPin.logicalId == 0) ? synth->getOutputNodeID() : synth->getNodeIdForLogical(dstPin.logicalId);

                    synth->connect(srcNode, srcPin.channel, dstNode, dstPin.channel);
                    graphNeedsRebuild = true;
                    pushSnapshot(); // Make it undoable
                }
            }

            // ALWAYS reset the state, whether the connection was successful or not.
            splittingFromAttrId = -1;
        }
        // Also allow cancellation with a right-click.
        else if (ImGui::IsMouseReleased(ImGuiMouseButton_Right))
        {
            splittingFromAttrId = -1; // Cancel the operation.
        }
    }
    // --- END OF NEW LOGIC ---

    // Open popup now (outside editor) if requested this frame
    if (showInsertNodePopup)
    {
        showInsertNodePopup = false;
        // Validate the link still exists
        if (pendingInsertLinkId != -1)
        {
            bool stillValid = (/* modLinkIdToRoute.count(pendingInsertLinkId) || */ linkIdToAttrs.count(pendingInsertLinkId));
            if (!stillValid)
            {
                juce::Logger::writeToLog("[InsertNode] Skipping popup: link disappeared this frame");
                pendingInsertLinkId = -1;
            }
        }
        if (pendingInsertLinkId != -1)
        {
            ImGui::OpenPopup("InsertNodeOnLinkPopup");
            // Consume the mouse release/click so the popup stays open
            ImGui::GetIO().WantCaptureMouse = true;
            juce::Logger::writeToLog("[InsertNode] Opened popup (post-editor)");
        }
        else
        {
            linkToInsertOn = {}; // safety
        }
        pendingInsertLinkId = -1;
    }

    // Fallback: If user right-clicked and a link was hovered this frame, open popup using cached hover
    if (ImGui::IsMouseClicked(ImGuiMouseButton_Right)
        && lastHoveredLinkId != -1
        && !ImGui::IsPopupOpen("InsertNodeOnLinkPopup"))
    {
        int id = lastHoveredLinkId;
        linkToInsertOn = {}; linkToInsertOn.linkId = id;
        bool captured = false;
        // TODO: Handle modulation link deletion for new bus-based system
        // if (auto itM = modLinkIdToRoute.find(id); itM != modLinkIdToRoute.end())
        // {
        //     linkToInsertOn.isMod = true;
        //     int sL, sC, dL; juce::String paramId; std::tie(sL, sC, dL, paramId) = itM->second;
        //     linkToInsertOn.srcLogicalId = (juce::uint32) sL;
        //     linkToInsertOn.srcChan = sC;
        //     linkToInsertOn.dstLogicalId = (juce::uint32) dL;
        //     linkToInsertOn.paramId = paramId;
        //     captured = true;
        //     juce::Logger::writeToLog("[InsertNode][RC-Fallback] Mod link captured id=" + juce::String(id));
        // }
        // else 
        if (auto it = linkIdToAttrs.find(id); it != linkIdToAttrs.end())
        {
            linkToInsertOn.isMod = false;
            linkToInsertOn.srcPin = decodePinId(it->second.first);
            linkToInsertOn.dstPin = decodePinId(it->second.second);
            // Infer modulation vs audio list from pin data types
            const PinDataType srcType = getPinDataTypeForPin(linkToInsertOn.srcPin);
            const PinDataType dstType = getPinDataTypeForPin(linkToInsertOn.dstPin);
            if (srcType == PinDataType::CV || dstType == PinDataType::CV ||
                srcType == PinDataType::Gate || dstType == PinDataType::Gate ||
                srcType == PinDataType::Raw || dstType == PinDataType::Raw)
            {
                linkToInsertOn.isMod = true;
            }
            captured = true;
            juce::Logger::writeToLog("[InsertNode][RC-Fallback] Link captured id=" + juce::String(id));
        }
        if (captured)
        {
            ImGui::OpenPopup("InsertNodeOnLinkPopup");
            ImGui::GetIO().WantCaptureMouse = true;
            juce::Logger::writeToLog("[InsertNode][RC-Fallback] Opened popup");
        }
        else
        {
            linkToInsertOn.linkId = -1;
        }
    }
    // This function draws the popup if the popup is open.
    drawInsertNodeOnLinkPopup();

    // --- Cable Inspector: Stateless, rebuild-safe implementation ---
    hoveredLinkSrcId = 0;
    hoveredLinkDstId = 0;

    // Skip inspector if popups are open (graph is always in consistent state now)
    const bool anyPopupOpen = ImGui::IsPopupOpen("InsertNodeOnLinkPopup") || ImGui::IsPopupOpen("AddModulePopup");
    // Do not early-return here; we still need to finish the frame and close any ImGui scopes.

    if (!anyPopupOpen && isLinkHovered && hoveredLinkId != -1 && synth != nullptr)
    {
        // Safety: Re-verify link still exists in our mapping
        auto it = linkIdToAttrs.find(hoveredLinkId);
        if (it != linkIdToAttrs.end())
        {
            auto srcPin = decodePinId(it->second.first);
            auto dstPin = decodePinId(it->second.second);

            // Set highlight IDs for this frame only
            hoveredLinkSrcId = srcPin.logicalId;
            hoveredLinkDstId = (dstPin.logicalId == 0) ? kOutputHighlightId : dstPin.logicalId;

            // Query source module (no caching - stateless)
            if (auto* srcModule = synth->getModuleForLogical(srcPin.logicalId))
            {
                // Validate channel index
                const int numOutputs = srcModule->getTotalNumOutputChannels();
                if (srcPin.channel >= 0 && srcPin.channel < numOutputs)
                {
                    // Optional: Throttle value sampling to 60 Hz (every 16.67ms)
                    // For now, query every frame for responsive UI
                    const float liveValue = srcModule->getOutputChannelValue(srcPin.channel);
                    const juce::String srcName = srcModule->getName();
                    const juce::String srcLabel = srcModule->getAudioOutputLabel(srcPin.channel);

                    // Render tooltip (stateless - no caching)
                    ImGui::BeginTooltip();
                    ImGui::Text("Value: %.3f", liveValue);
                    ImGui::Text("From: %s (ID %u)", srcName.toRawUTF8(), (unsigned)srcPin.logicalId);
                    if (srcLabel.isNotEmpty())
                        ImGui::Text("Pin: %s", srcLabel.toRawUTF8());
                    ImGui::EndTooltip();
                }
            }
        }
    }
    

    // Update hovered node/link id for next frame (must be called outside editor scope)
    // Graph is always in consistent state since we rebuild at frame start
    int hv = -1;
    if (ImNodes::IsNodeHovered(&hv)) lastHoveredNodeId = hv; else lastHoveredNodeId = -1;
    
    int hl = -1;
    if (ImNodes::IsLinkHovered(&hl)) lastHoveredLinkId = hl; else lastHoveredLinkId = -1;
    

    // Shortcut: press 'I' while hovering a link to open Insert-on-Link popup (bypasses mouse handling)
    if (ImGui::IsKeyPressed(ImGuiKey_I) && lastHoveredLinkId != -1 && !ImGui::IsPopupOpen("InsertNodeOnLinkPopup"))
    {
        linkToInsertOn = {}; // reset
        linkToInsertOn.linkId = lastHoveredLinkId;
        bool captured = false;
        // TODO: Handle modulation link hover end for new bus-based system
        // if (auto itM = modLinkIdToRoute.find(lastHoveredLinkId); itM != modLinkIdToRoute.end())
        // {
        //     linkToInsertOn.isMod = true;
        //     int sL, sC, dL; juce::String paramId; std::tie(sL, sC, dL, paramId) = itM->second;
        //     linkToInsertOn.srcLogicalId = (juce::uint32) sL;
        //     linkToInsertOn.srcChan = sC;
        //     linkToInsertOn.dstLogicalId = (juce::uint32) dL;
        //     linkToInsertOn.paramId = paramId;
        //     captured = true;
        //     juce::Logger::writeToLog("[InsertNode][KeyI] Mod link captured id=" + juce::String(lastHoveredLinkId));
        // }
        // else 
        if (auto it = linkIdToAttrs.find(lastHoveredLinkId); it != linkIdToAttrs.end())
        {
            linkToInsertOn.isMod = false;
            linkToInsertOn.srcPin = decodePinId(it->second.first);
            linkToInsertOn.dstPin = decodePinId(it->second.second);
            const PinDataType srcType = getPinDataTypeForPin(linkToInsertOn.srcPin);
            const PinDataType dstType = getPinDataTypeForPin(linkToInsertOn.dstPin);
            if (srcType == PinDataType::CV || dstType == PinDataType::CV ||
                srcType == PinDataType::Gate || dstType == PinDataType::Gate ||
                srcType == PinDataType::Raw || dstType == PinDataType::Raw)
            {
                linkToInsertOn.isMod = true;
            }
            captured = true;
            juce::Logger::writeToLog("[InsertNode][KeyI] Link captured id=" + juce::String(lastHoveredLinkId));
        }
        if (captured)
        {
            pendingInsertLinkId = lastHoveredLinkId;
            showInsertNodePopup = true; // will open next lines
        }
        else
        {
            linkToInsertOn.linkId = -1;
            juce::Logger::writeToLog("[InsertNode][KeyI] No link data found for id=" + juce::String(lastHoveredLinkId));
        }
    }

    // After editor pass, if we added/duplicated a node, take snapshot now that nodes exist
    if (snapshotAfterEditor)
    {
        snapshotAfterEditor = false;
        pushSnapshot();
    }

    if (synth != nullptr)
    {
        // No persistent panning state when zoom is disabled

        // Right-click on empty canvas -> Add module popup
        // Avoid passing nullptr to ImNodes::IsLinkHovered; some builds may write to the pointer
        int dummyHoveredLinkId = -1;
        const bool anyLinkHovered = ImNodes::IsLinkHovered(&dummyHoveredLinkId);
        if (ImGui::IsMouseReleased(ImGuiMouseButton_Right)
            && ImGui::IsWindowHovered(ImGuiHoveredFlags_RootAndChildWindows)
            && ! ImGui::IsAnyItemHovered()
            && !anyLinkHovered
            && !ImGui::IsPopupOpen("InsertNodeOnLinkPopup")
            && linkToInsertOn.linkId == -1) // avoid conflict with insert-on-link popup
        {
                ImGui::OpenPopup("AddModulePopup");
        }

        // --- REVISED AND IMPROVED "QUICK ADD" POPUP ---
        if (ImGui::BeginPopup("AddModulePopup"))
        {
            static char searchQuery[128] = "";
            static int selectedIndex = 0;  // Track keyboard navigation

            // Auto-focus the search bar when the popup opens and clear any previous search
            if (ImGui::IsWindowAppearing()) {
                ImGui::SetKeyboardFocusHere(0);
                ImGui::SetWindowFocus();  // Ensure immediate keyboard input capture
                searchQuery[0] = '\0';
                selectedIndex = 0;  // Reset selection
            }
            
            ImGui::Text("Add Module");
            ImGui::PushItemWidth(250.0f);
            
            // Enable Enter key detection for instant module creation
            bool enterPressed = ImGui::InputText("Search##addmodule", searchQuery, sizeof(searchQuery), 
                                                  ImGuiInputTextFlags_EnterReturnsTrue);
            
            ImGui::PopItemWidth();
            ImGui::Separator();
            
            // --- PROBE TOOL ---
            if (ImGui::MenuItem(" Probe Signal (Click any output pin)"))
            {
                isProbeModeActive = true;
                ImGui::CloseCurrentPopup();
            }
            if (ImGui::IsItemHovered())
            {
                ImGui::SetTooltip("Activate probe mode to instantly visualize any signal without manual patching.\nClick on any output pin to route it to the probe scope.");
            }
            ImGui::Separator();

            auto addAtMouse = [this](const char* type) {
                auto nodeId = synth->addModule(type);
                const int logicalId = (int) synth->getLogicalIdForNode (nodeId);
                // This places the new node exactly where the user right-clicked
                pendingNodeScreenPositions[logicalId] = ImGui::GetMousePosOnOpeningCurrentPopup();
                
                // Special handling for recorder module
                if (juce::String(type).equalsIgnoreCase("recorder"))
                {
                    if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(synth->getModuleForLogical((juce::uint32)logicalId)))
                    {
                        recorder->setPropertiesFile(PresetCreatorApplication::getApp().getProperties());
                    }
                }
                
                // Give comment nodes a default size to prevent feedback loop
                if (juce::String(type).equalsIgnoreCase("comment"))
                {
                    pendingNodeSizes[logicalId] = ImVec2(250.f, 150.f);
                }
                
                snapshotAfterEditor = true;
                ImGui::CloseCurrentPopup();
            };
            
            juce::String filter(searchQuery);

            ImGui::BeginChild("ModuleList", ImVec2(280, 350), true);

            if (filter.isEmpty())
            {
                // --- BROWSE MODE (No text in search bar) ---
                // Reorganized to match the new category structure
                
                if (ImGui::BeginMenu("Sources")) {
                    if (ImGui::MenuItem("VCO")) addAtMouse("vco");
                    if (ImGui::MenuItem("Polyphonic VCO")) addAtMouse("polyvco");
                    if (ImGui::MenuItem("Noise")) addAtMouse("noise");
                    if (ImGui::MenuItem("Audio Input")) addAtMouse("audio_input");
                    if (ImGui::MenuItem("Sample Loader")) addAtMouse("sample_loader");
                    if (ImGui::MenuItem("Value")) addAtMouse("value");
                    ImGui::EndMenu();
                }
                
                if (ImGui::BeginMenu("Effects")) {
                    if (ImGui::MenuItem("VCF")) addAtMouse("vcf");
                    if (ImGui::MenuItem("Delay")) addAtMouse("delay");
                    if (ImGui::MenuItem("Reverb")) addAtMouse("reverb");
                    if (ImGui::MenuItem("Chorus")) addAtMouse("chorus");
                    if (ImGui::MenuItem("Phaser")) addAtMouse("phaser");
                    if (ImGui::MenuItem("Compressor")) addAtMouse("compressor");
                    if (ImGui::MenuItem("Limiter")) addAtMouse("limiter");
                    if (ImGui::MenuItem("Noise Gate")) addAtMouse("gate");
                    if (ImGui::MenuItem("Drive")) addAtMouse("drive");
                    if (ImGui::MenuItem("Graphic EQ")) addAtMouse("graphic_eq");
                    if (ImGui::MenuItem("Waveshaper")) addAtMouse("waveshaper");
                    if (ImGui::MenuItem("8-Band Shaper")) addAtMouse("8bandshaper");
                    if (ImGui::MenuItem("Granulator")) addAtMouse("granulator");
                    if (ImGui::MenuItem("Harmonic Shaper")) addAtMouse("harmonic_shaper");
                    if (ImGui::MenuItem("Time/Pitch Shifter")) addAtMouse("timepitch");
                    if (ImGui::MenuItem("De-Crackle")) addAtMouse("de_crackle");
                    ImGui::EndMenu();
                }
                
                if (ImGui::BeginMenu("Modulators")) {
                    if (ImGui::MenuItem("LFO")) addAtMouse("lfo");
                    if (ImGui::MenuItem("ADSR")) addAtMouse("adsr");
                    if (ImGui::MenuItem("Random")) addAtMouse("random");
                    if (ImGui::MenuItem("S&H")) addAtMouse("s_and_h");
                    if (ImGui::MenuItem("Function Generator")) addAtMouse("function_generator");
                    if (ImGui::MenuItem("Shaping Oscillator")) addAtMouse("shaping_oscillator");
                    ImGui::EndMenu();
                }
                
                if (ImGui::BeginMenu("Utilities & Logic")) {
                    if (ImGui::MenuItem("VCA")) addAtMouse("vca");
                    if (ImGui::MenuItem("Mixer")) addAtMouse("mixer");
                    if (ImGui::MenuItem("CV Mixer")) addAtMouse("cv_mixer");
                    if (ImGui::MenuItem("Track Mixer")) addAtMouse("track_mixer");
                    if (ImGui::MenuItem("Attenuverter")) addAtMouse("attenuverter");
                    if (ImGui::MenuItem("Lag Processor")) addAtMouse("lag_processor");
                    if (ImGui::MenuItem("Math")) addAtMouse("math");
                    if (ImGui::MenuItem("Map Range")) addAtMouse("map_range");
                    if (ImGui::MenuItem("Quantizer")) addAtMouse("quantizer");
                    if (ImGui::MenuItem("Rate")) addAtMouse("rate");
                    if (ImGui::MenuItem("Comparator")) addAtMouse("comparator");
                    if (ImGui::MenuItem("Logic")) addAtMouse("logic");
                    if (ImGui::MenuItem("Clock Divider")) addAtMouse("clock_divider");
                    if (ImGui::MenuItem("Sequential Switch")) addAtMouse("sequential_switch");
                    ImGui::EndMenu();
                }
                
                if (ImGui::BeginMenu("Sequencers")) {
                    if (ImGui::MenuItem("Sequencer")) addAtMouse("sequencer");
                    if (ImGui::MenuItem("Multi Sequencer")) addAtMouse("multi_sequencer");
                    if (ImGui::MenuItem("Tempo Clock")) addAtMouse("tempo_clock");
                    if (ImGui::MenuItem("Snapshot Sequencer")) addAtMouse("snapshot_sequencer");
                    if (ImGui::MenuItem("Stroke Sequencer")) addAtMouse("stroke_sequencer");
                    ImGui::EndMenu();
                }
                
                if (ImGui::BeginMenu("MIDI")) {
                    if (ImGui::MenuItem("MIDI CV")) addAtMouse("midi_cv");
                    if (ImGui::MenuItem("MIDI Player")) addAtMouse("midi_player");
                    ImGui::Separator();
                    if (ImGui::MenuItem("MIDI Faders")) addAtMouse("midi_faders");
                    if (ImGui::MenuItem("MIDI Knobs")) addAtMouse("midi_knobs");
                    if (ImGui::MenuItem("MIDI Buttons")) addAtMouse("midi_buttons");
                    if (ImGui::MenuItem("MIDI Jog Wheel")) addAtMouse("midi_jog_wheel");
                    if (ImGui::MenuItem("MIDI Pads")) addAtMouse("midi_pads");
                    ImGui::Separator();
                    if (ImGui::MenuItem("MIDI Logger")) addAtMouse("midi_logger");
                    ImGui::EndMenu();
                }
                
                if (ImGui::BeginMenu("Analysis")) {
                    if (ImGui::MenuItem("Scope")) addAtMouse("scope");
                    if (ImGui::MenuItem("Debug")) addAtMouse("debug");
                    if (ImGui::MenuItem("Input Debug")) addAtMouse("input_debug");
                    if (ImGui::MenuItem("Frequency Graph")) addAtMouse("frequency_graph");
                    ImGui::EndMenu();
                }
                if (ImGui::BeginMenu("TTS")) {
                    if (ImGui::MenuItem("TTS Performer")) addAtMouse("tts_performer");
                    if (ImGui::MenuItem("Vocal Tract Filter")) addAtMouse("vocal_tract_filter");
                    ImGui::EndMenu();
                }
                if (ImGui::BeginMenu("Special")) {
                    if (ImGui::MenuItem("Physics")) addAtMouse("physics");
                    if (ImGui::MenuItem("Animation")) addAtMouse("animation");
                    ImGui::EndMenu();
                }
                if (ImGui::BeginMenu("Computer Vision")) {
                    if (ImGui::MenuItem("Webcam Loader")) addAtMouse("webcam_loader");
                    if (ImGui::MenuItem("Video File Loader")) addAtMouse("video_file_loader");
                    ImGui::Separator();
                    if (ImGui::MenuItem("Movement Detector")) addAtMouse("movement_detector");
                    if (ImGui::MenuItem("Human Detector")) addAtMouse("human_detector");
                    if (ImGui::MenuItem("Object Detector")) addAtMouse("object_detector");
                    if (ImGui::MenuItem("Pose Estimator")) addAtMouse("pose_estimator");
                    if (ImGui::MenuItem("Hand Tracker")) addAtMouse("hand_tracker");
                    if (ImGui::MenuItem("Face Tracker")) addAtMouse("face_tracker");
                    if (ImGui::MenuItem("Color Tracker")) addAtMouse("color_tracker");
                    if (ImGui::MenuItem("Contour Detector")) addAtMouse("contour_detector");
                    if (ImGui::MenuItem("Semantic Segmentation")) addAtMouse("semantic_segmentation");
                    ImGui::EndMenu();
                }
                
                if (ImGui::BeginMenu("Plugins / VST")) {
                    addPluginModules(); // Re-use your existing plugin menu logic
                    ImGui::EndMenu();
                }
                
                if (ImGui::BeginMenu("System")) {
                    if (ImGui::MenuItem("Meta")) addAtMouse("meta");
                    if (ImGui::MenuItem("Inlet")) addAtMouse("inlet");
                    if (ImGui::MenuItem("Outlet")) addAtMouse("outlet");
                    if (ImGui::MenuItem("Comment")) addAtMouse("comment");
                    if (ImGui::MenuItem("Recorder")) addAtMouse("recorder");
                    if (ImGui::MenuItem("VST Host")) addAtMouse("vst_host");
                    ImGui::Separator();
                    if (ImGui::MenuItem("Best Practice")) addAtMouse("best_practice");
                    ImGui::EndMenu();
                }
            }
            else
            {
                // --- SEARCH MODE (Text has been entered) ---
                // Build list of matching modules first for keyboard navigation
                struct MatchedModule {
                    juce::String displayName;
                    const char* internalType;
                    const char* description;
                };
                std::vector<MatchedModule> matches;
                
                for (const auto& entry : getModuleRegistry())
                {
                    const juce::String& displayName = entry.first;
                    const char* internalType = entry.second.first;
                    const char* description = entry.second.second;
                    
                    if (displayName.containsIgnoreCase(filter))
                    {
                        matches.push_back({displayName, internalType, description});
                    }
                }
                
                // Handle keyboard navigation (arrow keys)
                if (ImGui::IsKeyPressed(ImGuiKey_DownArrow)) 
                {
                    selectedIndex++;
                    if (selectedIndex >= (int)matches.size()) 
                        selectedIndex = (int)matches.size() - 1;
                }
                if (ImGui::IsKeyPressed(ImGuiKey_UpArrow)) 
                {
                    selectedIndex--;
                    if (selectedIndex < 0) 
                        selectedIndex = 0;
                }
                
                // Handle Enter key to create selected module
                if (enterPressed && !matches.empty())
                {
                    if (selectedIndex >= 0 && selectedIndex < (int)matches.size())
                    {
                        addAtMouse(matches[selectedIndex].internalType);
                    }
                }
                
                // Display the matching modules with selection highlight
                for (int i = 0; i < (int)matches.size(); ++i)
                {
                    const auto& match = matches[i];
                    bool isSelected = (i == selectedIndex);
                    
                    if (ImGui::Selectable(match.displayName.toRawUTF8(), isSelected))
                    {
                        addAtMouse(match.internalType);
                    }
                    
                    // Auto-scroll to keep selected item visible
                    if (isSelected && ImGui::IsItemVisible() == false)
                    {
                        ImGui::SetScrollHereY(0.5f);
                    }
                    
                    if (ImGui::IsItemHovered())
                    {
                        ImGui::BeginTooltip();
                        ImGui::TextUnformatted(match.description);
                        ImGui::EndTooltip();
                    }
                }
                
                // Reset selection if out of bounds
                if (selectedIndex >= (int)matches.size())
                    selectedIndex = (int)matches.size() - 1;
                if (selectedIndex < 0)
                    selectedIndex = 0;
            }

            ImGui::EndChild();
            ImGui::EndPopup();
        }

        // Helper functions are now class methods

        // Handle user-created links (must be called after EndNodeEditor)
        int startAttr = 0, endAttr = 0;
        if (ImNodes::IsLinkCreated(&startAttr, &endAttr))
        {
            auto startPin = decodePinId(startAttr);
            auto endPin = decodePinId(endAttr);
            auto srcPin = startPin.isInput ? endPin : startPin;
            auto dstPin = startPin.isInput ? startPin : endPin;

            // Ensure connection is always Output -> Input
            if (!srcPin.isInput && dstPin.isInput)
            {
                PinDataType srcType = getPinDataTypeForPin(srcPin);
                PinDataType dstType = getPinDataTypeForPin(dstPin);

                bool conversionHandled = false;

                // Determine if a converter is needed based on pin types
                if (srcType == PinDataType::Audio && dstType == PinDataType::CV)
                {
                    insertNodeBetween("Attenuverter", srcPin, dstPin);
                    conversionHandled = true;
                }
                else if (srcType == PinDataType::CV && dstType == PinDataType::Gate)
                {
                    insertNodeBetween("Comparator", srcPin, dstPin);
                    conversionHandled = true;
                }
                else if (srcType == PinDataType::Audio && dstType == PinDataType::Gate)
                {
                    insertNodeBetween("Comparator", srcPin, dstPin);
                    conversionHandled = true;
                }
                else if (srcType == PinDataType::Raw && dstType != PinDataType::Raw)
                {
                    insertNodeBetween("MapRange", srcPin, dstPin);
                    conversionHandled = true;
                }

                if (conversionHandled)
                {
                    graphNeedsRebuild = true;
                    pushSnapshot();
                }
                else
                {
                    // All other combinations are considered directly compatible.
                    auto srcNode = synth->getNodeIdForLogical(srcPin.logicalId);
                    auto dstNode = (dstPin.logicalId == 0) ? synth->getOutputNodeID() : synth->getNodeIdForLogical(dstPin.logicalId);

                    synth->connect(srcNode, srcPin.channel, dstNode, dstPin.channel);
                    // Immediate commit for RecordModuleProcessor filename update
                    synth->commitChanges();

                    if (auto* dstModule = synth->getModuleForLogical(dstPin.logicalId)) {
                        if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(dstModule)) {
                            juce::String sourceName;
                            if (auto* srcModule = synth->getModuleForLogical(srcPin.logicalId)) {
                                sourceName = srcModule->getName();
                            }
                            recorder->updateSuggestedFilename(sourceName);
                        }
                    }

                    pushSnapshot();
                }
            }
        }

        // Handle link deletion (single)
        int linkId = 0;
        if (ImNodes::IsLinkDestroyed(&linkId))
        {
            if (auto it = linkIdToAttrs.find(linkId); it != linkIdToAttrs.end())
            {
                auto srcPin = decodePinId(it->second.first);
                auto dstPin = decodePinId(it->second.second);
                
                auto srcNode = synth->getNodeIdForLogical(srcPin.logicalId);
                auto dstNode = (dstPin.logicalId == 0) ? synth->getOutputNodeID() : synth->getNodeIdForLogical(dstPin.logicalId);

                // Debug log disconnect intent
                juce::Logger::writeToLog(
                    juce::String("[LinkDelete] src(lid=") + juce::String((int)srcPin.logicalId) + ",ch=" + juce::String(srcPin.channel) +
                    ") -> dst(lid=" + juce::String((int)dstPin.logicalId) + ",ch=" + juce::String(dstPin.channel) + ")");

                synth->disconnect(srcNode, srcPin.channel, dstNode, dstPin.channel);
                
                // Immediate commit for RecordModuleProcessor filename update
                synth->commitChanges();
                
                // After disconnecting, tell the recorder to update (pass empty string for unconnected)
                if (auto* dstModule = synth->getModuleForLogical(dstPin.logicalId))
                {
                    if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(dstModule))
                    {
                        recorder->updateSuggestedFilename(""); // Empty = unconnected
                    }
                }
                
                pushSnapshot();
                linkIdToAttrs.erase (it);
            }
        }
        // Handle link deletion (multi-select via Delete)

        // Keyboard shortcuts
        // Only process global keyboard shortcuts if no ImGui widget wants the keyboard
        if (!ImGui::GetIO().WantCaptureKeyboard)
        {
            const bool ctrl = ImGui::GetIO().KeyCtrl;
            const bool shift = ImGui::GetIO().KeyShift;
            const bool alt = ImGui::GetIO().KeyAlt;
            
            if (ctrl && ImGui::IsKeyPressed (ImGuiKey_S)) { startSaveDialog(); }
            if (ctrl && ImGui::IsKeyPressed (ImGuiKey_O)) { startLoadDialog(); }
            if (ctrl && ImGui::IsKeyPressed(ImGuiKey_P)) { handleRandomizePatch(); }
            if (ctrl && ImGui::IsKeyPressed(ImGuiKey_M)) { handleRandomizeConnections(); }
            if (ctrl && ImGui::IsKeyPressed(ImGuiKey_B)) { handleBeautifyLayout(); }
            if (ctrl && !shift && !alt && ImGui::IsKeyPressed(ImGuiKey_R, false)) { handleRecordOutput(); }
        
        // M: Mute/Bypass selected nodes (without Ctrl modifier)
        if (!ctrl && !alt && !shift && ImGui::IsKeyPressed(ImGuiKey_M, false) && ImNodes::NumSelectedNodes() > 0)
        {
            handleMuteToggle();
        }
        
        // Ctrl + A: Select All
        if (ctrl && !shift && ImGui::IsKeyPressed(ImGuiKey_A, false))
        {
            if (synth != nullptr)
            {
                const auto& modules = synth->getModulesInfo();
                std::vector<int> allNodeIds;
                allNodeIds.push_back(0); // Include output node
                for (const auto& mod : modules)
                {
                    allNodeIds.push_back((int)mod.first);
                }
                ImNodes::ClearNodeSelection();
                for (int id : allNodeIds)
                {
                    ImNodes::SelectNode(id);
                }
            }
        }
        
        // Ctrl + R: Reset selected node(s) to default parameters
        if (ctrl && ImGui::IsKeyPressed(ImGuiKey_R, false))
        {
            const int numSelected = ImNodes::NumSelectedNodes();
            if (numSelected > 0 && synth != nullptr)
            {
                // Create a single undo state for the entire operation
                pushSnapshot();
                
                std::vector<int> selectedNodeIds(numSelected);
                ImNodes::GetSelectedNodes(selectedNodeIds.data());

                for (int lid : selectedNodeIds)
                {
                    if (auto* module = synth->getModuleForLogical((juce::uint32)lid))
                    {
                        // Get all parameters for this module
                        auto& params = module->getParameters();
                        for (auto* paramBase : params)
                        {
                            // Cast to a ranged parameter to access default values
                            if (auto* param = dynamic_cast<juce::RangedAudioParameter*>(paramBase))
                            {
                                // Get the default value (normalized 0-1) and apply it
                                param->setValueNotifyingHost(param->getDefaultValue());
                            }
                        }
                        juce::Logger::writeToLog("[Reset] Reset parameters for node " + juce::String(lid));
                    }
                }
            }
        }
        
        // O: Connect selected to Output
        if (!ctrl && !alt && !shift && ImGui::IsKeyPressed(ImGuiKey_O, false) && ImNodes::NumSelectedNodes() == 1)
        {
            if (synth != nullptr)
            {
                int selectedId;
                ImNodes::GetSelectedNodes(&selectedId);
                if (selectedId != 0)
                {
                    synth->connect(synth->getNodeIdForLogical(selectedId), 0, synth->getOutputNodeID(), 0);
                    synth->connect(synth->getNodeIdForLogical(selectedId), 1, synth->getOutputNodeID(), 1);
                    graphNeedsRebuild = true;
                    pushSnapshot();
                }
            }
        }
        
        // Alt + D: Disconnect selected nodes
        if (alt && ImGui::IsKeyPressed(ImGuiKey_D, false) && ImNodes::NumSelectedNodes() > 0)
        {
            if (synth != nullptr)
            {
                std::vector<int> selectedNodeIds(ImNodes::NumSelectedNodes());
                ImNodes::GetSelectedNodes(selectedNodeIds.data());
                for (int id : selectedNodeIds)
                {
                    synth->clearConnectionsForNode(synth->getNodeIdForLogical(id));
                }
                graphNeedsRebuild = true;
                pushSnapshot();
            }
        }
        
        // --- REVISED 'F' and 'Home' KEY LOGIC ---
        auto frameNodes = [&](const std::vector<int>& nodeIds) {
            if (nodeIds.empty() || synth == nullptr) return;

            juce::Rectangle<float> bounds;
            bool foundAny = false;
            
            // Build a set of valid node IDs for checking
            std::unordered_set<int> validNodes;
            validNodes.insert(0); // Output node
            for (const auto& mod : synth->getModulesInfo())
                validNodes.insert((int)mod.first);
            
            for (size_t i = 0; i < nodeIds.size(); ++i)
            {
                // Ensure the node exists before getting its position
                if (validNodes.find(nodeIds[i]) != validNodes.end())
                {
                    ImVec2 pos = ImNodes::GetNodeGridSpacePos(nodeIds[i]);
                    if (!foundAny)
                    {
                        bounds = juce::Rectangle<float>(pos.x, pos.y, 1, 1);
                        foundAny = true;
                    }
                    else
                    {
                        bounds = bounds.getUnion(juce::Rectangle<float>(pos.x, pos.y, 1, 1));
                    }
                }
            }

            if (!foundAny) return;

            // Add some padding to the bounds
            if (!nodeIds.empty() && validNodes.find(nodeIds[0]) != validNodes.end())
                bounds = bounds.expanded(ImNodes::GetNodeDimensions(nodeIds[0]).x, ImNodes::GetNodeDimensions(nodeIds[0]).y);
            
            ImVec2 center((bounds.getX() + bounds.getRight()) * 0.5f, (bounds.getY() + bounds.getBottom()) * 0.5f);
            ImNodes::EditorContextResetPanning(center);
        };

        // F: Frame Selected
        if (!ctrl && !alt && !shift && ImGui::IsKeyPressed(ImGuiKey_F, false))
        {
            const int numSelected = ImNodes::NumSelectedNodes();
            if (numSelected > 0)
            {
                std::vector<int> selectedNodeIds(numSelected);
                ImNodes::GetSelectedNodes(selectedNodeIds.data());
                frameNodes(selectedNodeIds);
            }
        }

        // Home and Ctrl+Home: Frame All / Reset to Origin
        if (ImGui::IsKeyPressed(ImGuiKey_Home, false))
        {
            if (ctrl) // Ctrl+Home: Reset to origin
            {
                ImNodes::EditorContextResetPanning(ImVec2(0, 0));
            }
            else // Home: Frame all
            {
                if (synth != nullptr)
                {
                    auto modules = synth->getModulesInfo();
                    std::vector<int> allNodeIds;
                    allNodeIds.push_back(0); // Include output node
                    for (const auto& mod : modules)
                    {
                        allNodeIds.push_back((int)mod.first);
                    }
                    frameNodes(allNodeIds);
                }
            }
        }
        
        // Debug menu (Ctrl+Shift+D)
        if (ctrl && shift && ImGui::IsKeyPressed(ImGuiKey_D)) { showDebugMenu = !showDebugMenu; }

        // Undo / Redo (Ctrl+Z / Ctrl+Y)
    if (ctrl && ImGui::IsKeyPressed (ImGuiKey_Z))
        {
            if (undoStack.size() > 1)
            {
                Snapshot current = undoStack.back();
                redoStack.push_back (current);
                undoStack.pop_back();
                restoreSnapshot (undoStack.back());
                // After a restore, clear transient link maps only; keep pending positions so they apply next frame
                linkIdToAttrs.clear();
                // modLinkIdToRoute.clear(); // TODO: Remove when fully migrated
            }
        }
        if (ctrl && ImGui::IsKeyPressed (ImGuiKey_Y))
        {
            if (! redoStack.empty())
            {
                Snapshot s = redoStack.back(); redoStack.pop_back();
                restoreSnapshot (s);
                undoStack.push_back (s);
                linkIdToAttrs.clear();
                // modLinkIdToRoute.clear(); // TODO: Remove when fully migrated
            }
        }

        // Duplicate selected nodes (Ctrl+D) and Duplicate with connections (Shift+D)
        if ((ctrl || ImGui::GetIO().KeyShift) && ImGui::IsKeyPressed (ImGuiKey_D))
        {
            const int n = ImNodes::NumSelectedNodes();
            if (n > 0)
            {
                std::vector<int> sel((size_t) n);
                ImNodes::GetSelectedNodes(sel.data());
                for (int oldId : sel)
                {
                    if (oldId == 0) continue;
                    const juce::String type = getTypeForLogical ((juce::uint32) oldId);
                    if (type.isEmpty()) continue;
                    auto newNodeId = synth->addModule (type);
                    graphNeedsRebuild = true;
                    const juce::uint32 newLogical = synth->getLogicalIdForNode (newNodeId);
                    if (newLogical != 0)
                    {
                        if (auto* src = synth->getModuleForLogical ((juce::uint32) oldId))
                            if (auto* dst = synth->getModuleForLogical (newLogical))
                                dst->getAPVTS().replaceState (src->getAPVTS().copyState());
                        // Position offset
                        ImVec2 pos = ImNodes::GetNodeGridSpacePos (oldId);
                        pendingNodePositions[(int) newLogical] = ImVec2 (pos.x + 40.0f, pos.y + 40.0f);

                        // If Shift is held: duplicate connections into and out of this node
                        if (!ctrl && ImGui::GetIO().KeyShift)
                        {
                            const auto oldNode = synth->getNodeIdForLogical ((juce::uint32) oldId);
                            const auto newNode = newNodeId;
                            // Duplicate audio/CV connections
                            for (const auto& c : synth->getConnectionsInfo())
                            {
                                // Outgoing from old -> someone
                                if ((int) c.srcLogicalId == oldId)
                                {
                                    auto dstNode = (c.dstLogicalId == 0) ? synth->getOutputNodeID() : synth->getNodeIdForLogical (c.dstLogicalId);
                                    synth->connect (newNode, c.srcChan, dstNode, c.dstChan);
                                }
                                // Incoming from someone -> old
                                if ((int) c.dstLogicalId == oldId)
                                {
                                    auto srcNode = synth->getNodeIdForLogical (c.srcLogicalId);
                                    synth->connect (srcNode, c.srcChan, newNode, c.dstChan);
                                }
                            }
                            // TODO: Implement modulation route duplication for new bus-based system
                        }
                    }
                }
                pushSnapshot();
            }
        }
        
        } // End of keyboard shortcuts (WantCaptureKeyboard check)

        // Update selection for parameter panel
        {
            int selCount = ImNodes::NumSelectedNodes();
            if (selCount > 0)
            {
                std::vector<int> ids((size_t) selCount);
                ImNodes::GetSelectedNodes(ids.data());
                selectedLogicalId = ids.back();
            }
            else
            {
                selectedLogicalId = 0;
            }
        }

        handleDeletion();
    }

    // === MIDI DEVICE MANAGER WINDOW ===
    if (showMidiDeviceManager)
    {
        if (ImGui::Begin("MIDI Device Manager", &showMidiDeviceManager, ImGuiWindowFlags_AlwaysAutoResize))
        {
            ImGui::TextColored(ImVec4(0.6f, 0.8f, 1.0f, 1.0f), "MIDI Input Devices");
            ImGui::Separator();
            
            // Access MidiDeviceManager from PresetCreatorComponent
            auto* presetCreator = dynamic_cast<PresetCreatorComponent*>(getParentComponent());
            if (presetCreator && presetCreator->midiDeviceManager)
            {
                auto& midiMgr = *presetCreator->midiDeviceManager;
                const auto& devices = midiMgr.getDevices();
                
                if (devices.empty())
                {
                    ImGui::TextDisabled("No MIDI devices found");
                }
                else
                {
                    ImGui::Text("Found %d device(s):", (int)devices.size());
                    ImGui::Spacing();
                    
                    // Display each device
                    for (const auto& device : devices)
                    {
                        ImGui::PushID(device.identifier.toRawUTF8());
                        
                        // Checkbox to enable/disable device
                        bool enabled = device.enabled;
                        if (ImGui::Checkbox("##enabled", &enabled))
                        {
                            if (enabled)
                                midiMgr.enableDevice(device.identifier);
                            else
                                midiMgr.disableDevice(device.identifier);
                        }
                        
                        ImGui::SameLine();
                        
                        // Device name
                        ImGui::Text("%s", device.name.toRawUTF8());
                        
                        // Activity indicator
                        auto activity = midiMgr.getDeviceActivity(device.identifier);
                        if (activity.lastMessageTime > 0)
                        {
                            ImGui::SameLine();
                            float timeSinceMessage = (juce::Time::getMillisecondCounter() - activity.lastMessageTime) / 1000.0f;
                            if (timeSinceMessage < 1.0f)
                            {
                                ImGui::PushStyleColor(ImGuiCol_Text, IM_COL32(100, 255, 100, 255));
                                ImGui::Text("ACTIVE");
                                ImGui::PopStyleColor();
                            }
                            else
                            {
                                ImGui::PushStyleColor(ImGuiCol_Text, IM_COL32(100, 100, 100, 255));
                                ImGui::Text("idle");
                                ImGui::PopStyleColor();
                            }
                        }
                        
                        ImGui::PopID();
                    }
                }
                
                ImGui::Spacing();
                ImGui::Separator();
                ImGui::Spacing();
                
                // Rescan button
                if (ImGui::Button("Rescan Devices"))
                {
                    midiMgr.scanDevices();
                }
                
                ImGui::SameLine();
                
                // Enable/Disable all buttons
                if (ImGui::Button("Enable All"))
                {
                    midiMgr.enableAllDevices();
                }
                
                ImGui::SameLine();
                
                if (ImGui::Button("Disable All"))
                {
                    midiMgr.disableAllDevices();
                }
            }
            else
            {
                ImGui::TextDisabled("MIDI Manager not available");
            }
        }
        ImGui::End();
    }

    // === DEBUG WINDOW ===
    if (showDebugMenu)
    {
        if (ImGui::Begin("System Diagnostics", &showDebugMenu))
        {
            if (synth != nullptr)
            {
                ImGui::Text("=== SYSTEM OVERVIEW ===");
                if (ImGui::Button("Refresh"))
                {
                    // Force refresh of diagnostics
                }
                
                
                // System diagnostics
                ImGui::Text("System State:");
                juce::String systemDiag = synth->getSystemDiagnostics();
                ImGui::TextWrapped("%s", systemDiag.toUTF8());
                
                
                // Module selector
                ImGui::Text("Module Diagnostics:");
                auto modules = synth->getModulesInfo();
                if (!modules.empty())
                {
                    static int selectedModuleIndex = 0;
                    if (selectedModuleIndex >= (int)modules.size()) selectedModuleIndex = 0;
                    
                    juce::String moduleList = "";
                    for (size_t i = 0; i < modules.size(); ++i)
                    {
                        if (i > 0) moduleList += "\0";
                        moduleList += "Logical " + juce::String((int)modules[i].first) + ": " + modules[i].second;
                    }
                    moduleList += "\0";
                    
                    if (ImGui::Combo("Select Module", &selectedModuleIndex, moduleList.toUTF8()))
                    {
                        if (selectedModuleIndex < (int)modules.size())
                        {
                            juce::String moduleDiag = synth->getModuleDiagnostics(modules[selectedModuleIndex].first);
                            ImGui::TextWrapped("%s", moduleDiag.toUTF8());
                        }
                    }
                }
                else
                {
                    ImGui::Text("No modules found.");
                }
            }
            else
            {
                ImGui::Text("No synth processor available.");
            }
        }
        ImGui::End();
    }

    // Keyboard Shortcuts Help Window (F1)
    if (showShortcutsWindow)
    {
        ImGui::Begin("Keyboard Shortcuts", &showShortcutsWindow, ImGuiWindowFlags_AlwaysAutoResize);
        
        // --- NEW, COMPREHENSIVE SHORTCUT LIST ---

        ImGui::Text("Patch & File Management");
        ImGui::Separator();
        ImGui::BulletText("Ctrl + S: Save Preset.");
        ImGui::BulletText("Ctrl + O: Load Preset.");
        ImGui::BulletText("Ctrl + Z: Undo last action.");
        ImGui::BulletText("Ctrl + Y: Redo last action.");
        ImGui::BulletText("Ctrl + P: Generate a new random patch.");

        ImGui::Spacing();
        ImGui::Text("Node Creation & Deletion");
        ImGui::Separator();
        ImGui::BulletText("Right-click canvas: Open Quick Add menu to create a node.");
        ImGui::BulletText("Delete: Delete selected nodes and links.");
        ImGui::BulletText("Shift + Delete: Bypass-delete selected node(s), preserving signal chain.");
        ImGui::BulletText("Ctrl + D: Duplicate selected node(s).");
        ImGui::BulletText("Shift + D: Duplicate selected node(s) with their connections.");
        ImGui::BulletText("Ctrl + Shift + M: Collapse selected nodes into a new 'Meta Module'.");

        ImGui::Spacing();
        ImGui::Text("Connections & Signal Flow");
        ImGui::Separator();
        ImGui::BulletText("Right-click canvas -> Probe Signal: Enter Probe Mode.");
        ImGui::BulletText("  (In Probe Mode) Left-click output pin: Instantly view signal in the Probe Scope.");
        ImGui::BulletText("Right-click link: Open menu to insert a node on that cable.");
        ImGui::BulletText("I key (while hovering link): Open 'Insert Node' menu for that cable.");
        ImGui::BulletText("Ctrl + Middle-click link: Split a new cable from a connected output pin.");
        ImGui::BulletText("O key (with one node selected): Connect node's output to the Main Output.");
        ImGui::BulletText("Alt + D: Disconnect all cables from selected node(s).");
        ImGui::BulletText("Ctrl + M: Randomize connections between existing nodes.");
        ImGui::BulletText("C key (multi-select): Chain selected nodes (L->L, R->R).");
        ImGui::BulletText("G, B, Y, R keys (multi-select): Chain pins by type (Audio, CV, Gate, Raw).");
        
        ImGui::Spacing();
        ImGui::Text("Navigation & View");
        ImGui::Separator();
        ImGui::BulletText("F: Frame (zoom to fit) selected nodes.");
        ImGui::BulletText("Home: Frame all nodes in the patch.");
        ImGui::BulletText("Ctrl + Home: Reset view panning to the origin (0,0).");
        ImGui::BulletText("Ctrl + B: Automatically arrange nodes for a clean layout ('Beautify').");
        ImGui::BulletText("Ctrl + A: Select all nodes.");

        ImGui::Spacing();
        ImGui::Text("Parameter & Settings");
        ImGui::Separator();
        ImGui::BulletText("M key (with node(s) selected): Mute or Bypass the selected node(s).");
        ImGui::BulletText("Ctrl + R (with node(s) selected): Reset parameters of selected node(s) to default.");
        ImGui::BulletText("Ctrl + Shift + C: Copy selected node's settings to clipboard.");
        ImGui::BulletText("Ctrl + Shift + V: Paste settings to selected node (must be same type).");
        ImGui::BulletText("Mouse Wheel (on slider): Fine-tune parameter value.");

        ImGui::Spacing();
        ImGui::Text("General & Debugging");
        ImGui::Separator();
        ImGui::BulletText("Ctrl + R (no node selected): Insert a Recorder tapped into the Main Output.");
        ImGui::BulletText("Ctrl + Shift + D: Show System Diagnostics window.");
        ImGui::BulletText("F1: Toggle this help window.");
        
        ImGui::End();
    }

    ImGui::End();
    // drawPendingModPopup(); // TODO: Remove when fully migrated

    // No deferred snapshots; unified pre-state strategy
}

void ImGuiNodeEditorComponent::pushSnapshot()
{
    // Ensure any newly scheduled positions are flushed into the current UI state
    // by applying them immediately before capturing.
    if (! pendingNodePositions.empty())
    {
        // Temporarily mask rebuild flag to avoid ImNodes queries during capture
        const bool rebuilding = graphNeedsRebuild.load();
        if (rebuilding) {
            // getUiValueTree will still avoid ImNodes now, but assert safety
        }
        juce::ValueTree applied = getUiValueTree();
        for (const auto& kv : pendingNodePositions)
        {
            // Overwrite the entry for this node if present
            for (int i = 0; i < applied.getNumChildren(); ++i)
            {
                auto n = applied.getChild(i);
                if (n.hasType("node") && (int) n.getProperty("id", -1) == kv.first)
                { n.setProperty("x", kv.second.x, nullptr); n.setProperty("y", kv.second.y, nullptr); break; }
            }
        }
        // Do not commit pending positions of (0,0) which are placeholders
        for (int i = 0; i < applied.getNumChildren(); ++i)
        {
            auto n = applied.getChild(i);
            if (! n.hasType("node")) continue;
            const float x = (float) n.getProperty("x", 0.0f);
            const float y = (float) n.getProperty("y", 0.0f);
            if (x == 0.0f && y == 0.0f) {
                // Try to recover from last-known or pending
                const int nid = (int) n.getProperty("id", -1);
                auto itL = lastKnownNodePositions.find(nid);
                if (itL != lastKnownNodePositions.end()) { n.setProperty("x", itL->second.x, nullptr); n.setProperty("y", itL->second.y, nullptr); }
                else if (auto itP = pendingNodePositions.find(nid); itP != pendingNodePositions.end()) { n.setProperty("x", itP->second.x, nullptr); n.setProperty("y", itP->second.y, nullptr); }
            }
        }
        Snapshot s; s.uiState = applied; if (synth != nullptr) synth->getStateInformation (s.synthState);
        undoStack.push_back (std::move (s)); redoStack.clear();
        isPatchDirty = true; // Mark patch as dirty
        return;
    }
    Snapshot s; s.uiState = getUiValueTree();
    if (synth != nullptr) synth->getStateInformation (s.synthState);
    undoStack.push_back (std::move (s));
    redoStack.clear();
    
    // Mark patch as dirty whenever a change is made
    isPatchDirty = true;
}

void ImGuiNodeEditorComponent::restoreSnapshot (const Snapshot& s)
{
    if (synth != nullptr && s.synthState.getSize() > 0)
        synth->setStateInformation (s.synthState.getData(), (int) s.synthState.getSize());
    // Restore UI positions exactly as saved
    applyUiValueTreeNow (s.uiState);
}

juce::String ImGuiNodeEditorComponent::getTypeForLogical (juce::uint32 logicalId) const
{
    if (synth == nullptr) return {};
    for (const auto& p : synth->getModulesInfo())
        if (p.first == logicalId) return p.second;
    return {};
}

// Parameters are now drawn inline within each node; side panel removed


juce::ValueTree ImGuiNodeEditorComponent::getUiValueTree() const
{
    juce::ValueTree ui ("NodeEditorUI");
    if (synth == nullptr) return ui;
    // Save node positions
    for (const auto& mod : synth->getModulesInfo())
    {
        const int nid = (int) mod.first;
        
        // Prefer cached position if available; never query ImNodes while rebuilding
        ImVec2 pos;
        if (lastKnownNodePositions.count(nid) > 0)
        {
            pos = lastKnownNodePositions.at(nid);
        }
        else if (graphNeedsRebuild.load())
        {
            // Fallback to any pending position queued for this node
            auto it = pendingNodePositions.find(nid);
            pos = (it != pendingNodePositions.end()) ? it->second : ImVec2(0.0f, 0.0f);
        }
        else
        {
            pos = ImNodes::GetNodeGridSpacePos(nid);
        }
        
        juce::ValueTree n ("node");
        n.setProperty ("id", nid, nullptr);
        n.setProperty ("x", pos.x, nullptr);
        n.setProperty ("y", pos.y, nullptr);
        
        // --- FIX: Save muted/bypassed state ---
        // If this node's ID is in our map of muted nodes, add the property to the XML
        if (mutedNodeStates.count(nid) > 0)
        {
            n.setProperty("muted", true, nullptr);
        }
        
        ui.addChild (n, -1, nullptr);
    }
    
    // --- FIX: Explicitly save the output node position (ID 0) ---
    // The main output node is not part of getModulesInfo(), so we need to save it separately
    
    // Prefer cached output position; avoid ImNodes when rebuilding
    ImVec2 outputPos;
    if (lastKnownNodePositions.count(0) > 0)
        outputPos = lastKnownNodePositions.at(0);
    else if (graphNeedsRebuild.load())
    {
        auto it0 = pendingNodePositions.find(0);
        outputPos = (it0 != pendingNodePositions.end()) ? it0->second : ImVec2(0.0f, 0.0f);
    }
    else
        outputPos = ImNodes::GetNodeGridSpacePos(0);
    
    juce::ValueTree outputNode("node");
    outputNode.setProperty("id", 0, nullptr);
    outputNode.setProperty("x", outputPos.x, nullptr);
    outputNode.setProperty("y", outputPos.y, nullptr);
    ui.addChild(outputNode, -1, nullptr);
    // --- END OF FIX ---
    
    return ui;
}

void ImGuiNodeEditorComponent::applyUiValueTreeNow (const juce::ValueTree& uiState)
{
    if (! uiState.isValid() || synth == nullptr) return;
    
    juce::Logger::writeToLog("[UI_RESTORE] Applying UI ValueTree now...");

    // This is the core of the crash: the synth graph has already been rebuilt by setStateInformation.
    // We must clear our stale UI data (like muted nodes) before applying the new state from the preset.
    mutedNodeStates.clear();
    
    auto nodes = uiState; // expect tag NodeEditorUI
    for (int i = 0; i < nodes.getNumChildren(); ++i)
    {
        auto n = nodes.getChild(i);
        
        if (! n.hasType ("node")) continue;
        const int nid = (int) n.getProperty ("id", 0);

        // ========================= THE FIX STARTS HERE =========================
        //
        // Before applying any property, VERIFY that this node ID actually exists
        // in the synth. This prevents crashes when loading presets that contain
        // modules which are not available in the current build.
        //
        bool nodeExistsInSynth = (nid == 0); // Node 0 is always the output node.
        if (!nodeExistsInSynth) {
            for (const auto& modInfo : synth->getModulesInfo()) {
                if ((int)modInfo.first == nid) {
                    nodeExistsInSynth = true;
                    break;
                }
            }
        }

        if (!nodeExistsInSynth)
        {
            juce::Logger::writeToLog("[UI_RESTORE] WARNING: Skipping UI properties for non-existent node ID " + juce::String(nid) + ". The module may be missing or failed to load.");
            continue; // Skip to the next node in the preset.
        }
        // ========================== END OF FIX ==========================

        const float x = (float) n.getProperty ("x", 0.0f);
        const float y = (float) n.getProperty ("y", 0.0f);
        if (!(x == 0.0f && y == 0.0f))
        {
            pendingNodePositions[nid] = ImVec2(x, y);
            juce::Logger::writeToLog("[UI_RESTORE] Queued position for node " + juce::String(nid) + ": (" + juce::String(x) + ", " + juce::String(y) + ")");
        }
        
        // Read and apply muted state from preset for existing nodes.
        if ((bool) n.getProperty("muted", false))
        {
            // Use muteNodeSilent to store the original connections first,
            // then apply the mute (which creates bypass connections)
            muteNodeSilent(nid);
            muteNode(nid);
        }
    }
    
    // Muting/unmuting modifies graph connections, so we must tell the
    // synth to rebuild its processing order.
    graphNeedsRebuild = true;
    juce::Logger::writeToLog("[UI_RESTORE] UI state applied. Flagging for graph rebuild.");
}

void ImGuiNodeEditorComponent::applyUiValueTree (const juce::ValueTree& uiState)
{
    // Queue for next frame to avoid calling imnodes setters before editor is begun
    uiPending = uiState;
}

void ImGuiNodeEditorComponent::handleDeletion()
{
    if (synth == nullptr)
        return;

    // Shift+Delete => bypass delete (keep chain intact)
    if ((ImGui::GetIO().KeyShift) && ImGui::IsKeyPressed(ImGuiKey_Delete))
    {
        bypassDeleteSelectedNodes();
        return;
    }

    // Use new key query API (1.90+) for normal delete
    if (! ImGui::IsKeyPressed(ImGuiKey_Delete))
        return;

    // If a drag was in progress, capture positions before we mutate the graph
    if (isDraggingNode || ImGui::IsMouseDragging(ImGuiMouseButton_Left))
    {
        isDraggingNode = false;
        pushSnapshot();
    }

    // Early out if nothing selected
    const int numSelLinks = ImNodes::NumSelectedLinks();
    const int numSelNodes = ImNodes::NumSelectedNodes();

    if (numSelLinks <= 0 && numSelNodes <= 0)
        return;

    // Perform batch delete; snapshot after commit

    // Disconnect selected links
        if (numSelLinks > 0)
        {
        std::vector<int> ids((size_t) numSelLinks);
        ImNodes::GetSelectedLinks(ids.data());
        for (int id : ids)
        {
            // TODO: Handle modulation link deletion for new bus-based system
            // if (auto itM = modLinkIdToRoute.find (id); itM != modLinkIdToRoute.end())
            // {
            //     int sL, sC, dL; juce::String paramId; std::tie(sL, sC, dL, paramId) = itM->second;
            //     // TODO: Handle modulation route removal
            //     // if (paramId.isNotEmpty())
            //     //     synth->removeModulationRoute (synth->getNodeIdForLogical ((juce::uint32) sL), sC, (juce::uint32) dL, paramId);
            //     // else
            //     //     synth->removeModulationRoute (synth->getNodeIdForLogical ((juce::uint32) sL), sC, (juce::uint32) dL);
            // }
            // else 
            if (auto it = linkIdToAttrs.find(id); it != linkIdToAttrs.end())
            {
                auto srcPin = decodePinId(it->second.first);
                auto dstPin = decodePinId(it->second.second);

                auto srcNode = synth->getNodeIdForLogical(srcPin.logicalId);
                auto dstNode = (dstPin.logicalId == 0) ? synth->getOutputNodeID() : synth->getNodeIdForLogical(dstPin.logicalId);
                synth->disconnect(srcNode, srcPin.channel, dstNode, dstPin.channel);
            }
            }
        }

        if (numSelNodes > 0)
        {
        std::vector<int> nodeIds((size_t) numSelNodes);
        ImNodes::GetSelectedNodes(nodeIds.data());
        // Build a set for quick lookup when removing connections
        std::unordered_map<int, bool> toDelete;
        for (int nid : nodeIds) toDelete[nid] = true;
        // Disconnect all connections touching any selected node
        for (const auto& c : synth->getConnectionsInfo())
        {
            if (toDelete.count((int) c.srcLogicalId) || (! c.dstIsOutput && toDelete.count((int) c.dstLogicalId)))
            {
                auto srcNode = synth->getNodeIdForLogical(c.srcLogicalId);
                auto dstNode = c.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(c.dstLogicalId);
                synth->disconnect(srcNode, c.srcChan, dstNode, c.dstChan);
            }
        }
        // Remove nodes
        for (int nid : nodeIds)
        {
            if (nid == 0) continue; // don't delete output sink
            
            // Clean up vision module textures if exists
            if (visionModuleTextures.count(nid))
            {
                visionModuleTextures.erase(nid);
            }
            
            // Clean up sample loader textures if exists
            if (sampleLoaderTextureIds.count(nid))
            {
                sampleLoaderTextureIds.erase(nid);
            }
            
            mutedNodeStates.erase((juce::uint32)nid); // Clean up muted state if exists
            lastKnownNodePositions.erase(nid); // Clean up position cache
            synth->removeModule(synth->getNodeIdForLogical((juce::uint32) nid));
        }
    }
    graphNeedsRebuild = true;
    pushSnapshot();
}

void ImGuiNodeEditorComponent::bypassDeleteSelectedNodes()
{
    const int numSelNodes = ImNodes::NumSelectedNodes();
    if (numSelNodes <= 0 || synth == nullptr) return;

    // Snapshot positions first if dragging
    if (isDraggingNode || ImGui::IsMouseDragging(ImGuiMouseButton_Left))
    {
        isDraggingNode = false;
        pushSnapshot();
    }

    std::vector<int> nodeIds((size_t) numSelNodes);
    ImNodes::GetSelectedNodes(nodeIds.data());

    for (int nid : nodeIds)
    {
        if (nid == 0) continue; // don't bypass-delete the output sink
        bypassDeleteNode((juce::uint32) nid);
    }
    graphNeedsRebuild = true;
    pushSnapshot();
}

void ImGuiNodeEditorComponent::bypassDeleteNode(juce::uint32 logicalId)
{
    // Collect all incoming/outgoing audio links for this node
    std::vector<decltype(synth->getConnectionsInfo())::value_type> inputs, outputs;
    for (const auto& c : synth->getConnectionsInfo())
    {
        if (!c.dstIsOutput && c.dstLogicalId == logicalId) inputs.push_back(c);
        if (c.srcLogicalId == logicalId) outputs.push_back(c);
    }

    // For each output channel, find matching input channel to splice
    for (const auto& out : outputs)
    {
        // Try to find input with same channel index, else fallback to first input
        const auto* inPtr = (const decltype(inputs)::value_type*) nullptr;
        for (const auto& in : inputs) { if (in.dstChan == out.srcChan) { inPtr = &in; break; } }
        if (inPtr == nullptr && !inputs.empty()) inPtr = &inputs.front();

        // Disconnect out link first
        auto srcNode = synth->getNodeIdForLogical(out.srcLogicalId);
        auto dstNode = out.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(out.dstLogicalId);
        synth->disconnect(srcNode, out.srcChan, dstNode, out.dstChan);

        if (inPtr != nullptr)
        {
            // Disconnect incoming link from the node
            auto inSrcNode = synth->getNodeIdForLogical(inPtr->srcLogicalId);
            auto inDstNode = synth->getNodeIdForLogical(inPtr->dstLogicalId);
            synth->disconnect(inSrcNode, inPtr->srcChan, inDstNode, inPtr->dstChan);

            // Connect source of incoming directly to destination of outgoing
            auto finalDstNode = out.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(out.dstLogicalId);
            synth->connect(inSrcNode, inPtr->srcChan, finalDstNode, out.dstChan);
        }
    }

    // TODO: Remove modulation routes targeting or originating this node using new bus-based system

    // Finally remove the node itself
    mutedNodeStates.erase(logicalId); // Clean up muted state if exists
    synth->removeModule(synth->getNodeIdForLogical(logicalId));
}

// === Non-Destructive Mute/Bypass Implementation ===

void ImGuiNodeEditorComponent::muteNodeSilent(juce::uint32 logicalId)
{
    // This function is used when loading presets. It records the connections that were
    // loaded from the XML without modifying the graph or creating bypass connections.
    // This preserves the original "unmuted" connections for later use.
    
    if (!synth) return;

    MutedNodeState state;
    auto allConnections = synth->getConnectionsInfo();

    // Store all connections attached to this node
    for (const auto& c : allConnections) {
        if (!c.dstIsOutput && c.dstLogicalId == logicalId) {
            state.incomingConnections.push_back(c);
        }
        if (c.srcLogicalId == logicalId) {
            state.outgoingConnections.push_back(c);
        }
    }

    // Store the state, but DON'T modify the graph or create bypass connections
    mutedNodeStates[logicalId] = state;
    juce::Logger::writeToLog("[MuteSilent] Node " + juce::String(logicalId) + 
                            " marked as muted, stored " + juce::String(state.incomingConnections.size()) + 
                            " incoming and " + juce::String(state.outgoingConnections.size()) + 
                            " outgoing connections.");
}

void ImGuiNodeEditorComponent::muteNode(juce::uint32 logicalId)
{
    if (!synth) return;

    MutedNodeState state;
    auto allConnections = synth->getConnectionsInfo();

    // 1. Find and store all connections attached to this node.
    for (const auto& c : allConnections) {
        if (!c.dstIsOutput && c.dstLogicalId == logicalId) {
            state.incomingConnections.push_back(c);
        }
        if (c.srcLogicalId == logicalId) {
            state.outgoingConnections.push_back(c);
        }
    }

    // 2. Disconnect all of them.
    for (const auto& c : state.incomingConnections) {
        synth->disconnect(synth->getNodeIdForLogical(c.srcLogicalId), c.srcChan, synth->getNodeIdForLogical(c.dstLogicalId), c.dstChan);
    }
    for (const auto& c : state.outgoingConnections) {
        auto dstNodeId = c.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(c.dstLogicalId);
        synth->disconnect(synth->getNodeIdForLogical(c.srcLogicalId), c.srcChan, dstNodeId, c.dstChan);
    }
    
    // --- FIX: More robust bypass splicing logic ---
    // 3. Splice the connections to bypass the node.
    // Connect the FIRST input source to ALL output destinations.
    // This correctly handles cases where input channel != output channel (e.g., Mixer input 3  output 0).
    if (!state.incomingConnections.empty() && !state.outgoingConnections.empty())
    {
        const auto& primary_input = state.incomingConnections[0];
        auto srcNodeId = synth->getNodeIdForLogical(primary_input.srcLogicalId);

        for (const auto& out_conn : state.outgoingConnections)
        {
            auto dstNodeId = out_conn.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(out_conn.dstLogicalId);
            // Connect the primary input's source directly to the original output's destination
            synth->connect(srcNodeId, primary_input.srcChan, dstNodeId, out_conn.dstChan);
            juce::Logger::writeToLog("[Mute] Splicing bypass: [" + juce::String(primary_input.srcLogicalId) + 
                                    ":" + juce::String(primary_input.srcChan) + "] -> [" + 
                                    (out_conn.dstIsOutput ? "Output" : juce::String(out_conn.dstLogicalId)) + 
                                    ":" + juce::String(out_conn.dstChan) + "]");
        }
    }

    // 4. Store the original state.
    mutedNodeStates[logicalId] = state;
    juce::Logger::writeToLog("[Mute] Node " + juce::String(logicalId) + " muted and bypassed.");
}

void ImGuiNodeEditorComponent::unmuteNode(juce::uint32 logicalId)
{
    if (!synth || mutedNodeStates.find(logicalId) == mutedNodeStates.end()) return;

    MutedNodeState state = mutedNodeStates[logicalId];

    // --- FIX: Remove bypass connections matching the new mute logic ---
    // 1. Find and remove the bypass connections.
    // The bypass connected the first input source to all output destinations.
    if (!state.incomingConnections.empty() && !state.outgoingConnections.empty())
    {
        const auto& primary_input = state.incomingConnections[0];
        auto srcNodeId = synth->getNodeIdForLogical(primary_input.srcLogicalId);

        for (const auto& out_conn : state.outgoingConnections)
        {
            auto dstNodeId = out_conn.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(out_conn.dstLogicalId);
            // Disconnect the bypass connection
            synth->disconnect(srcNodeId, primary_input.srcChan, dstNodeId, out_conn.dstChan);
            juce::Logger::writeToLog("[Unmute] Removing bypass: [" + juce::String(primary_input.srcLogicalId) + 
                                    ":" + juce::String(primary_input.srcChan) + "] -> [" + 
                                    (out_conn.dstIsOutput ? "Output" : juce::String(out_conn.dstLogicalId)) + 
                                    ":" + juce::String(out_conn.dstChan) + "]");
        }
    }

    // 2. Restore the original connections.
    for (const auto& c : state.incomingConnections) {
        synth->connect(synth->getNodeIdForLogical(c.srcLogicalId), c.srcChan, synth->getNodeIdForLogical(c.dstLogicalId), c.dstChan);
    }
    for (const auto& c : state.outgoingConnections) {
        auto dstNodeId = c.dstIsOutput ? synth->getOutputNodeID() : synth->getNodeIdForLogical(c.dstLogicalId);
        synth->connect(synth->getNodeIdForLogical(c.srcLogicalId), c.srcChan, dstNodeId, c.dstChan);
    }

    // 3. Remove from muted state.
    mutedNodeStates.erase(logicalId);
    juce::Logger::writeToLog("[Mute] Node " + juce::String(logicalId) + " unmuted.");
}

void ImGuiNodeEditorComponent::handleMuteToggle()
{
    const int numSelected = ImNodes::NumSelectedNodes();
    if (numSelected == 0) return;

    pushSnapshot(); // Create a single undo state for the whole operation.

    std::vector<int> selectedNodeIds(numSelected);
    ImNodes::GetSelectedNodes(selectedNodeIds.data());

    for (int lid : selectedNodeIds) {
        if (mutedNodeStates.count(lid)) {
            unmuteNode(lid);
        } else {
            muteNode(lid);
        }
    }

    graphNeedsRebuild = true;
}

void ImGuiNodeEditorComponent::startSaveDialog()
{
    saveChooser = std::make_unique<juce::FileChooser> ("Save preset", findPresetsDirectory(), "*.xml");
    saveChooser->launchAsync (juce::FileBrowserComponent::saveMode | juce::FileBrowserComponent::canSelectFiles,
        [this] (const juce::FileChooser& fc)
    {
        auto f = fc.getResult();
        if (! f.exists() && ! f.getParentDirectory().exists()) return;
        if (synth == nullptr) return;
        
        // --- FIX: Temporarily unmute nodes to save original connections ---
        // Collect all currently muted nodes
        std::vector<juce::uint32> currentlyMutedNodes;
        for (const auto& pair : mutedNodeStates)
        {
            currentlyMutedNodes.push_back(pair.first);
        }
        
        // Temporarily UNMUTE all of them to restore the original connections
        for (juce::uint32 lid : currentlyMutedNodes)
        {
            unmuteNode(lid);
        }
        
        // Force the synth to apply these connection changes immediately
        if (synth)
        {
            synth->commitChanges();
        }
        // At this point, the synth graph is in its "true", unmuted state
        
        // NOW get the state - this will save the correct, original connections
        juce::MemoryBlock mb; synth->getStateInformation (mb);
        auto xml = juce::XmlDocument::parse (mb.toString());
        
        // IMMEDIATELY RE-MUTE the nodes to return the editor to its visible state
        for (juce::uint32 lid : currentlyMutedNodes)
        {
            muteNode(lid);
        }
        
        // Force the synth to apply the re-mute changes immediately
        if (synth)
        {
            synth->commitChanges();
        }
        // The synth graph is now back to its bypassed state for audio processing
        // --- END OF FIX ---
        
        if (! xml) return;
        juce::ValueTree presetVT = juce::ValueTree::fromXml (*xml);
        presetVT.addChild (getUiValueTree(), -1, nullptr);
        f.replaceWithText (presetVT.createXml()->toString());
        
        // Update preset status tracking
        isPatchDirty = false;
        currentPresetFile = f.getFileName();
    });
}

void ImGuiNodeEditorComponent::startLoadDialog()
{
    loadChooser = std::make_unique<juce::FileChooser> ("Load preset", findPresetsDirectory(), "*.xml");
    loadChooser->launchAsync (juce::FileBrowserComponent::openMode | juce::FileBrowserComponent::canSelectFiles,
        [this] (const juce::FileChooser& fc)
    {
        auto f = fc.getResult();
        if (f.existsAsFile())
        {
            loadPresetFromFile(f); // Use the unified loading function
        }
    });
}

void ImGuiNodeEditorComponent::handleRandomizePatch()
{
    if (synth == nullptr) return;
    
    populatePinDatabase();

    // 1. --- SETUP ---
    synth->clearAll();
    juce::Random rng(juce::Time::getMillisecondCounterHiRes());
    
    // 2. --- ADD A "CLOUD" OF RANDOM MODULES ---
    std::vector<juce::String> modulePool = {
        "VCO", "Noise", "Sequencer", "VCF", "Delay", "Reverb", "Waveshaper",
        "LFO", "ADSR", "Random", "S&H", "Math", "MapRange", "Quantizer", "ClockDivider"
    };
    int numModules = 6 + rng.nextInt(7); // 6 to 12 modules
    std::vector<std::pair<juce::uint32, juce::String>> addedModules;

    for (int i = 0; i < numModules; ++i) {
        auto type = modulePool[rng.nextInt(modulePool.size())];
        auto newId = synth->getLogicalIdForNode(synth->addModule(type));
        addedModules.push_back({newId, type});
    }

    // 3. --- ESTABLISH AN OBSERVATION POINT ---
    // Always add a Mixer and Scope. This is our window into the chaos.
    auto mixerId = synth->getLogicalIdForNode(synth->addModule("mixer"));
    addedModules.push_back({mixerId, "Mixer"});
    auto scopeId = synth->getLogicalIdForNode(synth->addModule("scope"));
    addedModules.push_back({scopeId, "Scope"});
    
    // Connect the observation path: Mixer -> Scope -> Output
    auto outputNodeId = synth->getOutputNodeID();
    synth->connect(synth->getNodeIdForLogical(mixerId), 0, synth->getNodeIdForLogical(scopeId), 0);
    synth->connect(synth->getNodeIdForLogical(scopeId), 0, outputNodeId, 0);
    synth->connect(synth->getNodeIdForLogical(scopeId), 1, outputNodeId, 1);

    // 4. --- CREATE CHAOTIC CONNECTIONS ---
    std::vector<std::pair<juce::uint32, AudioPin>> allAudioOuts;
    std::vector<std::pair<juce::uint32, AudioPin>> allAudioIns;
    std::vector<std::pair<juce::uint32, ModPin>> allModIns;

    for (const auto& mod : addedModules) {
        auto it = getModulePinDatabase().find(mod.second);
        if (it != getModulePinDatabase().end()) {
            for(const auto& pin : it->second.audioOuts) allAudioOuts.push_back({mod.first, pin});
            for(const auto& pin : it->second.audioIns) allAudioIns.push_back({mod.first, pin});
            for(const auto& pin : it->second.modIns) allModIns.push_back({mod.first, pin});
        }
    }
    
    // Connect a few random audio sources to the Mixer to make sound likely
    int numMixerInputs = 2 + rng.nextInt(3); // 2 to 4 mixer inputs
    if (!allAudioOuts.empty()) {
        for (int i = 0; i < numMixerInputs; ++i) {
            auto& source = allAudioOuts[rng.nextInt(allAudioOuts.size())];
            // Connect to mixer inputs 0, 1, 2, 3
            synth->connect(synth->getNodeIdForLogical(source.first), source.second.channel, synth->getNodeIdForLogical(mixerId), i);
        }
    }

    // Make a large number of fully random connections
    int numRandomConnections = numModules + rng.nextInt(numModules);
    for (int i = 0; i < numRandomConnections; ++i)
    {
        float choice = rng.nextFloat();
        // 70% chance of making a CV modulation connection
        if (choice < 0.7f && !allAudioOuts.empty() && !allModIns.empty()) {
            auto& source = allAudioOuts[rng.nextInt(allAudioOuts.size())];
            auto& target = allModIns[rng.nextInt(allModIns.size())];
            // TODO: synth->addModulationRouteByLogical(source.first, source.second.channel, target.first, target.second.paramId);
        }
        // 30% chance of making an audio-path or gate connection
        else if (!allAudioOuts.empty() && !allAudioIns.empty()) {
            auto& source = allAudioOuts[rng.nextInt(allAudioOuts.size())];
            auto& target = allAudioIns[rng.nextInt(allAudioIns.size())];
            // Allow self-connection for feedback
            if (source.first != target.first || rng.nextFloat() < 0.2f) {
                synth->connect(synth->getNodeIdForLogical(source.first), source.second.channel, synth->getNodeIdForLogical(target.first), target.second.channel);
            }
        }
    }

    // 5. --- LAYOUT AND FINALIZE ---
    // Arrange nodes in a neat grid to prevent overlap.
    const float startX = 50.0f;
    const float startY = 50.0f;
    const float cellWidth = 300.0f;
    const float cellHeight = 400.0f;
    const int numColumns = 4;
    int col = 0;
    int row = 0;

    juce::uint32 finalMixerId = 0, finalScopeId = 0;
    for (const auto& mod : addedModules) {
        if (mod.second == "Mixer") finalMixerId = mod.first;
        if (mod.second == "Scope") finalScopeId = mod.first;
    }

    for (const auto& mod : addedModules)
    {
        // Skip the special output-chain nodes; we will place them manually.
        if (mod.first == finalMixerId || mod.first == finalScopeId) continue;

        float x = startX + col * cellWidth;
        float y = startY + row * cellHeight;
        pendingNodePositions[(int)mod.first] = ImVec2(x, y);

        col++;
        if (col >= numColumns) {
            col = 0;
            row++;
        }
    }

    // Manually place the Mixer and Scope on the far right for a clean, readable signal flow.
    float finalX = startX + numColumns * cellWidth;
    if (finalMixerId != 0) pendingNodePositions[(int)finalMixerId] = ImVec2(finalX, startY);
    if (finalScopeId != 0) pendingNodePositions[(int)finalScopeId] = ImVec2(finalX, startY + cellHeight);
    
    synth->commitChanges();
    pushSnapshot();
}

void ImGuiNodeEditorComponent::handleRandomizeConnections()
{
    if (synth == nullptr) return;
    auto currentModules = synth->getModulesInfo();
    if (currentModules.empty()) return;

    // 1. --- SETUP AND CLEAR ---
    synth->clearAllConnections();
    juce::Random rng(juce::Time::getMillisecondCounterHiRes());

    // 2. --- ESTABLISH AN OBSERVATION POINT ---
    juce::uint32 mixerId = 0, scopeId = 0;
    for (const auto& mod : currentModules) {
        if (mod.second == "Mixer") mixerId = mod.first;
        if (mod.second == "Scope") scopeId = mod.first;
    }
    // Add Mixer/Scope if they don't exist, as they are crucial for listening
    if (mixerId == 0) mixerId = synth->getLogicalIdForNode(synth->addModule("mixer"));
    if (scopeId == 0) scopeId = synth->getLogicalIdForNode(synth->addModule("scope"));

    auto outputNodeId = synth->getOutputNodeID();
    synth->connect(synth->getNodeIdForLogical(mixerId), 0, synth->getNodeIdForLogical(scopeId), 0);
    synth->connect(synth->getNodeIdForLogical(scopeId), 0, outputNodeId, 0);

    // 3. --- CREATE CHAOTIC CONNECTIONS ---
    std::vector<std::pair<juce::uint32, AudioPin>> allAudioOuts;
    std::vector<std::pair<juce::uint32, AudioPin>> allAudioIns;
    std::vector<std::pair<juce::uint32, ModPin>> allModIns;
    
    // Refresh module list in case we added a Mixer/Scope
    auto updatedModules = synth->getModulesInfo();
    for (const auto& mod : updatedModules) {
        auto it = getModulePinDatabase().find(mod.second);
        if (it != getModulePinDatabase().end()) {
            for(const auto& pin : it->second.audioOuts) allAudioOuts.push_back({mod.first, pin});
            for(const auto& pin : it->second.audioIns) allAudioIns.push_back({mod.first, pin});
            for(const auto& pin : it->second.modIns) allModIns.push_back({mod.first, pin});
        }
    }
    
    // Connect random sources to the Mixer
    int numMixerInputs = 2 + rng.nextInt(3);
    if (!allAudioOuts.empty()) {
        for (int i = 0; i < numMixerInputs; ++i) {
            auto& source = allAudioOuts[rng.nextInt(allAudioOuts.size())];
            if (source.first != mixerId) // Don't connect mixer to itself here
                synth->connect(synth->getNodeIdForLogical(source.first), source.second.channel, synth->getNodeIdForLogical(mixerId), i);
        }
    }
    
    // Make a large number of fully random connections
    int numRandomConnections = (int)updatedModules.size() + rng.nextInt((int)updatedModules.size());
    for (int i = 0; i < numRandomConnections; ++i)
    {
        float choice = rng.nextFloat();
        if (choice < 0.7f && !allAudioOuts.empty() && !allModIns.empty()) {
            auto& source = allAudioOuts[rng.nextInt(allAudioOuts.size())];
            auto& target = allModIns[rng.nextInt(allModIns.size())];
            // TODO: synth->addModulationRouteByLogical(source.first, source.second.channel, target.first, target.second.paramId);
        }
        else if (!allAudioOuts.empty() && !allAudioIns.empty()) {
            auto& source = allAudioOuts[rng.nextInt(allAudioOuts.size())];
            auto& target = allAudioIns[rng.nextInt(allAudioIns.size())];
            if (source.first != target.first || rng.nextFloat() < 0.2f) { // Allow feedback
                synth->connect(synth->getNodeIdForLogical(source.first), source.second.channel, synth->getNodeIdForLogical(target.first), target.second.channel);
            }
        }
    }

    // 4. --- FINALIZE ---
    synth->commitChanges();
    pushSnapshot();
}

void ImGuiNodeEditorComponent::handleBeautifyLayout()
{
    if (synth == nullptr) return;

    // Graph is always in consistent state since we rebuild at frame start
    // Create an undo state so the action can be reversed
    pushSnapshot();
    juce::Logger::writeToLog("--- [Beautify Layout] Starting ---");

    // --- STEP 1: Build Graph Representation ---
    // Adjacency list: map<source_lid, vector<destination_lid>>
    std::map<juce::uint32, std::vector<juce::uint32>> adjacencyList;
    std::map<juce::uint32, int> inDegree; // Counts incoming connections for each node
    std::vector<juce::uint32> sourceNodes;

    auto modules = synth->getModulesInfo();
    for (const auto& mod : modules)
    {
        inDegree[mod.first] = 0;
        adjacencyList[mod.first] = {};
    }
    // Include the output node in the graph
    inDegree[0] = 0; // Output node ID is 0
    adjacencyList[0] = {}; // Output node has no outgoing connections

    for (const auto& conn : synth->getConnectionsInfo())
    {
        if (conn.dstIsOutput)
        {
            adjacencyList[conn.srcLogicalId].push_back(0); // Connect to output node
            inDegree[0]++;
        }
        else
        {
            adjacencyList[conn.srcLogicalId].push_back(conn.dstLogicalId);
            inDegree[conn.dstLogicalId]++;
        }
    }

    for (const auto& mod : modules)
    {
        if (inDegree[mod.first] == 0)
        {
            sourceNodes.push_back(mod.first);
        }
    }

    juce::Logger::writeToLog("[Beautify] Found " + juce::String(sourceNodes.size()) + " source nodes");

    // --- STEP 2: Assign Nodes to Columns (Topological Sort) ---
    std::map<juce::uint32, int> nodeColumn;
    std::vector<std::vector<juce::uint32>> columns;
    int maxColumn = 0;

    // Initialize source nodes in column 0
    for (juce::uint32 nodeId : sourceNodes)
    {
        nodeColumn[nodeId] = 0;
    }
    columns.push_back(sourceNodes);

    // Process each column and assign children to appropriate columns
    std::queue<juce::uint32> processQueue;
    for (juce::uint32 srcNode : sourceNodes)
        processQueue.push(srcNode);

    while (!processQueue.empty())
    {
        juce::uint32 u = processQueue.front();
        processQueue.pop();

        for (juce::uint32 v : adjacencyList[u])
        {
            // The column for node 'v' is the maximum of its predecessors' columns + 1
            int newColumn = nodeColumn[u] + 1;
            if (nodeColumn.count(v) == 0 || newColumn > nodeColumn[v])
            {
                nodeColumn[v] = newColumn;
                maxColumn = std::max(maxColumn, newColumn);
                processQueue.push(v);
            }
        }
    }

    // Re-populate columns based on assignments
    columns.assign(maxColumn + 1, {});
    for (const auto& pair : nodeColumn)
    {
        columns[pair.second].push_back(pair.first);
    }

    juce::Logger::writeToLog("[Beautify] Arranged nodes into " + juce::String(maxColumn + 1) + " columns");

    // --- STEP 3: Optimize Node Ordering Within Columns ---
    // Sort nodes in each column based on median position of their parents
    for (int c = 1; c <= maxColumn; ++c)
    {
        std::map<juce::uint32, float> medianPositions;
        
        for (juce::uint32 nodeId : columns[c])
        {
            std::vector<float> parentPositions;
            
            // Find all parents in previous columns
            for (const auto& pair : adjacencyList)
            {
                for (juce::uint32 dest : pair.second)
                {
                    if (dest == nodeId)
                    {
                        // Find the vertical index of the parent node
                        int parentColumn = nodeColumn[pair.first];
                        auto& parentColVec = columns[parentColumn];
                        auto it = std::find(parentColVec.begin(), parentColVec.end(), pair.first);
                        if (it != parentColVec.end())
                        {
                            parentPositions.push_back((float)std::distance(parentColVec.begin(), it));
                        }
                    }
                }
            }
            
            if (!parentPositions.empty())
            {
                std::sort(parentPositions.begin(), parentPositions.end());
                medianPositions[nodeId] = parentPositions[parentPositions.size() / 2];
            }
            else
            {
                medianPositions[nodeId] = 0.0f;
            }
        }
        
        // Sort the column based on median positions
        std::sort(columns[c].begin(), columns[c].end(), [&](juce::uint32 a, juce::uint32 b) {
            return medianPositions[a] < medianPositions[b];
        });
    }

    // --- STEP 4: Calculate Final Coordinates ---
    const float COLUMN_WIDTH = 400.0f;
    const float NODE_VERTICAL_PADDING = 50.0f;

    // Find the tallest column to center shorter ones
    float tallestColumnHeight = 0.0f;
    for (const auto& col : columns)
    {
        float height = 0.0f;
        for (juce::uint32 lid : col)
        {
            ImVec2 nodeSize = ImNodes::GetNodeDimensions((int)lid);
            height += nodeSize.y + NODE_VERTICAL_PADDING;
        }
        tallestColumnHeight = std::max(tallestColumnHeight, height);
    }

    // --- STEP 5: Apply Positions ---
    for (int c = 0; c <= maxColumn; ++c)
    {
        // Calculate column height for centering
        float columnHeight = 0.0f;
        for (juce::uint32 lid : columns[c])
        {
            columnHeight += ImNodes::GetNodeDimensions((int)lid).y + NODE_VERTICAL_PADDING;
        }
        
        // Start Y position (centered vertically)
        float currentY = (tallestColumnHeight - columnHeight) / 2.0f;

        for (juce::uint32 lid : columns[c])
        {
            float x = c * COLUMN_WIDTH;
            pendingNodePositions[(int)lid] = ImVec2(x, currentY);
            
            ImVec2 nodeSize = ImNodes::GetNodeDimensions((int)lid);
            currentY += nodeSize.y + NODE_VERTICAL_PADDING;
        }
    }

    // Position the output node to the right of all other modules
    float finalX = (maxColumn + 1) * COLUMN_WIDTH;
    float outputNodeY = (tallestColumnHeight - ImNodes::GetNodeDimensions(0).y) / 2.0f;
    pendingNodePositions[0] = ImVec2(finalX, outputNodeY);
    juce::Logger::writeToLog("[Beautify] Applied position to Output Node");
    
    juce::Logger::writeToLog("[Beautify] Applied positions to " + juce::String(modules.size()) + " nodes");
    juce::Logger::writeToLog("--- [Beautify Layout] Complete ---");
}

void ImGuiNodeEditorComponent::handleConnectSelectedToTrackMixer()
{
    if (synth == nullptr || ImNodes::NumSelectedNodes() <= 0)
    {
        juce::Logger::writeToLog("[AutoConnect] Aborted: No synth or no nodes selected.");
        return;
    }

    // This is a significant action, so create an undo state first.
    pushSnapshot();
    juce::Logger::writeToLog("--- [Connect to Mixer] Starting routine ---");

    // 1. Get all selected node IDs.
    const int numSelectedNodes = ImNodes::NumSelectedNodes();
    std::vector<int> selectedNodeLids(numSelectedNodes);
    ImNodes::GetSelectedNodes(selectedNodeLids.data());

    // 2. Find the geometric center of the selected nodes to position our new modules.
    float totalX = 0.0f, maxX = 0.0f, totalY = 0.0f;
    for (int lid : selectedNodeLids)
    {
        ImVec2 pos = ImNodes::GetNodeGridSpacePos(lid);
        totalX += pos.x;
        totalY += pos.y;
        if (pos.x > maxX) {
            maxX = pos.x;
        }
    }
    ImVec2 centerPos = ImVec2(totalX / numSelectedNodes, totalY / numSelectedNodes);
    
    // 3. Create the Value node and set its value to the number of selected nodes.
    auto valueNodeId = synth->addModule("value");
    auto valueLid = synth->getLogicalIdForNode(valueNodeId);
    if (auto* valueProc = dynamic_cast<ValueModuleProcessor*>(synth->getModuleForLogical(valueLid)))
    {
        if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(valueProc->getAPVTS().getParameter("value")))
        {
            *p = (float)numSelectedNodes;
            juce::Logger::writeToLog("[AutoConnect] Created Value node " + juce::String(valueLid) + " and set its value to " + juce::String(numSelectedNodes));
        }
    }
    // Position it slightly to the right of the center of the selection.
    pendingNodePositions[(int)valueLid] = ImVec2(centerPos.x + 400.0f, centerPos.y);

    // 4. Create the Track Mixer node.
    auto mixerNodeId = synth->addModule("track_mixer");
    auto mixerLid = synth->getLogicalIdForNode(mixerNodeId);
    // Position it to the right of the right-most selected node for a clean signal flow.
    pendingNodePositions[(int)mixerLid] = ImVec2(maxX + 800.0f, centerPos.y);
    juce::Logger::writeToLog("[AutoConnect] Created Track Mixer with logical ID " + juce::String(mixerLid));

    // 5. Connect the Value node to the Track Mixer's "Num Tracks Mod" input.
    // The Value module's "Raw" output is channel 0 (provides the exact value entered by the user).
    // The Track Mixer's "Num Tracks Mod" is on Bus 1, Channel 0, which is absolute channel 64.
    synth->connect(valueNodeId, 0, mixerNodeId, TrackMixerModuleProcessor::MAX_TRACKS);
    juce::Logger::writeToLog("[AutoConnect] Connected Value node 'Raw' output to Track Mixer's Num Tracks Mod input.");

    // 6. Connect the primary audio output of each selected node to a unique input on the Track Mixer.
    int mixerInputChannel = 0;
    for (int lid : selectedNodeLids)
    {
        if (mixerInputChannel >= TrackMixerModuleProcessor::MAX_TRACKS) break;

        auto sourceNodeId = synth->getNodeIdForLogical((juce::uint32)lid);
        
        // We will connect the first audio output (channel 0) of the source to the next available mixer input.
        synth->connect(sourceNodeId, 0, mixerNodeId, mixerInputChannel);
        juce::Logger::writeToLog("[AutoConnect] Connected node " + juce::String(lid) + " (Out 0) to Track Mixer (In " + juce::String(mixerInputChannel + 1) + ")");
        
        mixerInputChannel++;
    }

    // 7. Flag the graph for a rebuild to apply all changes.
    graphNeedsRebuild = true;
    juce::Logger::writeToLog("--- [Connect to Mixer] Routine complete. ---");
}

void ImGuiNodeEditorComponent::handleMidiPlayerAutoConnect(MIDIPlayerModuleProcessor* midiPlayer, juce::uint32 midiPlayerLid)
{
    if (!synth || !midiPlayer || midiPlayerLid == 0 || !midiPlayer->hasMIDIFileLoaded())
    {
        juce::Logger::writeToLog("[AutoConnect] Aborted: MIDI Player not ready.");
        return;
    }

    juce::Logger::writeToLog("--- [AutoConnect to Samplers] Starting routine for MIDI Player " + juce::String(midiPlayerLid) + " ---");

    // 1. Get initial positions and clear existing connections from the MIDI Player.
    auto midiPlayerNodeId = synth->getNodeIdForLogical(midiPlayerLid);
    ImVec2 midiPlayerPos = ImNodes::GetNodeGridSpacePos((int)midiPlayerLid);
    synth->clearConnectionsForNode(midiPlayerNodeId);

    // --- FIX: Create and position the Track Mixer first ---
    auto mixerNodeId = synth->addModule("track_mixer");
    auto mixerLid = synth->getLogicalIdForNode(mixerNodeId);
    pendingNodePositions[(int)mixerLid] = ImVec2(midiPlayerPos.x + 1200.0f, midiPlayerPos.y);
    juce::Logger::writeToLog("[AutoConnect] Created Track Mixer with logical ID " + juce::String(mixerLid));

    // --- FIX: Connect MIDI Player "Num Tracks" output to Track Mixer "Num Tracks Mod" input ---
    // This ensures the Track Mixer automatically adjusts its track count based on the MIDI file content
    synth->connect(midiPlayerNodeId, MIDIPlayerModuleProcessor::kNumTracksChannelIndex, mixerNodeId, TrackMixerModuleProcessor::MAX_TRACKS);
    juce::Logger::writeToLog("[AutoConnect] Connected MIDI Player Num Tracks to Track Mixer Num Tracks Mod");

    // 2. Create and connect a Sample Loader for each active MIDI track.
    const auto& activeTrackIndices = midiPlayer->getActiveTrackIndices();
    juce::Logger::writeToLog("[AutoConnect] MIDI file has " + juce::String(activeTrackIndices.size()) + " active tracks.");

    for (int i = 0; i < (int)activeTrackIndices.size(); ++i)
    {
        if (i >= MIDIPlayerModuleProcessor::kMaxTracks) break;

        // A. Create and position the new modules.
        auto samplerNodeId = synth->addModule("sample_loader");
        auto samplerLid = synth->getLogicalIdForNode(samplerNodeId);
        pendingNodePositions[(int)samplerLid] = ImVec2(midiPlayerPos.x + 800.0f, midiPlayerPos.y + (i * 350.0f));

        auto mapRangeNodeId = synth->addModule("map_range");
        auto mapRangeLid = synth->getLogicalIdForNode(mapRangeNodeId);
        pendingNodePositions[(int)mapRangeLid] = ImVec2(midiPlayerPos.x + 400.0f, midiPlayerPos.y + (i * 350.0f));
        
        // B. Configure the MapRange module for Pitch CV conversion.
        if (auto* mapRangeProc = dynamic_cast<MapRangeModuleProcessor*>(synth->getModuleForLogical(mapRangeLid)))
        {
            auto& ap = mapRangeProc->getAPVTS();
            // MIDI Player Pitch Out (0..1) -> Sample Loader Pitch Mod (-24..+24 semitones)
            if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("inMin"))) *p = 0.0f;
            if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("inMax"))) *p = 1.0f;
            if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("outMin"))) *p = -24.0f;
            if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(ap.getParameter("outMax"))) *p = 24.0f;
        }

        // C. Connect the outputs for this track.
        const int pitchChan = i * MIDIPlayerModuleProcessor::kOutputsPerTrack + 0;
        const int gateChan  = i * MIDIPlayerModuleProcessor::kOutputsPerTrack + 1;
        const int trigChan  = i * MIDIPlayerModuleProcessor::kOutputsPerTrack + 3;

        // Pitch: MIDI Player -> MapRange -> Sample Loader
        synth->connect(midiPlayerNodeId, pitchChan, mapRangeNodeId, 0); // Pitch Out -> MapRange In
        synth->connect(mapRangeNodeId, 1, samplerNodeId, 0);             // MapRange Raw Out -> SampleLoader Pitch Mod In

        // Gate: MIDI Player -> Sample Loader
        synth->connect(midiPlayerNodeId, gateChan, samplerNodeId, 2);    // Gate Out -> SampleLoader Gate Mod In

        // Trigger: MIDI Player -> Sample Loader
        synth->connect(midiPlayerNodeId, trigChan, samplerNodeId, 3);    // Trigger Out -> SampleLoader Trigger Mod In

        // --- FIX: Connect the Sample Loader's audio output to the Track Mixer ---
        // The Sample Loader's main audio output is channel 0.
        // The Track Mixer's inputs are mono channels 0, 1, 2...
        synth->connect(samplerNodeId, 0, mixerNodeId, i);
    }

    // --- FIX: Connect the mixer to the main output so you can hear it! ---
    auto outputNodeId = synth->getOutputNodeID();
    synth->connect(mixerNodeId, 0, outputNodeId, 0); // Mixer Out L -> Main Out L
    synth->connect(mixerNodeId, 1, outputNodeId, 1); // Mixer Out R -> Main Out R

    // 3. Flag the graph for a rebuild to apply all changes.
    graphNeedsRebuild = true;
    juce::Logger::writeToLog("--- [AutoConnect to Samplers] Routine complete. ---");
}

void ImGuiNodeEditorComponent::handleMidiPlayerAutoConnectVCO(MIDIPlayerModuleProcessor* midiPlayer, juce::uint32 midiPlayerLid)
{
    if (!synth || !midiPlayer || midiPlayerLid == 0 || !midiPlayer->hasMIDIFileLoaded())
    {
        juce::Logger::writeToLog("[AutoConnectVCO] Aborted: MIDI Player not ready.");
        return;
    }
    
    juce::Logger::writeToLog("--- [AutoConnectVCO] Starting routine for MIDI Player " + juce::String(midiPlayerLid) + " ---");

    // 1. Get initial positions and clear all existing connections from the MIDI Player.
    auto midiPlayerNodeId = synth->getNodeIdForLogical(midiPlayerLid);
    ImVec2 midiPlayerPos = ImNodes::GetNodeGridSpacePos((int)midiPlayerLid);
    synth->clearConnectionsForNode(midiPlayerNodeId);
    
    // 2. Create and position the PolyVCO and Track Mixer.
    auto polyVcoNodeId = synth->addModule("polyvco");
    auto polyVcoLid = synth->getLogicalIdForNode(polyVcoNodeId);
    pendingNodePositions[(int)polyVcoLid] = ImVec2(midiPlayerPos.x + 400.0f, midiPlayerPos.y);
    juce::Logger::writeToLog("[AutoConnectVCO] Created PolyVCO with logical ID " + juce::String(polyVcoLid));

    auto mixerNodeId = synth->addModule("track_mixer");
    auto mixerLid = synth->getLogicalIdForNode(mixerNodeId);
    pendingNodePositions[(int)mixerLid] = ImVec2(midiPlayerPos.x + 800.0f, midiPlayerPos.y);
    juce::Logger::writeToLog("[AutoConnectVCO] Created Track Mixer with logical ID " + juce::String(mixerLid));

    // 3. Connect the track count outputs to control both new modules.
    synth->connect(midiPlayerNodeId, MIDIPlayerModuleProcessor::kRawNumTracksChannelIndex, polyVcoNodeId, 0); // Raw Num Tracks -> PolyVCO Num Voices Mod
    synth->connect(midiPlayerNodeId, MIDIPlayerModuleProcessor::kRawNumTracksChannelIndex, mixerNodeId, TrackMixerModuleProcessor::MAX_TRACKS); // Raw Num Tracks -> Mixer Num Tracks Mod
    juce::Logger::writeToLog("[AutoConnectVCO] Connected MIDI Player raw track counts to PolyVCO and Track Mixer modulation inputs.");
    
    // 4. Loop through active MIDI tracks to connect CV routes and audio.
    const auto& activeTrackIndices = midiPlayer->getActiveTrackIndices();
    juce::Logger::writeToLog("[AutoConnectVCO] MIDI file has " + juce::String(activeTrackIndices.size()) + " active tracks. Patching voices...");

    for (int i = 0; i < (int)activeTrackIndices.size(); ++i)
    {
        if (i >= PolyVCOModuleProcessor::MAX_VOICES) break; // Don't try to connect more voices than the PolyVCO has

        int sourceTrackIndex = activeTrackIndices[i];

        // A. Connect CV modulation routes from MIDI Player to the corresponding PolyVCO voice.
        int pitchChan = i * MIDIPlayerModuleProcessor::kOutputsPerTrack + 0;
        int velChan   = i * MIDIPlayerModuleProcessor::kOutputsPerTrack + 2;
        
        // Connect MIDI CV to the corresponding PolyVCO voice inputs
        synth->connect(midiPlayerNodeId, pitchChan, polyVcoNodeId, 1 + i); // Pitch -> Freq Mod
        synth->connect(midiPlayerNodeId, velChan,   polyVcoNodeId, 1 + PolyVCOModuleProcessor::MAX_VOICES * 2 + i); // Velocity -> Gate Mod

        // B. Connect the PolyVCO voice's audio output to the Track Mixer's input.
        synth->connect(polyVcoNodeId, i, mixerNodeId, i);
    }
    
    // 5. Connect the Track Mixer to the main audio output.
    auto outputNodeId = synth->getOutputNodeID();
    synth->connect(mixerNodeId, 0, outputNodeId, 0); // Mixer Out L -> Main Out L
    synth->connect(mixerNodeId, 1, outputNodeId, 1); // Mixer Out R -> Main Out R
    
    // 6. Flag the graph for a rebuild.
    graphNeedsRebuild = true;
    juce::Logger::writeToLog("--- [AutoConnectVCO] Routine complete. ---");
}

void ImGuiNodeEditorComponent::handleMidiPlayerAutoConnectHybrid(MIDIPlayerModuleProcessor* midiPlayer, juce::uint32 midiPlayerLid)
{
    if (!synth || !midiPlayer) return;

    pushSnapshot();

    const int numTracks = midiPlayer->getNumTracks();
    if (numTracks == 0) return;

    auto midiPlayerNodeId = synth->getNodeIdForLogical(midiPlayerLid);
    ImVec2 midiPos = ImNodes::GetNodeGridSpacePos((int)midiPlayerLid);

    // --- THIS IS THE NEW "FIND-BY-TRACING" LOGIC ---

    juce::uint32 polyVcoLid = 0;
    juce::uint32 trackMixerLid = 0;

    // 1. Scan existing connections to find modules to reuse by tracing backwards.
    // First, find a TrackMixer connected to the output.
    for (const auto& conn : synth->getConnectionsInfo())
    {
        if (conn.dstIsOutput && synth->getModuleTypeForLogical(conn.srcLogicalId).equalsIgnoreCase("trackmixer"))
        {
            trackMixerLid = conn.srcLogicalId; // Found a TrackMixer to reuse!
            break;
        }
    }
    // If we found a TrackMixer, now find a PolyVCO connected to it.
    if (trackMixerLid != 0)
    {
        for (const auto& conn : synth->getConnectionsInfo())
        {
            if (conn.dstLogicalId == trackMixerLid && synth->getModuleTypeForLogical(conn.srcLogicalId).equalsIgnoreCase("polyvco"))
            {
                polyVcoLid = conn.srcLogicalId; // Found a PolyVCO to reuse!
                break;
            }
        }
    }

    // 2. Clear all old Pitch/Gate/Velocity connections from the MIDI Player.
    std::vector<ModularSynthProcessor::ConnectionInfo> oldConnections;
    for (const auto& conn : synth->getConnectionsInfo())
    {
        if (conn.srcLogicalId == midiPlayerLid && conn.srcChan < 16 * 3)
            oldConnections.push_back(conn);
    }
    for (const auto& conn : oldConnections)
    {
        synth->disconnect(synth->getNodeIdForLogical(conn.srcLogicalId), conn.srcChan,
                          synth->getNodeIdForLogical(conn.dstLogicalId), conn.dstChan);
    }

    // 3. If we didn't find a PolyVCO to reuse after tracing, create a new one.
    if (polyVcoLid == 0)
    {
        auto polyVcoNodeId = synth->addModule("polyvco", false);
        polyVcoLid = synth->getLogicalIdForNode(polyVcoNodeId);
        pendingNodePositions[(int)polyVcoLid] = ImVec2(midiPos.x + 400.0f, midiPos.y);
    }

    // 4. If we didn't find a TrackMixer to reuse after tracing, create a new one.
    if (trackMixerLid == 0)
    {
        auto trackMixerNodeId = synth->addModule("track_mixer", false);
        trackMixerLid = synth->getLogicalIdForNode(trackMixerNodeId);
        pendingNodePositions[(int)trackMixerLid] = ImVec2(midiPos.x + 800.0f, midiPos.y);
    }
    // --- END OF NEW LOGIC ---

    auto polyVcoNodeId = synth->getNodeIdForLogical(polyVcoLid);
    auto trackMixerNodeId = synth->getNodeIdForLogical(trackMixerLid);

    if (auto* vco = dynamic_cast<PolyVCOModuleProcessor*>(synth->getModuleForLogical(polyVcoLid)))
        if (auto* p = dynamic_cast<juce::AudioParameterInt*>(vco->getAPVTS().getParameter("numVoices"))) *p = numTracks;
    if (auto* mixer = dynamic_cast<TrackMixerModuleProcessor*>(synth->getModuleForLogical(trackMixerLid)))
        if (auto* p = dynamic_cast<juce::AudioParameterInt*>(mixer->getAPVTS().getParameter("numTracks"))) *p = numTracks;

    int voicesToConnect = std::min({numTracks, PolyVCOModuleProcessor::MAX_VOICES, 64});
    for (int i = 0; i < voicesToConnect; ++i)
    {
        synth->connect(midiPlayerNodeId, i, polyVcoNodeId, 1 + i);
        synth->connect(midiPlayerNodeId, i + 16, polyVcoNodeId, 1 + PolyVCOModuleProcessor::MAX_VOICES * 2 + i);
        synth->connect(polyVcoNodeId, i, trackMixerNodeId, i * 2);
        synth->connect(polyVcoNodeId, i, trackMixerNodeId, i * 2 + 1);
    }
    
    synth->connect(trackMixerNodeId, 0, synth->getOutputNodeID(), 0);
    synth->connect(trackMixerNodeId, 1, synth->getOutputNodeID(), 1);

    synth->commitChanges();
}

void ImGuiNodeEditorComponent::handleStrokeSeqBuildDrumKit(StrokeSequencerModuleProcessor* strokeSeq, juce::uint32 strokeSeqLid)
{
    if (!synth || !strokeSeq) return;

    juce::Logger::writeToLog(" BUILD DRUM KIT handler called! Creating modules...");

    // 1. Get Stroke Sequencer position
    auto seqNodeId = synth->getNodeIdForLogical(strokeSeqLid);
    ImVec2 seqPos = ImNodes::GetNodeGridSpacePos((int)strokeSeqLid);

    // 2. Create 3 Sample Loaders (for Floor, Mid, Ceiling triggers)
    auto sampler1NodeId = synth->addModule("sample_loader");
    auto sampler2NodeId = synth->addModule("sample_loader");
    auto sampler3NodeId = synth->addModule("sample_loader");
    
    auto sampler1Lid = synth->getLogicalIdForNode(sampler1NodeId);
    auto sampler2Lid = synth->getLogicalIdForNode(sampler2NodeId);
    auto sampler3Lid = synth->getLogicalIdForNode(sampler3NodeId);
    
    // Position samplers in a vertical stack to the right
    pendingNodePositions[(int)sampler1Lid] = ImVec2(seqPos.x + 400.0f, seqPos.y);
    pendingNodePositions[(int)sampler2Lid] = ImVec2(seqPos.x + 400.0f, seqPos.y + 220.0f);
    pendingNodePositions[(int)sampler3Lid] = ImVec2(seqPos.x + 400.0f, seqPos.y + 440.0f);

    // 3. Create Track Mixer (will be set to 6 tracks by Value node)
    auto mixerNodeId = synth->addModule("track_mixer");
    auto mixerLid = synth->getLogicalIdForNode(mixerNodeId);
    pendingNodePositions[(int)mixerLid] = ImVec2(seqPos.x + 800.0f, seqPos.y + 200.0f);

    // 4. Create Value node set to 6.0 (for 3 stereo tracks = 6 channels)
    auto valueNodeId = synth->addModule("value");
    auto valueLid = synth->getLogicalIdForNode(valueNodeId);
    pendingNodePositions[(int)valueLid] = ImVec2(seqPos.x + 600.0f, seqPos.y + 550.0f);
    
    if (auto* valueNode = dynamic_cast<ValueModuleProcessor*>(synth->getModuleForLogical(valueLid)))
    {
        *dynamic_cast<juce::AudioParameterFloat*>(valueNode->getAPVTS().getParameter("value")) = 6.0f;
    }

    // 5. Connect Stroke Sequencer TRIGGERS to Sample Loader TRIGGER MOD inputs (channel 3)
    synth->connect(seqNodeId, 0, sampler1NodeId, 3); // Floor Trig   -> Sampler 1 Trigger Mod
    synth->connect(seqNodeId, 1, sampler2NodeId, 3); // Mid Trig     -> Sampler 2 Trigger Mod
    synth->connect(seqNodeId, 2, sampler3NodeId, 3); // Ceiling Trig -> Sampler 3 Trigger Mod

    // 6. Connect Sample Loader AUDIO OUTPUTS to Track Mixer AUDIO INPUTS (stereo pairs)
    // Sampler 1 (L+R) -> Mixer Audio 1+2
    synth->connect(sampler1NodeId, 0, mixerNodeId, 0); // Sampler 1 L -> Mixer Audio 1
    synth->connect(sampler1NodeId, 1, mixerNodeId, 1); // Sampler 1 R -> Mixer Audio 2
    
    // Sampler 2 (L+R) -> Mixer Audio 3+4
    synth->connect(sampler2NodeId, 0, mixerNodeId, 2); // Sampler 2 L -> Mixer Audio 3
    synth->connect(sampler2NodeId, 1, mixerNodeId, 3); // Sampler 2 R -> Mixer Audio 4
    
    // Sampler 3 (L+R) -> Mixer Audio 5+6
    synth->connect(sampler3NodeId, 0, mixerNodeId, 4); // Sampler 3 L -> Mixer Audio 5
    synth->connect(sampler3NodeId, 1, mixerNodeId, 5); // Sampler 3 R -> Mixer Audio 6

    // 7. Connect Value node (6.0) to Track Mixer's "Num Tracks" input
    synth->connect(valueNodeId, 0, mixerNodeId, 64); // Value (6) -> Num Tracks Mod

    // 8. Connect Track Mixer output to global output
    auto outputNodeId = synth->getOutputNodeID();
    synth->connect(mixerNodeId, 0, outputNodeId, 0); // Mixer Out L -> Global Out L
    synth->connect(mixerNodeId, 1, outputNodeId, 1); // Mixer Out R -> Global Out R

    synth->commitChanges();
    graphNeedsRebuild = true;
}

void ImGuiNodeEditorComponent::handleAnimationBuildTriggersAudio(AnimationModuleProcessor* animModule, juce::uint32 animModuleLid)
{
    if (!synth || !animModule) return;

    // Query the dynamic output pins to determine how many bones are tracked
    auto dynamicPins = animModule->getDynamicOutputPins();
    
    // Each bone has 3 outputs: Vel X, Vel Y, Hit
    // So number of bones = number of pins / 3
    int numTrackedBones = (int)dynamicPins.size() / 3;
    
    if (numTrackedBones == 0)
    {
        juce::Logger::writeToLog(" BUILD TRIGGERS AUDIO: No tracked bones! Add bones first.");
        return;
    }

    juce::Logger::writeToLog(" BUILD TRIGGERS AUDIO handler called! Creating modules for " + 
                             juce::String(numTrackedBones) + " tracked bones...");

    // 1. Get Animation Module position
    auto animNodeId = synth->getNodeIdForLogical(animModuleLid);
    ImVec2 animPos = ImNodes::GetNodeGridSpacePos((int)animModuleLid);

    // 2. Create one Sample Loader per tracked bone
    std::vector<juce::AudioProcessorGraph::NodeID> samplerNodeIds;
    std::vector<juce::uint32> samplerLids;
    
    for (int i = 0; i < numTrackedBones; ++i)
    {
        auto samplerNodeId = synth->addModule("sample_loader");
        samplerNodeIds.push_back(samplerNodeId);
        samplerLids.push_back(synth->getLogicalIdForNode(samplerNodeId));
        
        // Position samplers in a vertical stack to the right
        pendingNodePositions[(int)samplerLids[i]] = ImVec2(animPos.x + 400.0f, animPos.y + i * 220.0f);
    }

    // 3. Create Track Mixer (num_bones * 2 for stereo pairs)
    auto mixerNodeId = synth->addModule("track_mixer");
    auto mixerLid = synth->getLogicalIdForNode(mixerNodeId);
    pendingNodePositions[(int)mixerLid] = ImVec2(animPos.x + 800.0f, animPos.y + (numTrackedBones * 110.0f));

    // 4. Create Value node for mixer track count
    int numMixerTracks = numTrackedBones * 2; // 2 channels per sampler (stereo)
    auto valueNodeId = synth->addModule("value");
    auto valueLid = synth->getLogicalIdForNode(valueNodeId);
    pendingNodePositions[(int)valueLid] = ImVec2(animPos.x + 600.0f, animPos.y + (numTrackedBones * 220.0f));

    if (auto* valueNode = dynamic_cast<ValueModuleProcessor*>(synth->getModuleForLogical(valueLid)))
    {
        *dynamic_cast<juce::AudioParameterFloat*>(valueNode->getAPVTS().getParameter("value")) = (float)numMixerTracks;
    }

    // 5. Connect Animation Module TRIGGERS to Sample Loader TRIGGER MOD inputs
    // Animation Module Output Channels (per bone):
    //   i*3 + 0: Bone Vel X
    //   i*3 + 1: Bone Vel Y
    //   i*3 + 2: Bone Hit (trigger)  Connect this to sampler
    for (int i = 0; i < numTrackedBones; ++i)
    {
        int triggerChannel = i * 3 + 2; // Every 3rd channel starting at 2 (2, 5, 8, 11, ...)
        synth->connect(animNodeId, triggerChannel, samplerNodeIds[i], 3); // Bone Hit -> Sampler Trigger Mod
    }

    // 6. Connect Sample Loader AUDIO OUTPUTS to Track Mixer AUDIO INPUTS (stereo pairs)
    for (int i = 0; i < numTrackedBones; ++i)
    {
        int mixerChannelL = i * 2;       // 0, 2, 4, 6, ...
        int mixerChannelR = i * 2 + 1;   // 1, 3, 5, 7, ...
        
        synth->connect(samplerNodeIds[i], 0, mixerNodeId, mixerChannelL); // Sampler L -> Mixer Audio L
        synth->connect(samplerNodeIds[i], 1, mixerNodeId, mixerChannelR); // Sampler R -> Mixer Audio R
    }

    // 7. Connect Value node to Track Mixer's "Num Tracks" input
    synth->connect(valueNodeId, 0, mixerNodeId, 64); // Value -> Num Tracks Mod

    // 8. Connect Track Mixer output to global output
    auto outputNodeId = synth->getOutputNodeID();
    synth->connect(mixerNodeId, 0, outputNodeId, 0); // Mixer Out L -> Global Out L
    synth->connect(mixerNodeId, 1, outputNodeId, 1); // Mixer Out R -> Global Out R

    synth->commitChanges();
    graphNeedsRebuild = true;
    
    juce::Logger::writeToLog(" BUILD TRIGGERS AUDIO complete! " + juce::String(numTrackedBones) + 
                             " samplers + mixer + wiring created.");
}

void ImGuiNodeEditorComponent::handleMultiSequencerAutoConnectSamplers(MultiSequencerModuleProcessor* sequencer, juce::uint32 sequencerLid)
{
    if (!synth || !sequencer) return;

    // 1. Get Sequencer info and clear its old connections
    auto seqNodeId = synth->getNodeIdForLogical(sequencerLid);
    ImVec2 seqPos = ImNodes::GetNodeGridSpacePos((int)sequencerLid);
    const int numSteps = static_cast<int>(sequencer->getAPVTS().getRawParameterValue("numSteps")->load());
    synth->clearConnectionsForNode(seqNodeId);

    // 2. Create the necessary Mixer
    auto mixerNodeId = synth->addModule("track_mixer");
    auto mixerLid = synth->getLogicalIdForNode(mixerNodeId);
    pendingNodePositions[(int)mixerLid] = ImVec2(seqPos.x + 800.0f, seqPos.y + 100.0f);
    if (auto* mixer = dynamic_cast<TrackMixerModuleProcessor*>(synth->getModuleForLogical(mixerLid))) {
        *dynamic_cast<juce::AudioParameterInt*>(mixer->getAPVTS().getParameter("numTracks")) = numSteps;
    }

    // 3. CREATE a Sample Loader for each step and connect its audio to the mixer
    for (int i = 0; i < numSteps; ++i)
    {
        auto samplerNodeId = synth->addModule("sample_loader");
        auto samplerLid = synth->getLogicalIdForNode(samplerNodeId);
        pendingNodePositions[(int)samplerLid] = ImVec2(seqPos.x + 400.0f, seqPos.y + (i * 220.0f));

        // Connect this sampler's audio output to the mixer's input
        synth->connect(samplerNodeId, 0 /*Audio Output*/, mixerNodeId, i);
        
        // Connect the Sequencer's CV/Trig for this step directly to the new sampler
        synth->connect(seqNodeId, 7 + i * 3 + 0, samplerNodeId, 0); // Pitch N -> Pitch Mod
        synth->connect(seqNodeId, 1, samplerNodeId, 2); // Main Gate -> Gate Mod
        synth->connect(seqNodeId, 7 + i * 3 + 2, samplerNodeId, 3); // Trig N  -> Trigger Mod
    }
    
    // Connect Num Steps output (channel 6) to Track Mixer's Num Tracks Mod input (channel 64)
    synth->connect(seqNodeId, 6, mixerNodeId, 64); // Num Steps -> Num Tracks Mod

    // 4. Connect the mixer to the main output
    auto outputNodeId = synth->getOutputNodeID();
    synth->connect(mixerNodeId, 0, outputNodeId, 0); // Out L
    synth->connect(mixerNodeId, 1, outputNodeId, 1); // Out R

    graphNeedsRebuild = true;
}

void ImGuiNodeEditorComponent::handleMultiSequencerAutoConnectVCO(MultiSequencerModuleProcessor* sequencer, juce::uint32 sequencerLid)
{
    if (!synth || !sequencer) return;

    // 1. Get Sequencer info and clear its old connections
    auto seqNodeId = synth->getNodeIdForLogical(sequencerLid);
    ImVec2 seqPos = ImNodes::GetNodeGridSpacePos((int)sequencerLid);
    const int numSteps = static_cast<int>(sequencer->getAPVTS().getRawParameterValue("numSteps")->load());
    synth->clearConnectionsForNode(seqNodeId);

    // 2. CREATE the PolyVCO and Track Mixer
    auto polyVcoNodeId = synth->addModule("polyvco");
    auto polyVcoLid = synth->getLogicalIdForNode(polyVcoNodeId);
    pendingNodePositions[(int)polyVcoLid] = ImVec2(seqPos.x + 400.0f, seqPos.y);
    if (auto* vco = dynamic_cast<PolyVCOModuleProcessor*>(synth->getModuleForLogical(polyVcoLid))) {
        if (auto* p = dynamic_cast<juce::AudioParameterInt*>(vco->getAPVTS().getParameter("numVoices"))) *p = numSteps;
    }
    
    auto mixerNodeId = synth->addModule("track_mixer");
    auto mixerLid = synth->getLogicalIdForNode(mixerNodeId);
    pendingNodePositions[(int)mixerLid] = ImVec2(seqPos.x + 800.0f, seqPos.y);
    if (auto* mixer = dynamic_cast<TrackMixerModuleProcessor*>(synth->getModuleForLogical(mixerLid))) {
        if (auto* p = dynamic_cast<juce::AudioParameterInt*>(mixer->getAPVTS().getParameter("numTracks"))) *p = numSteps;
    }

    // 3. Connect CV, Audio, and Main Output
    for (int i = 0; i < numSteps; ++i)
    {
        // Connect CV: Sequencer -> PolyVCO
        synth->connect(seqNodeId, 7 + i * 3 + 0, polyVcoNodeId, 1 + i);                                  // Pitch N -> Freq N Mod
        synth->connect(seqNodeId, 1, polyVcoNodeId, 1 + PolyVCOModuleProcessor::MAX_VOICES * 2 + i); // Main Gate -> Gate N Mod

        // Connect Audio: PolyVCO -> Mixer
        synth->connect(polyVcoNodeId, i, mixerNodeId, i);
    }
    
    // Connect Num Steps output (channel 6) to PolyVCO's Num Voices Mod input (channel 0)
    synth->connect(seqNodeId, 6, polyVcoNodeId, 0); // Num Steps -> Num Voices Mod
    
    // Connect Num Steps output (channel 6) to Track Mixer's Num Tracks Mod input (channel 64)
    synth->connect(seqNodeId, 6, mixerNodeId, 64); // Num Steps -> Num Tracks Mod
    
    // Connect Mixer -> Main Output
    auto outputNodeId = synth->getOutputNodeID();
    synth->connect(mixerNodeId, 0, outputNodeId, 0); // Out L
    synth->connect(mixerNodeId, 1, outputNodeId, 1); // Out R

    graphNeedsRebuild = true;
}

// Add this exact helper function to the class
void ImGuiNodeEditorComponent::parsePinName(const juce::String& fullName, juce::String& outType, int& outIndex)
{
    outIndex = -1; // Default to no index
    outType = fullName;

    if (fullName.contains(" "))
    {
        const juce::String lastWord = fullName.substring(fullName.lastIndexOfChar(' ') + 1);
        if (lastWord.containsOnly("0123456789"))
        {
            outIndex = lastWord.getIntValue();
            outType = fullName.substring(0, fullName.lastIndexOfChar(' '));
        }
    }
}

// Helper functions to get pins from modules
std::vector<AudioPin> ImGuiNodeEditorComponent::getOutputPins(const juce::String& moduleType)
{
    auto it = getModulePinDatabase().find(moduleType);
    if (it != getModulePinDatabase().end())
        return it->second.audioOuts;
    return {};
}

std::vector<AudioPin> ImGuiNodeEditorComponent::getInputPins(const juce::String& moduleType)
{
    auto it = getModulePinDatabase().find(moduleType);
    if (it != getModulePinDatabase().end())
        return it->second.audioIns;
    return {};
}

AudioPin* ImGuiNodeEditorComponent::findInputPin(const juce::String& moduleType, const juce::String& pinName)
{
    auto pins = getInputPins(moduleType);
    for (auto& pin : pins)
    {
        if (pin.name == pinName)
            return &pin;
    }
    return nullptr;
}

AudioPin* ImGuiNodeEditorComponent::findOutputPin(const juce::String& moduleType, const juce::String& pinName)
{
    auto pins = getOutputPins(moduleType);
    for (auto& pin : pins)
    {
        if (pin.name == pinName)
            return &pin;
    }
    return nullptr;
}

std::vector<juce::uint32> ImGuiNodeEditorComponent::findNodesOfType(const juce::String& moduleType)
{
    std::vector<juce::uint32> result;
    if (!synth) return result;
    
    for (const auto& modInfo : synth->getModulesInfo())
    {
        if (synth->getModuleTypeForLogical(modInfo.first) == moduleType)
        {
            result.push_back(modInfo.first);
        }
    }
    return result;
}

// New dynamic pin-fetching helper
std::vector<PinInfo> ImGuiNodeEditorComponent::getDynamicOutputPins(ModuleProcessor* module)
{
    std::vector<PinInfo> pins;
    if (!module) return pins;

    const int numOutputChannels = module->getBus(false, 0)->getNumberOfChannels();
    for (int i = 0; i < numOutputChannels; ++i)
    {
        juce::String pinName = module->getAudioOutputLabel(i);
        if (pinName.isNotEmpty())
        {
            pins.push_back({(uint32_t)i, pinName}); // Store the full pin name in the type field
        }
    }
    return pins;
}

// Template function implementations
template<typename TargetProcessorType>
void ImGuiNodeEditorComponent::connectToMonophonicTargets(
    ModuleProcessor* sourceNode,
    const std::map<juce::String, juce::String>& pinNameMapping,
    const std::vector<juce::uint32>& targetLids)
{
    if (!synth || !sourceNode || targetLids.empty()) return;
    
    juce::Logger::writeToLog("[AutoConnect] connectToMonophonicTargets called for " + sourceNode->getName());
    
    // Get the source module type
    juce::String sourceModuleType;
    for (const auto& modInfo : synth->getModulesInfo())
    {
        if (synth->getModuleForLogical(modInfo.first) == sourceNode)
        {
            sourceModuleType = synth->getModuleTypeForLogical(modInfo.first);
            break;
        }
    }
    
    if (sourceModuleType.isEmpty()) return;
    
    // Use provided target logical IDs explicitly
    auto targetNodes = targetLids;

    int currentTargetIndex = 0;

    // First, group all of the source node's output pins by their index number.
    // For example, "Pitch 1" and "Trig 1" will both be in the group for index 1.
    std::map<int, std::vector<PinInfo>> pinsByIndex;
    
    // THE FIX: Get pins directly from the module instance.
    auto outputPins = getDynamicOutputPins(sourceNode);
    
    for (const auto& pin : outputPins)
    {
        juce::String type;
        int index = -1;
        parsePinName(pin.type, type, index); // Use pin.type instead of pin.name
        if (index != -1) {
            // Store channel ID as the pin's ID
            pinsByIndex[index].push_back({(uint32_t)pin.id, type}); 
        }
    }

    // Now, loop through each group of pins (each voice).
    for (auto const& [index, pinsInGroup] : pinsByIndex)
    {
        if (currentTargetIndex >= (int)targetNodes.size()) break; // Stop if we run out of targets
        auto targetNodeId = targetNodes[currentTargetIndex];

        // For each pin in the group (e.g., for "Pitch 1" and "Trig 1")...
        for (const auto& pinInfo : pinsInGroup)
        {
            // Check if we have a connection rule for this pin type (e.g., "Pitch").
            if (pinNameMapping.count(pinInfo.type))
            {
                juce::String targetPinName = pinNameMapping.at(pinInfo.type);
                auto* targetPin = findInputPin("sample loader", targetPinName);

                // If the target pin exists, create the connection.
                if (targetPin)
                {
                    juce::uint32 sourceLogicalId = 0;
                    for (const auto& modInfo : synth->getModulesInfo())
                    {
                        if (synth->getModuleForLogical(modInfo.first) == sourceNode)
                        {
                            sourceLogicalId = modInfo.first;
                            break;
                        }
                    }
                    auto sourceNodeId = synth->getNodeIdForLogical(sourceLogicalId);
                    synth->connect(sourceNodeId, pinInfo.id, synth->getNodeIdForLogical(targetNodeId), targetPin->channel);
                }
            }
        }
        // IMPORTANT: Move to the next target module for the next voice.
        currentTargetIndex++;
    }
}

template<typename TargetProcessorType>
void ImGuiNodeEditorComponent::connectToPolyphonicTarget(
    ModuleProcessor* sourceNode,
    const std::map<juce::String, juce::String>& pinNameMapping)
{
    if (!synth || !sourceNode) return;
    
    juce::Logger::writeToLog("[AutoConnect] connectToPolyphonicTarget called for " + sourceNode->getName());
    
    // Get the source module type
    juce::String sourceModuleType;
    juce::uint32 sourceLogicalId = 0;
    for (const auto& modInfo : synth->getModulesInfo())
    {
        if (synth->getModuleForLogical(modInfo.first) == sourceNode)
        {
            sourceModuleType = synth->getModuleTypeForLogical(modInfo.first);
            sourceLogicalId = modInfo.first;
            break;
        }
    }
    
    if (sourceModuleType.isEmpty()) return;
    
    auto targetNodes = findNodesOfType("polyvco");
    if (targetNodes.empty()) return;
    auto targetNodeId = targetNodes[0]; // Use the first available PolyVCO

    auto sourceNodeId = synth->getNodeIdForLogical(sourceLogicalId);

    // THE FIX: Get pins directly from the module instance, not the database.
    auto outputPins = getDynamicOutputPins(sourceNode);

    // Loop through every output pin on the source module.
    for (const auto& sourcePin : outputPins)
    {
        // Parse the source pin's name to get its type and index.
        juce::String sourceType;
        int sourceIndex = -1;
        parsePinName(sourcePin.type, sourceType, sourceIndex); // Use pin.type instead of pin.name

        if (sourceIndex == -1) continue; // Skip pins that aren't numbered.

        // Check if we have a rule for this pin type (e.g., "Pitch" maps to "Freq").
        if (pinNameMapping.count(sourceType))
        {
            juce::String targetType = pinNameMapping.at(sourceType);
            // PolyVCO inputs use the format "Freq 1 Mod", "Gate 1 Mod", etc.
            juce::String targetPinName = targetType + " " + juce::String(sourceIndex) + " Mod";

            // Find that pin on the target and connect it if available.
            auto* targetPin = findInputPin("polyvco", targetPinName);
            if (targetPin)
            {
                synth->connect(sourceNodeId, sourcePin.id, synth->getNodeIdForLogical(targetNodeId), targetPin->channel);
            }
        }
    }
}

void ImGuiNodeEditorComponent::handleAutoConnectionRequests()
{
    if (!synth) return;
    
    for (const auto& modInfo : synth->getModulesInfo())
    {
        auto* module = synth->getModuleForLogical(modInfo.first);
        if (!module) continue;

        // --- Check MultiSequencer Flags ---
        if (auto* multiSeq = dynamic_cast<MultiSequencerModuleProcessor*>(module))
        {
            if (multiSeq->autoConnectSamplersTriggered.exchange(false))
            {
                handleMultiSequencerAutoConnectSamplers(multiSeq, modInfo.first); // Call the new specific handler
                pushSnapshot();
                return;
            }
            if (multiSeq->autoConnectVCOTriggered.exchange(false))
            {
                handleMultiSequencerAutoConnectVCO(multiSeq, modInfo.first); // Call the new specific handler
                pushSnapshot();
                return;
            }
        }
        
        // --- Check StrokeSequencer Flags ---
        if (auto* strokeSeq = dynamic_cast<StrokeSequencerModuleProcessor*>(module))
        {
            if (strokeSeq->autoBuildDrumKitTriggered.exchange(false))
            {
                handleStrokeSeqBuildDrumKit(strokeSeq, modInfo.first);
                pushSnapshot();
                return;
            }
        }
        
        // --- Check AnimationModule Flags ---
        if (auto* animModule = dynamic_cast<AnimationModuleProcessor*>(module))
        {
            if (animModule->autoBuildTriggersAudioTriggered.exchange(false))
            {
                handleAnimationBuildTriggersAudio(animModule, modInfo.first);
                pushSnapshot();
                return;
            }
        }
        
        // --- Check MIDIPlayer Flags ---
        if (auto* midiPlayer = dynamic_cast<MIDIPlayerModuleProcessor*>(module))
        {
            if (midiPlayer->autoConnectTriggered.exchange(false)) // Samplers
            {
                handleMidiPlayerAutoConnect(midiPlayer, modInfo.first); // Reuse old detailed handler
                pushSnapshot();
                return;
            }
            if (midiPlayer->autoConnectVCOTriggered.exchange(false))
            {
                handleMidiPlayerAutoConnectVCO(midiPlayer, modInfo.first); // Reuse old detailed handler
                pushSnapshot();
                return;
            }
            if (midiPlayer->autoConnectHybridTriggered.exchange(false))
            {
                handleMidiPlayerAutoConnectHybrid(midiPlayer, modInfo.first); // Reuse old detailed handler
                pushSnapshot();
                return;
            }
        }
    }
}

void ImGuiNodeEditorComponent::handleMIDIPlayerConnectionRequest(juce::uint32 midiPlayerLid, MIDIPlayerModuleProcessor* midiPlayer, int requestType)
{
    if (!synth || !midiPlayer) return;
    
    juce::Logger::writeToLog("[MIDI Player Quick Connect] Request type: " + juce::String(requestType));
    
    // Get ALL tracks (don't filter by whether they have notes)
    const auto& notesByTrack = midiPlayer->getNotesByTrack();
    int numTracks = (int)notesByTrack.size();
    
    if (numTracks == 0)
    {
        juce::Logger::writeToLog("[MIDI Player Quick Connect] No tracks in MIDI file");
        return;
    }
    
    // Get MIDI Player position for positioning new nodes
    ImVec2 playerPos = ImNodes::GetNodeEditorSpacePos(static_cast<int>(midiPlayerLid));
    auto midiPlayerNodeId = synth->getNodeIdForLogical(midiPlayerLid);
    
    // Request Type: 1=PolyVCO, 2=Samplers, 3=Both
    juce::uint32 polyVCOLid = 0;
    juce::uint32 mixerLid = 0;
    
    if (requestType == 1 || requestType == 3) // PolyVCO or Both
    {
        // 1. Create PolyVCO
        auto polyVCONodeId = synth->addModule("polyvco");
        polyVCOLid = synth->getLogicalIdForNode(polyVCONodeId);
        pendingNodeScreenPositions[(int)polyVCOLid] = ImVec2(playerPos.x + 400.0f, playerPos.y);
        juce::Logger::writeToLog("[MIDI Player Quick Connect] Created PolyVCO at LID " + juce::String((int)polyVCOLid));
        
        // 2. Create Track Mixer
        auto mixerNodeId = synth->addModule("track_mixer");
        mixerLid = synth->getLogicalIdForNode(mixerNodeId);
        pendingNodeScreenPositions[(int)mixerLid] = ImVec2(playerPos.x + 700.0f, playerPos.y);
        juce::Logger::writeToLog("[MIDI Player Quick Connect] Created Track Mixer at LID " + juce::String((int)mixerLid));
        
        // 3. Connect MIDI Player tracks to PolyVCO
        // Connect ALL tracks, regardless of whether they have notes
        int trackIdx = 0;
        for (size_t i = 0; i < notesByTrack.size() && trackIdx < 32; ++i)
        {
            const int midiPitchPin = trackIdx * 4 + 1;
            const int midiGatePin = trackIdx * 4 + 0;
            const int midiVeloPin = trackIdx * 4 + 2;
            
            const int vcoFreqPin = trackIdx + 1;
            const int vcoWavePin = 32 + trackIdx + 1;
            const int vcoGatePin = 64 + trackIdx + 1;
            
            synth->connect(midiPlayerNodeId, midiPitchPin, polyVCONodeId, vcoFreqPin);
            synth->connect(midiPlayerNodeId, midiGatePin, polyVCONodeId, vcoGatePin);
            synth->connect(midiPlayerNodeId, midiVeloPin, polyVCONodeId, vcoWavePin);
            trackIdx++;
        }
        
        // 4. Connect Num Tracks to PolyVCO (Num Voices Mod on channel 0)
        synth->connect(midiPlayerNodeId, MIDIPlayerModuleProcessor::kRawNumTracksChannelIndex, 
                       polyVCONodeId, 0);
        
        // 5. Connect PolyVCO outputs to Track Mixer inputs
        for (int i = 0; i < trackIdx; ++i)
        {
            synth->connect(polyVCONodeId, i, mixerNodeId, i);
        }
        
        // 6. Connect Num Tracks output to mixer's Num Tracks Mod input
        synth->connect(midiPlayerNodeId, MIDIPlayerModuleProcessor::kRawNumTracksChannelIndex, 
                       mixerNodeId, TrackMixerModuleProcessor::MAX_TRACKS);
        
        // 7. Connect Track Mixer to main output
        auto outputNodeId = synth->getOutputNodeID();
        synth->connect(mixerNodeId, 0, outputNodeId, 0); // L
        synth->connect(mixerNodeId, 1, outputNodeId, 1); // R
        
        juce::Logger::writeToLog("[MIDI Player Quick Connect] Connected " + juce::String(trackIdx) + 
                                " tracks: MIDI Player  PolyVCO  Track Mixer  Output");
    }
    
    if (requestType == 2 || requestType == 3) // Samplers or Both
    {
        float samplerX = playerPos.x + 400.0f;
        float mixerX = playerPos.x + 700.0f;
        
        // If PolyVCO mode (Both), offset samplers and use same mixer
        if (requestType == 3)
        {
            samplerX += 300.0f; // Offset samplers if PolyVCO exists
            // Reuse existing mixer created in PolyVCO section
        }
        else
        {
            // 1. Create Track Mixer for Samplers-only mode
            auto mixerNodeId = synth->addModule("track_mixer");
            mixerLid = synth->getLogicalIdForNode(mixerNodeId);
            pendingNodeScreenPositions[(int)mixerLid] = ImVec2(mixerX, playerPos.y);
            juce::Logger::writeToLog("[MIDI Player Quick Connect] Created Track Mixer at LID " + juce::String((int)mixerLid));
        }
        
        // 2. Create samplers and connect
        // Connect ALL tracks, regardless of whether they have notes
        auto mixerNodeId = synth->getNodeIdForLogical(mixerLid);
        int trackIdx = 0;
        int totalTracks = (int)notesByTrack.size();
        int mixerStartChannel = (requestType == 3) ? totalTracks : 0; // Offset for "Both" mode
        
        for (size_t i = 0; i < notesByTrack.size(); ++i)
        {
            // Create SampleLoader
            float samplerY = playerPos.y + (trackIdx * 150.0f);
            auto samplerNodeId = synth->addModule("sample_loader");
            juce::uint32 samplerLid = synth->getLogicalIdForNode(samplerNodeId);
            pendingNodeScreenPositions[(int)samplerLid] = ImVec2(samplerX, samplerY);
            
            const int midiPitchPin = trackIdx * 4 + 1;
            const int midiGatePin = trackIdx * 4 + 0;
            const int midiTrigPin = trackIdx * 4 + 3;
            
            // Connect MIDI Player to Sampler
            synth->connect(midiPlayerNodeId, midiPitchPin, samplerNodeId, 0);
            synth->connect(midiPlayerNodeId, midiGatePin, samplerNodeId, 2);
            synth->connect(midiPlayerNodeId, midiTrigPin, samplerNodeId, 3);
            
            // Connect Sampler output to Track Mixer input
            synth->connect(samplerNodeId, 0, mixerNodeId, mixerStartChannel + trackIdx);
            
            trackIdx++;
        }
        
        // 3. Connect Num Tracks to mixer and route to output (only if not already done in PolyVCO mode)
        if (requestType != 3)
        {
            synth->connect(midiPlayerNodeId, MIDIPlayerModuleProcessor::kRawNumTracksChannelIndex, 
                           mixerNodeId, TrackMixerModuleProcessor::MAX_TRACKS);
            
            // 4. Connect Track Mixer to output
            auto outputNodeId = synth->getOutputNodeID();
            synth->connect(mixerNodeId, 0, outputNodeId, 0);
            synth->connect(mixerNodeId, 1, outputNodeId, 1);
            
            juce::Logger::writeToLog("[MIDI Player Quick Connect] Complete chain: " + juce::String(trackIdx) + 
                                    " SampleLoaders  Track Mixer (with Num Tracks)  Stereo Output");
        }
        else
        {
            juce::Logger::writeToLog("[MIDI Player Quick Connect] Connected " + juce::String(trackIdx) + 
                                    " SampleLoaders  Track Mixer (channels " + juce::String(mixerStartChannel) + 
                                    "-" + juce::String(mixerStartChannel + trackIdx - 1) + 
                                    ") [Mixer already connected in PolyVCO section]");
        }
    }
    
    // Commit changes
    if (synth)
    {
        synth->commitChanges();
        graphNeedsRebuild = true;
    }
    
    pushSnapshot();
}

void ImGuiNodeEditorComponent::drawInsertNodeOnLinkPopup()
{
    if (ImGui::BeginPopup("InsertNodeOnLinkPopup"))
    {
        const int numSelected = ImNodes::NumSelectedLinks();
        const bool isMultiInsert = numSelected > 1;

        // --- Module Insertion on Cables (Organized by Category) ---
        // Map format: {Display Name, Internal Type}
        // Internal types use lowercase with underscores for spaces
        const std::map<const char*, const char*> audioInsertable = {
            // Effects
            {"VCF", "vcf"}, {"Delay", "delay"}, {"Reverb", "reverb"},
            {"Chorus", "chorus"}, {"Phaser", "phaser"}, {"Compressor", "compressor"},
            {"Limiter", "limiter"}, {"Noise Gate", "gate"}, {"Drive", "drive"},
            {"Graphic EQ", "graphic_eq"}, {"Waveshaper", "waveshaper"}, 
            {"8-Band Shaper", "8bandshaper"}, {"Granulator", "granulator"}, 
            {"Harmonic Shaper", "harmonic_shaper"}, {"Time/Pitch Shifter", "timepitch"},
            {"De-Crackle", "de_crackle"},
            // Utilities
            {"VCA", "vca"}, {"Mixer", "mixer"}, {"Attenuverter", "attenuverter"},
            // Modulators
            {"Function Generator", "function_generator"}, {"Shaping Oscillator", "shaping_oscillator"},
            // TTS
            {"Vocal Tract Filter", "vocal_tract_filter"},
            // Analysis
            {"Scope", "scope"}, {"Frequency Graph", "frequency_graph"}
        };
        const std::map<const char*, const char*> modInsertable = {
            // Utilities
            {"Attenuverter", "attenuverter"}, {"Lag Processor", "lag_processor"}, 
            {"Math", "math"}, {"Map Range", "map_range"}, {"Quantizer", "quantizer"},
            {"Rate", "rate"}, {"Comparator", "comparator"}, {"Logic", "logic"},
            {"CV Mixer", "cv_mixer"}, {"Sequential Switch", "sequential_switch"},
            // Modulators
            {"S&H", "s_and_h"}, {"Function Generator", "function_generator"}
        };
        const auto& listToShow = linkToInsertOn.isMod ? modInsertable : audioInsertable;

        if (isMultiInsert)
            ImGui::Text("Insert Node on %d Cables", numSelected);
        else
            ImGui::Text("Insert Node on Cable");

        // --- FIX: Iterate over map pairs instead of simple strings ---
        for (const auto& pair : listToShow)
        {
            // pair.first = display label, pair.second = internal type
            if (ImGui::MenuItem(pair.first))
            {
                if (isMultiInsert)
                {
                    handleInsertNodeOnSelectedLinks(pair.second);
                }
                else
                {
                    insertNodeBetween(pair.second);
                }
                ImGui::CloseCurrentPopup();
            }
        }
        
        // VST Plugins submenu (only for audio cables)
        if (!linkToInsertOn.isMod)
        {
            ImGui::Separator();
            if (ImGui::BeginMenu("VST"))
            {
                auto& app = PresetCreatorApplication::getApp();
                auto& knownPluginList = app.getKnownPluginList();
                
                for (const auto& desc : knownPluginList.getTypes())
                {
                    if (ImGui::MenuItem(desc.name.toRawUTF8()))
                    {
                        if (isMultiInsert)
                        {
                            handleInsertNodeOnSelectedLinks(desc.name);
                        }
                        else
                        {
                            insertNodeBetween(desc.name);
                        }
                        ImGui::CloseCurrentPopup();
                    }
                    
                    // Show tooltip with plugin info
                    if (ImGui::IsItemHovered())
                    {
                        ImGui::BeginTooltip();
                        ImGui::Text("Manufacturer: %s", desc.manufacturerName.toRawUTF8());
                        ImGui::Text("Version: %s", desc.version.toRawUTF8());
                        ImGui::EndTooltip();
                    }
                }
                ImGui::EndMenu();
            }
        }
        
        ImGui::EndPopup();
    }
    else
    {
        // --- FIX: Reset state when popup is closed ---
        // If the popup is not open (i.e., it was closed or the user clicked away),
        // we must reset the state variable. This ensures that the application
        // is no longer "stuck" in the insert-on-link mode and right-click on
        // empty canvas will work again.
        linkToInsertOn.linkId = -1;
    }
}

// --- NEW HELPER FUNCTION ---
void ImGuiNodeEditorComponent::insertNodeOnLink(const juce::String& nodeType, const LinkInfo& linkInfo, const ImVec2& position)
{
    if (synth == nullptr) return;

    PinDataType srcType = getPinDataTypeForPin(linkInfo.srcPin);
    PinDataType dstType = getPinDataTypeForPin(linkInfo.dstPin);

    // 1. Create and Position the New Node
    // Check if this is a VST plugin by checking against known plugins
    juce::AudioProcessorGraph::NodeID newNodeId;
    auto& app = PresetCreatorApplication::getApp();
    auto& knownPluginList = app.getKnownPluginList();
    bool isVst = false;
    
    for (const auto& desc : knownPluginList.getTypes())
    {
        if (desc.name == nodeType)
        {
            // This is a VST plugin - use addVstModule
            newNodeId = synth->addVstModule(app.getPluginFormatManager(), desc);
            isVst = true;
            break;
        }
    }
    
    if (!isVst)
    {
        // Regular module - use addModule
        newNodeId = synth->addModule(nodeType);
    }
    
    auto newNodeLid = synth->getLogicalIdForNode(newNodeId);
    pendingNodeScreenPositions[(int)newNodeLid] = position;

    // 2. Get Original Connection Points
    auto originalSrcNodeId = synth->getNodeIdForLogical(linkInfo.srcPin.logicalId);
    auto originalDstNodeId = (linkInfo.dstPin.logicalId == 0) 
        ? synth->getOutputNodeID() 
        : synth->getNodeIdForLogical(linkInfo.dstPin.logicalId);

    // 3. Disconnect the Original Link
    synth->disconnect(originalSrcNodeId, linkInfo.srcPin.channel, originalDstNodeId, linkInfo.dstPin.channel);

    // 4. Configure newly inserted node if necessary (e.g., MapRange)
    int newNodeOutputChannel = 0;
    if (nodeType == "MapRange")
    {
        if (auto* mapRange = dynamic_cast<MapRangeModuleProcessor*>(synth->getModuleForLogical(newNodeLid)))
        {
            Range inRange = getSourceRange(linkInfo.srcPin, synth);
            configureMapRangeFor(srcType, dstType, *mapRange, inRange);
            newNodeOutputChannel = (dstType == PinDataType::Audio) ? 1 : 0;
        }
    }

    // 5. Reconnect Through the New Node
    synth->connect(originalSrcNodeId, linkInfo.srcPin.channel, newNodeId, 0);
    synth->connect(newNodeId, newNodeOutputChannel, originalDstNodeId, linkInfo.dstPin.channel);
}

void ImGuiNodeEditorComponent::insertNodeOnLinkStereo(const juce::String& nodeType, 
                                                       const LinkInfo& linkLeft, 
                                                       const LinkInfo& linkRight, 
                                                       const ImVec2& position)
{
    if (synth == nullptr) return;

    juce::Logger::writeToLog("[InsertStereo] Inserting stereo node: " + nodeType);
    juce::Logger::writeToLog("[InsertStereo] Left cable: " + juce::String(linkLeft.srcPin.logicalId) + 
                            " ch" + juce::String(linkLeft.srcPin.channel) + " -> " + 
                            juce::String(linkLeft.dstPin.logicalId) + " ch" + juce::String(linkLeft.dstPin.channel));
    juce::Logger::writeToLog("[InsertStereo] Right cable: " + juce::String(linkRight.srcPin.logicalId) + 
                            " ch" + juce::String(linkRight.srcPin.channel) + " -> " + 
                            juce::String(linkRight.dstPin.logicalId) + " ch" + juce::String(linkRight.dstPin.channel));

    // 1. Create ONE node for both channels
    juce::AudioProcessorGraph::NodeID newNodeId;
    auto& app = PresetCreatorApplication::getApp();
    auto& knownPluginList = app.getKnownPluginList();
    bool isVst = false;
    
    for (const auto& desc : knownPluginList.getTypes())
    {
        if (desc.name == nodeType)
        {
            newNodeId = synth->addVstModule(app.getPluginFormatManager(), desc);
            isVst = true;
            break;
        }
    }
    
    if (!isVst)
    {
        newNodeId = synth->addModule(nodeType);
    }
    
    auto newNodeLid = synth->getLogicalIdForNode(newNodeId);
    pendingNodeScreenPositions[(int)newNodeLid] = position;

    // 2. Get Original Connection Points for LEFT cable (first cable)
    auto leftSrcNodeId = synth->getNodeIdForLogical(linkLeft.srcPin.logicalId);
    auto leftDstNodeId = (linkLeft.dstPin.logicalId == 0) 
        ? synth->getOutputNodeID() 
        : synth->getNodeIdForLogical(linkLeft.dstPin.logicalId);

    // 3. Get Original Connection Points for RIGHT cable (second cable)
    auto rightSrcNodeId = synth->getNodeIdForLogical(linkRight.srcPin.logicalId);
    auto rightDstNodeId = (linkRight.dstPin.logicalId == 0) 
        ? synth->getOutputNodeID() 
        : synth->getNodeIdForLogical(linkRight.dstPin.logicalId);

    // 4. Disconnect BOTH Original Links (using their actual source/dest channels)
    synth->disconnect(leftSrcNodeId, linkLeft.srcPin.channel, leftDstNodeId, linkLeft.dstPin.channel);
    synth->disconnect(rightSrcNodeId, linkRight.srcPin.channel, rightDstNodeId, linkRight.dstPin.channel);

    // 5. Reconnect Through the New Node
    // Left cable -> new node's LEFT input (ch0)
    synth->connect(leftSrcNodeId, linkLeft.srcPin.channel, newNodeId, 0);
    
    // Right cable -> new node's RIGHT input (ch1)
    synth->connect(rightSrcNodeId, linkRight.srcPin.channel, newNodeId, 1);
    
    // New node's outputs -> original destinations
    // Note: We'll connect both outputs to their respective destinations
    synth->connect(newNodeId, 0, leftDstNodeId, linkLeft.dstPin.channel);
    synth->connect(newNodeId, 1, rightDstNodeId, linkRight.dstPin.channel);

    juce::Logger::writeToLog("[InsertStereo] Successfully inserted stereo node with separate sources/destinations");
}

// --- REFACTORED OLD FUNCTION ---
void ImGuiNodeEditorComponent::insertNodeBetween(const juce::String& nodeType, const PinID& srcPin, const PinID& dstPin)
{
    if (synth == nullptr) return;

    // 1. Get positions to place the new node between the source and destination
    ImVec2 srcPos = ImNodes::GetNodeGridSpacePos(srcPin.logicalId);
    ImVec2 dstPos = ImNodes::GetNodeGridSpacePos(dstPin.logicalId == 0 ? 0 : dstPin.logicalId);
    ImVec2 newNodePos = ImVec2((srcPos.x + dstPos.x) * 0.5f, (srcPos.y + dstPos.y) * 0.5f);

    // 2. Create and position the new converter node
    // Check if this is a VST plugin
    juce::AudioProcessorGraph::NodeID newNodeId;
    auto& app = PresetCreatorApplication::getApp();
    auto& knownPluginList = app.getKnownPluginList();
    bool isVst = false;
    
    for (const auto& desc : knownPluginList.getTypes())
    {
        if (desc.name == nodeType)
        {
            newNodeId = synth->addVstModule(app.getPluginFormatManager(), desc);
            isVst = true;
            break;
        }
    }
    
    if (!isVst)
    {
        newNodeId = synth->addModule(nodeType);
    }
    
    auto newNodeLid = synth->getLogicalIdForNode(newNodeId);
    pendingNodePositions[(int)newNodeLid] = newNodePos;

    // 3. Get original node IDs
    auto originalSrcNodeId = synth->getNodeIdForLogical(srcPin.logicalId);
    auto originalDstNodeId = (dstPin.logicalId == 0)
        ? synth->getOutputNodeID()
        : synth->getNodeIdForLogical(dstPin.logicalId);

    // 4. Configure the new node if it's a MapRange or Attenuverter
    int newNodeOutputChannel = 0;
    if (nodeType == "MapRange") {
        if (auto* mapRange = dynamic_cast<MapRangeModuleProcessor*>(synth->getModuleForLogical(newNodeLid))) {
            PinDataType srcType = getPinDataTypeForPin(srcPin);
            PinDataType dstType = getPinDataTypeForPin(dstPin);
            Range inRange = getSourceRange(srcPin, synth);
            configureMapRangeFor(srcType, dstType, *mapRange, inRange);
            newNodeOutputChannel = (dstType == PinDataType::Audio) ? 1 : 0; // Use Raw Out for Audio, Norm Out for CV
        }
    } else if (nodeType == "Attenuverter") {
        // You might want to pre-configure the Attenuverter here if needed
    }

    // 5. Connect the signal chain: Original Source -> New Node -> Original Destination
    synth->connect(originalSrcNodeId, srcPin.channel, newNodeId, 0); // Source -> New Node's first input
    synth->connect(newNodeId, newNodeOutputChannel, originalDstNodeId, dstPin.channel); // New Node -> Destination

    juce::Logger::writeToLog("[AutoConvert] Inserted '" + nodeType + "' between " + juce::String(srcPin.logicalId) + " and " + juce::String(dstPin.logicalId));
}

void ImGuiNodeEditorComponent::insertNodeBetween(const juce::String& nodeType)
{
    // This function is now just a wrapper that calls the helper
    // with the stored link info and the current mouse position.
    if (linkToInsertOn.linkId != -1)
    {
        insertNodeOnLink(nodeType, linkToInsertOn, ImGui::GetMousePos());
        graphNeedsRebuild = true;
        pushSnapshot();
        linkToInsertOn.linkId = -1; // Reset state
    }
}

void ImGuiNodeEditorComponent::handleInsertNodeOnSelectedLinks(const juce::String& nodeType)
{
    if (synth == nullptr || ImNodes::NumSelectedLinks() == 0) return;

    pushSnapshot(); // Create one undo state for the entire batch operation.

    const int numSelectedLinks = ImNodes::NumSelectedLinks();
    std::vector<int> selectedLinkIds(numSelectedLinks);
    ImNodes::GetSelectedLinks(selectedLinkIds.data());

    ImVec2 basePosition = ImGui::GetMousePos();
    float x_offset = 0.0f;

    // === OPTION A: If exactly 2 audio cables are selected, insert ONE stereo node ===
    if (numSelectedLinks == 2)
    {
        // Get info for both cables
        auto it0 = linkIdToAttrs.find(selectedLinkIds[0]);
        auto it1 = linkIdToAttrs.find(selectedLinkIds[1]);
        
        if (it0 != linkIdToAttrs.end() && it1 != linkIdToAttrs.end())
        {
            LinkInfo link0, link1;
            link0.linkId = selectedLinkIds[0];
            link0.srcPin = decodePinId(it0->second.first);
            link0.dstPin = decodePinId(it0->second.second);
            link0.isMod = link0.srcPin.isMod || link0.dstPin.isMod;
            
            link1.linkId = selectedLinkIds[1];
            link1.srcPin = decodePinId(it1->second.first);
            link1.dstPin = decodePinId(it1->second.second);
            link1.isMod = link1.srcPin.isMod || link1.dstPin.isMod;
            
            // Check if BOTH are audio cables (not mod cables)
            if (!link0.isMod && !link1.isMod)
            {
                // Create ONE stereo node with link0 -> Left (ch0), link1 -> Right (ch1)
                insertNodeOnLinkStereo(nodeType, link0, link1, basePosition);
                juce::Logger::writeToLog("[InsertNode] Inserted STEREO node for 2 selected audio cables");
                graphNeedsRebuild = true;
                return; // Done - we've handled both cables with one node
            }
        }
    }

    // === FALLBACK: Multiple cables or mixed mod/audio - insert separate nodes ===
    std::set<int> processedLinks; // Track which links we've already handled
    
    for (size_t i = 0; i < selectedLinkIds.size(); ++i)
    {
        int linkId = selectedLinkIds[i];
        if (processedLinks.count(linkId)) continue;

        auto it = linkIdToAttrs.find(linkId);
        if (it == linkIdToAttrs.end()) continue;

        LinkInfo currentLink;
        currentLink.linkId = linkId;
        currentLink.srcPin = decodePinId(it->second.first);
        currentLink.dstPin = decodePinId(it->second.second);
        currentLink.isMod = currentLink.srcPin.isMod || currentLink.dstPin.isMod;

        ImVec2 newPosition = ImVec2(basePosition.x + x_offset, basePosition.y);
        
        // === MONO INSERT: Create separate node for each cable ===
        insertNodeOnLink(nodeType, currentLink, newPosition);
        processedLinks.insert(linkId);
        juce::Logger::writeToLog("[InsertNode] Inserted MONO node for link " + juce::String(linkId));

        x_offset += 40.0f;
    }

    graphNeedsRebuild = true;
    // The single pushSnapshot at the beginning handles the undo state.
}

juce::File ImGuiNodeEditorComponent::findPresetsDirectory()
{
    // Search upwards from the executable's location for a sibling directory
    // named "Synth_presets". This is robust to different build configurations.
    juce::File dir = juce::File::getSpecialLocation(juce::File::currentApplicationFile);

    for (int i = 0; i < 8; ++i) // Limit search depth to 8 levels
    {
        dir = dir.getParentDirectory();
        if (!dir.exists()) break;

        juce::File candidate = dir.getSiblingFile("Synth_presets");
        if (candidate.isDirectory())
        {
            return candidate;
        }
    }
    
    // Fallback to an empty file (system default) if not found
    return {};
}

// Helper function implementations
PinDataType ImGuiNodeEditorComponent::getPinDataTypeForPin(const PinID& pin)
{
    if (synth == nullptr) return PinDataType::Raw;

    // Handle the main output node as a special case
    if (pin.logicalId == 0)
    {
        return PinDataType::Audio;
    }

    juce::String moduleType = getTypeForLogical(pin.logicalId);
    if (moduleType.isEmpty()) return PinDataType::Raw;

    // *** NEW: Check dynamic pins FIRST ***
    if (auto* module = synth->getModuleForLogical(pin.logicalId))
    {
        // Check dynamic input pins
        if (pin.isInput && !pin.isMod)
        {
            auto dynamicInputs = module->getDynamicInputPins();
            for (const auto& dynPin : dynamicInputs)
            {
                if (dynPin.channel == pin.channel)
                {
                    return dynPin.type;
                }
            }
        }
        // Check dynamic output pins
        else if (!pin.isInput && !pin.isMod)
        {
            auto dynamicOutputs = module->getDynamicOutputPins();
            for (const auto& dynPin : dynamicOutputs)
            {
                if (dynPin.channel == pin.channel)
                {
                    return dynPin.type;
                }
            }
        }
    }
    // *** END NEW CODE ***

    auto it = getModulePinDatabase().find(moduleType);
    if (it == getModulePinDatabase().end())
    {
        // Fallback: case-insensitive lookup (module registry may use different casing)
        juce::String moduleTypeLower = moduleType.toLowerCase();
        for (const auto& kv : getModulePinDatabase())
        {
            if (kv.first.compareIgnoreCase(moduleType) == 0 || kv.first.toLowerCase() == moduleTypeLower)
            {
                it = getModulePinDatabase().find(kv.first);
                break;
            }
        }
        if (it == getModulePinDatabase().end())
        {
            // If the module type is not in our static database, it's likely a VST plugin.
            // A safe assumption is that its pins are for audio.
            if (auto* module = synth->getModuleForLogical(pin.logicalId))
            {
                if (dynamic_cast<VstHostModuleProcessor*>(module))
                {
                    return PinDataType::Audio; // Green for VST pins
                }
            }
            return PinDataType::Raw;
        }
    }

    const auto& pinInfo = it->second;

    if (pin.isMod)
    {
        for (const auto& modPin : pinInfo.modIns)
        {
            if (modPin.paramId == pin.paramId)
            {
                return modPin.type;
            }
        }
    }
    else // It's an audio pin
    {
        const auto& pins = pin.isInput ? pinInfo.audioIns : pinInfo.audioOuts;
        for (const auto& audioPin : pins)
        {
            if (audioPin.channel == pin.channel)
            {
                return audioPin.type;
            }
        }
    }
    return PinDataType::Raw; // Fallback
}

unsigned int ImGuiNodeEditorComponent::getImU32ForType(PinDataType type)
{
    switch (type)
    {
        case PinDataType::CV:    return IM_COL32(100, 150, 255, 255); // Blue
        case PinDataType::Audio: return IM_COL32(100, 255, 150, 255); // Green
        case PinDataType::Gate:  return IM_COL32(255, 220, 100, 255); // Yellow
        case PinDataType::Raw:   return IM_COL32(255, 100, 100, 255); // Red
        default:                 return IM_COL32(150, 150, 150, 255); // Grey
    }
}

const char* ImGuiNodeEditorComponent::pinDataTypeToString(PinDataType type)
{
    switch (type)
    {
        case PinDataType::CV:    return "CV (0 to 1)";
        case PinDataType::Audio: return "Audio (-1 to 1)";
        case PinDataType::Gate:  return "Gate/Trigger";
        case PinDataType::Raw:   return "Raw";
        default:                 return "Unknown";
    }
}

// Add this new function implementation to the .cpp file.

void ImGuiNodeEditorComponent::handleNodeChaining()
{
    if (synth == nullptr) return;

    const int numSelected = ImNodes::NumSelectedNodes();
    if (numSelected <= 1) return;

    juce::Logger::writeToLog("[Node Chaining] Initiated for " + juce::String(numSelected) + " nodes.");

    // 1. Get all selected nodes and their horizontal positions.
    std::vector<int> selectedNodeIds(numSelected);
    ImNodes::GetSelectedNodes(selectedNodeIds.data());

    std::vector<std::pair<float, int>> sortedNodes;
    for (int nodeId : selectedNodeIds)
    {
        // Don't include the main output node in the chaining logic.
        if (nodeId == 0) continue;
        ImVec2 pos = ImNodes::GetNodeGridSpacePos(nodeId);
        sortedNodes.push_back({pos.x, nodeId});
    }

    // 2. Sort the nodes from left to right based on their X position.
    std::sort(sortedNodes.begin(), sortedNodes.end(), [](const auto& a, const auto& b) {
        return a.first < b.first;
    });

    // Create a single undo action for the entire operation.
    pushSnapshot();

    // 3. Connect the nodes in sequence.
    for (size_t i = 0; i < sortedNodes.size() - 1; ++i)
    {
        juce::uint32 sourceLid = sortedNodes[i].second;
        juce::uint32 destLid   = sortedNodes[i + 1].second;

        auto sourceNodeId = synth->getNodeIdForLogical(sourceLid);
        auto destNodeId   = synth->getNodeIdForLogical(destLid);

        if (sourceNodeId.uid != 0 && destNodeId.uid != 0)
        {
            // Standard stereo connection: Out L -> In L, Out R -> In R
            synth->connect(sourceNodeId, 0, destNodeId, 0); // Connect channel 0
            synth->connect(sourceNodeId, 1, destNodeId, 1); // Connect channel 1

            juce::Logger::writeToLog("[Node Chaining] Connected " + getTypeForLogical(sourceLid) + " (" + juce::String(sourceLid) + ") to " + getTypeForLogical(destLid) + " (" + juce::String(destLid) + ")");
            
            // Check if the destination is a recorder and update its filename
            if (auto* destModule = synth->getModuleForLogical(destLid))
            {
                if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(destModule))
                {
                    if (auto* sourceModule = synth->getModuleForLogical(sourceLid))
                    {
                        recorder->updateSuggestedFilename(sourceModule->getName());
                    }
                }
            }
        }
    }

    // 4. Apply all the new connections to the audio graph.
    graphNeedsRebuild = true;
}

// Add this new helper function implementation.

std::vector<AudioPin> ImGuiNodeEditorComponent::getPinsOfType(juce::uint32 logicalId, bool isInput, PinDataType targetType)
{
    std::vector<AudioPin> matchingPins;
    juce::String moduleType = getTypeForLogical(logicalId);

    if (moduleType.isEmpty())
    {
        return matchingPins;
    }

    auto it = getModulePinDatabase().find(moduleType);

    // --- CASE-INSENSITIVE LOOKUP ---
    if (it == getModulePinDatabase().end())
    {
        for (const auto& kv : getModulePinDatabase())
        {
            if (kv.first.compareIgnoreCase(moduleType) == 0)
            {
                it = getModulePinDatabase().find(kv.first);
                break;
            }
        }
    }

    if (it != getModulePinDatabase().end())
    {
        // --- Standard path for built-in modules ---
        const auto& pins = isInput ? it->second.audioIns : it->second.audioOuts;
        for (const auto& pin : pins)
        {
            if (pin.type == targetType)
            {
                matchingPins.push_back(pin);
            }
        }
    }

    // If no static pins matched (or none defined), fall back to dynamic pins from the module
    if (matchingPins.empty())
    {
        if (auto* module = synth->getModuleForLogical(logicalId))
        {
            // --- DYNAMIC PATH FOR MODULES WITH getDynamicInputPins/getDynamicOutputPins ---
            auto dynamicPins = isInput ? module->getDynamicInputPins() : module->getDynamicOutputPins();
            
            if (!dynamicPins.empty())
            {
                // Module provides dynamic pins - filter by type
                for (const auto& pin : dynamicPins)
                {
                    if (pin.type == targetType)
                    {
                        matchingPins.emplace_back(pin.name, pin.channel, pin.type);
                    }
                }
            }
            else if (auto* vst = dynamic_cast<VstHostModuleProcessor*>(module))
            {
                // For VSTs without dynamic pins, assume all pins are 'Audio' type for chaining.
                if (targetType == PinDataType::Audio)
                {
                    const int numChannels = isInput ? vst->getTotalNumInputChannels() : vst->getTotalNumOutputChannels();
                    for (int i = 0; i < numChannels; ++i)
                    {
                        juce::String pinName = isInput ? vst->getAudioInputLabel(i) : vst->getAudioOutputLabel(i);
                        if (pinName.isNotEmpty())
                        {
                            matchingPins.emplace_back(pinName, i, PinDataType::Audio);
                        }
                    }
                }
            }
        }
    }

    return matchingPins;
}

// Add this new function implementation to the .cpp file.

void ImGuiNodeEditorComponent::handleRecordOutput()
{
    if (!synth) return;

    pushSnapshot();
    juce::Logger::writeToLog("[Record Output] Initiated.");

    // 1. Find connections going to the main output node.
    std::vector<ModularSynthProcessor::ConnectionInfo> outputFeeds;
    for (const auto& c : synth->getConnectionsInfo())
    {
        if (c.dstIsOutput)
        {
            outputFeeds.push_back(c);
        }
    }

    if (outputFeeds.empty())
    {
        juce::Logger::writeToLog("[Record Output] No connections to main output found.");
        return;
    }

    // 2. Create and position the recorder.
    auto recorderNodeId = synth->addModule("recorder");
    auto recorderLid = synth->getLogicalIdForNode(recorderNodeId);
    ImVec2 outPos = ImNodes::GetNodeGridSpacePos(0);
    pendingNodePositions[(int)recorderLid] = ImVec2(outPos.x - 400.0f, outPos.y);
    
    auto* recorder = dynamic_cast<RecordModuleProcessor*>(synth->getModuleForLogical(recorderLid));
    if (recorder)
    {
        recorder->setPropertiesFile(PresetCreatorApplication::getApp().getProperties());
    }

    // 3. "Tap" the signals by connecting the original sources to the recorder.
    juce::String sourceName;
    for (const auto& feed : outputFeeds)
    {
        auto srcNodeId = synth->getNodeIdForLogical(feed.srcLogicalId);
        synth->connect(srcNodeId, feed.srcChan, recorderNodeId, feed.dstChan); // dstChan will be 0 or 1
        
        // Get the name of the first source for the filename prefix
        if (sourceName.isEmpty())
        {
            if (auto* srcModule = synth->getModuleForLogical(feed.srcLogicalId))
            {
                sourceName = srcModule->getName();
            }
        }
    }
    
    if (recorder)
    {
        recorder->updateSuggestedFilename(sourceName);
    }

    graphNeedsRebuild = true;
    juce::Logger::writeToLog("[Record Output] Recorder added and connected.");
}

void ImGuiNodeEditorComponent::handleColorCodedChaining(PinDataType targetType)
{
    if (synth == nullptr)
    {
        juce::Logger::writeToLog("[Color Chaining] ERROR: synth is nullptr");
        return;
    }

    const int numSelected = ImNodes::NumSelectedNodes();
    if (numSelected <= 1)
    {
        juce::Logger::writeToLog("[Color Chaining] ERROR: numSelected <= 1 (" + juce::String(numSelected) + ")");
        return;
    }

    juce::Logger::writeToLog("[Color Chaining] Started for " + juce::String(toString(targetType)) + " with " + juce::String(numSelected) + " nodes");

    // 1. Get and sort selected nodes by their horizontal position.
    std::vector<int> selectedNodeIds(numSelected);
    ImNodes::GetSelectedNodes(selectedNodeIds.data());

    std::vector<std::pair<float, int>> sortedNodes;
    for (int nodeId : selectedNodeIds)
    {
        if (nodeId == 0) continue; // Exclude the output node.
        ImVec2 pos = ImNodes::GetNodeGridSpacePos(nodeId);
        sortedNodes.push_back({pos.x, nodeId});
    }

    if (sortedNodes.empty())
    {
        juce::Logger::writeToLog("[Color Chaining] ERROR: No valid nodes after filtering");
        return;
    }

    std::sort(sortedNodes.begin(), sortedNodes.end(), [](const auto& a, const auto& b) {
        return a.first < b.first;
    });

    // Create a single undo action for the entire operation.
    pushSnapshot();

    int totalConnectionsMade = 0;
    int totalConnectionAttempts = 0;

    // 2. Iterate through sorted nodes and connect matching pins.
    for (size_t i = 0; i < sortedNodes.size() - 1; ++i)
    {
        juce::uint32 sourceLid = sortedNodes[i].second;
        juce::uint32 destLid   = sortedNodes[i + 1].second;

        auto sourceNodeId = synth->getNodeIdForLogical(sourceLid);
        auto destNodeId   = synth->getNodeIdForLogical(destLid);

        if (sourceNodeId.uid == 0 || destNodeId.uid == 0)
        {
            juce::Logger::writeToLog("[Color Chaining] Skipping invalid node pair: " + juce::String(sourceLid) + " -> " + juce::String(destLid));
            continue;
        }

        // Find all matching output pins on the source and input pins on the destination.
        auto sourcePins = getPinsOfType(sourceLid, false, targetType);
        auto destPins   = getPinsOfType(destLid, true, targetType);

        if (sourcePins.empty() || destPins.empty())
        {
            juce::Logger::writeToLog("[Color Chaining] No matching pins: " + juce::String(sourcePins.size()) + " src, " + juce::String(destPins.size()) + " dst");
            continue;
        }

        // Connect them one-to-one until we run out of available pins on either side.
        int connectionsToMake = std::min((int)sourcePins.size(), (int)destPins.size());

        for (int j = 0; j < connectionsToMake; ++j)
        {
            totalConnectionAttempts++;
            bool connectResult = synth->connect(sourceNodeId, sourcePins[j].channel, destNodeId, destPins[j].channel);
            if (connectResult)
            {
                totalConnectionsMade++;
                juce::Logger::writeToLog("[Color Chaining] Connected " + getTypeForLogical(sourceLid) + " -> " + getTypeForLogical(destLid));

                // Check if the destination is a recorder and update its filename
                if (auto* destModule = synth->getModuleForLogical(destLid))
                {
                    if (auto* recorder = dynamic_cast<RecordModuleProcessor*>(destModule))
                    {
                        if (auto* sourceModule = synth->getModuleForLogical(sourceLid))
                        {
                            recorder->updateSuggestedFilename(sourceModule->getName());
                        }
                    }
                }
            }
        }
    }

    juce::Logger::writeToLog("[Color Chaining] Completed: " + juce::String(totalConnectionsMade) + "/" + juce::String(totalConnectionAttempts) + " connections made");

    // 3. Apply all new connections to the audio graph.
    graphNeedsRebuild = true;
}

// Module Category Color Coding
ImGuiNodeEditorComponent::ModuleCategory ImGuiNodeEditorComponent::getModuleCategory(const juce::String& moduleType)
{
    juce::String lower = moduleType.toLowerCase();
    
    // === CATEGORY CLASSIFICATION (Following Dictionary Structure) ===
    
    // --- 1. SOURCES (Green) ---
    if (lower.contains("vco") || lower.contains("polyvco") ||
        lower.contains("noise") || lower == "audio_input" || 
        lower.contains("sample") || lower == "value")
        return ModuleCategory::Source;
    
    // --- 2. EFFECTS (Red) ---
    // Note: Recorder moved to System, Vocal Tract Filter moved to TTS
    if (lower.contains("vcf") || lower.contains("delay") || 
        lower.contains("reverb") || lower.contains("chorus") || 
        lower.contains("phaser") || lower.contains("compressor") || 
        lower.contains("limiter") || lower == "gate" ||
        lower.contains("drive") || lower.contains("eq") ||
        lower.contains("waveshaper") || lower.contains("8bandshaper") ||
        lower.contains("granulator") || lower.contains("harmonic_shaper") ||
        lower.contains("timepitch") || lower.contains("crackle"))
        return ModuleCategory::Effect;
    
    // --- 3. MODULATORS (Blue) ---
    if (lower.contains("lfo") || lower.contains("adsr") || 
        lower.contains("random") || lower.contains("s&h") || 
        lower.contains("function_generator") || lower.contains("shaping_oscillator"))
        return ModuleCategory::Modulator;
    
    // --- 4. UTILITIES & LOGIC (Orange) ---
    if (lower.contains("vca") || lower.contains("mixer") || 
        lower.contains("attenuverter") || lower.contains("lag_processor") ||
        lower.contains("math") || lower.contains("map_range") ||
        lower.contains("quantizer") || lower.contains("rate") ||
        lower.contains("comparator") || lower.contains("logic") ||
        lower.contains("clock_divider") || lower.contains("sequential_switch"))
        return ModuleCategory::Utility;
    
    // --- 5. SEQUENCERS (Light Green) ---
    if (lower.contains("sequencer") || lower.contains("tempo_clock"))
        return ModuleCategory::Seq;
    
    // --- 6. MIDI (Vibrant Purple) ---
    if (lower.contains("midi"))
        return ModuleCategory::MIDI;
    
    // --- 7. ANALYSIS (Purple) ---
    if (lower.contains("scope") || lower.contains("debug") || 
        lower.contains("frequency_graph"))
        return ModuleCategory::Analysis;
    
    // --- 8. TTS (Peach/Coral) ---
    if (lower.contains("tts") || lower.contains("vocal_tract"))
        return ModuleCategory::TTS_Voice;
    
    // --- 9. SPECIAL (Cyan) - Physics & Animation ---
    if (lower.contains("physics") || lower.contains("animation"))
        return ModuleCategory::Special_Exp;
    
    // --- 10. COMPUTER VISION (Bright Orange) ---
    if (lower.contains("webcam") || lower.contains("video_file") ||
        lower.contains("movement") || lower.contains("detector") || 
        lower.contains("opencv") || lower.contains("vision") ||
        lower.contains("tracker") || lower.contains("segmentation") ||
        lower.contains("pose_estimator"))
        return ModuleCategory::OpenCV;
    
    // --- 11. SYSTEM (Lavender) ---
    if (lower.contains("meta") || lower.contains("inlet") || 
        lower.contains("outlet") || lower.contains("comment") ||
        lower.contains("recorder") || lower.contains("vst_host") ||
        lower.contains("best_practice"))
        return ModuleCategory::Sys;
    
    // --- 12. PLUGINS (Teal) ---
    if (lower.contains("vst") || lower.contains("plugin"))
        return ModuleCategory::Plugin;
    
    // --- Default: Utility ---
    return ModuleCategory::Utility;
}

unsigned int ImGuiNodeEditorComponent::getImU32ForCategory(ModuleCategory category, bool hovered)
{
    ImU32 color;
    switch (category)
    {
        case ModuleCategory::Source:      color = IM_COL32(50, 120, 50, 255); break;     // Green
        case ModuleCategory::Effect:      color = IM_COL32(130, 60, 60, 255); break;     // Red
        case ModuleCategory::Modulator:   color = IM_COL32(50, 50, 130, 255); break;     // Blue
        case ModuleCategory::Utility:     color = IM_COL32(110, 80, 50, 255); break;     // Orange
        case ModuleCategory::Seq:         color = IM_COL32(90, 140, 90, 255); break;     // Light Green
        case ModuleCategory::MIDI:        color = IM_COL32(180, 120, 255, 255); break;   // Vibrant Purple
        case ModuleCategory::Analysis:    color = IM_COL32(100, 50, 110, 255); break;    // Purple
        case ModuleCategory::TTS_Voice:   color = IM_COL32(255, 180, 100, 255); break;   // Peach/Coral
        case ModuleCategory::Special_Exp: color = IM_COL32(50, 200, 200, 255); break;    // Cyan
        case ModuleCategory::OpenCV:      color = IM_COL32(255, 140, 0, 255); break;     // Bright Orange
        case ModuleCategory::Sys:         color = IM_COL32(120, 100, 140, 255); break;   // Lavender
        case ModuleCategory::Comment:     color = IM_COL32(80, 80, 80, 255); break;      // Grey
        case ModuleCategory::Plugin:      color = IM_COL32(50, 110, 110, 255); break;    // Teal
        default:                         color = IM_COL32(70, 70, 70, 255); break;
    }
    
    if (hovered) 
    { 
        // Brighten on hover
        ImVec4 c = ImGui::ColorConvertU32ToFloat4(color);
        c.x *= 1.3f; c.y *= 1.3f; c.z *= 1.3f;
        return ImGui::ColorConvertFloat4ToU32(c);
    }
    return color;
}

// Quick Add Menu - Module Registry - Dictionary
// Maps Display Name -> { Internal Type, Description }
std::map<juce::String, std::pair<const char*, const char*>> ImGuiNodeEditorComponent::getModuleRegistry()
{
    return {
        // Sources
        {"Audio Input", {"audio_input", "Records audio from your audio interface"}},
        {"VCO", {"vco", "Voltage Controlled Oscillator - generates waveforms"}},
        {"Polyphonic VCO", {"polyvco", "Polyphonic VCO with multiple voices"}},
        {"Noise", {"noise", "White, pink, or brown noise generator"}},
        {"Sequencer", {"sequencer", "Step sequencer for creating patterns"}},
        {"Multi Sequencer", {"multi_sequencer", "Multi-track step sequencer"}},
        {"Stroke Sequencer", {"stroke_sequencer", "Freeform visual rhythmic and CV generator"}},
        {"MIDI Player", {"midi_player", "Plays MIDI files"}},
        {"MIDI CV", {"midi_cv", "Converts MIDI Note/CC messages to CV signals. (Monophonic)"}},
        {"MIDI Faders", {"midi_faders", "Up to 16 MIDI faders with CC learning"}},
        {"MIDI Knobs", {"midi_knobs", "Up to 16 MIDI knobs/rotary encoders with CC learning"}},
        {"MIDI Buttons", {"midi_buttons", "Up to 32 MIDI buttons with Gate/Toggle/Trigger modes"}},
        {"MIDI Jog Wheel", {"midi_jog_wheel", "Single MIDI jog wheel/rotary encoder"}},
        {"MIDI Pads", {"midi_pads", "16-pad MIDI controller with polyphonic triggers and velocity outputs"}},
        {"MIDI Logger", {"midi_logger", "Records CV/Gate to MIDI events with piano roll editor and .mid export"}},
        {"Value", {"value", "Constant CV value output"}},
        {"Sample Loader", {"sample_loader", "Loads and plays audio samples"}},
        
        // TTS
        {"TTS Performer", {"tts_performer", "Text-to-speech synthesizer"}},
        {"Vocal Tract Filter", {"vocal_tract_filter", "Physical model vocal tract filter"}},
        
        // Physics & Animation
        {"Physics", {"physics", "2D physics simulation for audio modulation"}},
        {"Animation", {"animation", "Skeletal animation system with glTF file support"}},
        
        // OpenCV (Computer Vision)
        {"Webcam Loader", {"webcam_loader", "Captures video from a webcam and publishes it as a source for vision processing modules"}},
        {"Video File Loader", {"video_file_loader", "Loads and plays a video file, publishes it as a source for vision processing modules"}},
        {"Movement Detector", {"movement_detector", "Analyzes video source for motion via optical flow or background subtraction, outputs motion data as CV"}},
        {"Human Detector", {"human_detector", "Detects faces or bodies in video source via Haar Cascades or HOG, outputs position and size as CV"}},
        {"Object Detector", {"object_detector", "Uses YOLOv3 to detect objects (person, car, etc.) and outputs bounding box position/size as CV"}},
        {"Pose Estimator", {"pose_estimator", "Uses OpenPose to detect 15 body keypoints (head, shoulders, elbows, wrists, hips, knees, ankles) and outputs their positions as CV signals"}},
        {"Hand Tracker", {"hand_tracker", "Detects 21 hand keypoints and outputs their X/Y positions as CV (42 channels)"}},
        {"Face Tracker", {"face_tracker", "Detects 70 facial landmarks and outputs X/Y positions as CV (140 channels)"}},
        {"Color Tracker", {"color_tracker", "Tracks multiple colors in video and outputs their positions and sizes as CV"}},
        {"Contour Detector", {"contour_detector", "Detects shapes via background subtraction and outputs area, complexity, and aspect ratio as CV"}},
        {"Semantic Segmentation", {"semantic_segmentation", "Uses deep learning to segment video into semantic regions and outputs detected areas as CV"}},
        
        // Effects
        {"VCF", {"vcf", "Voltage Controlled Filter"}},
        {"Delay", {"delay", "Echo/delay effect"}},
        {"Reverb", {"reverb", "Reverb effect"}},
        {"Chorus", {"chorus", "Chorus effect for thickening sound"}},
        {"Phaser", {"phaser", "Phaser modulation effect"}},
        {"Compressor", {"compressor", "Dynamic range compressor"}},
        {"Recorder", {"recorder", "Records audio to disk"}},
        {"Limiter", {"limiter", "Peak limiter"}},
        {"Noise Gate", {"gate", "Noise gate"}},
        {"Drive", {"drive", "Distortion/overdrive"}},
        {"Graphic EQ", {"graphic_eq", "Graphic equalizer"}},
        {"Waveshaper", {"waveshaper", "Waveshaping distortion"}},
        {"8-Band Shaper", {"8bandshaper", "8-band spectral shaper"}},
        {"Granulator", {"granulator", "Granular synthesis effect"}},
        {"Harmonic Shaper", {"harmonic_shaper", "Harmonic content shaper"}},
        {"Time/Pitch Shifter", {"timepitch", "Time stretching and pitch shifting"}},
        {"De-Crackle", {"de_crackle", "Removes clicks and pops"}},
        
        // Modulators
        {"LFO", {"lfo", "Low Frequency Oscillator for modulation"}},
        {"ADSR", {"adsr", "Attack Decay Sustain Release envelope"}},
        {"Random", {"random", "Random value generator"}},
        {"S&H", {"s_and_h", "Sample and Hold"}},
        {"Tempo Clock", {"tempo_clock", "Global clock with BPM control, transport (play/stop/reset), division, swing, and clock/gate outputs. Use External Takeover to drive the master transport."}},
        {"Function Generator", {"function_generator", "Custom function curves"}},
        {"Shaping Oscillator", {"shaping_oscillator", "Oscillator with waveshaping"}},
        
        // Utilities
        {"VCA", {"vca", "Voltage Controlled Amplifier"}},
        {"Mixer", {"mixer", "Audio/CV mixer"}},
        {"CV Mixer", {"cv_mixer", "CV signal mixer"}},
        {"Track Mixer", {"track_mixer", "Multi-track mixer with panning"}},
        {"Attenuverter", {"attenuverter", "Attenuate and invert signals"}},
        {"Lag Processor", {"lag_processor", "Slew rate limiter/smoother"}},
        {"Math", {"math", "Mathematical operations"}},
        {"Map Range", {"map_range", "Map values from one range to another"}},
        {"Quantizer", {"quantizer", "Quantize CV to scales"}},
        {"Rate", {"rate", "Rate/frequency divider"}},
        {"Comparator", {"comparator", "Compare and threshold signals"}},
        {"Logic", {"logic", "Boolean logic operations"}},
        {"Clock Divider", {"clock_divider", "Clock division and multiplication"}},
        {"Sequential Switch", {"sequential_switch", "Sequential signal router"}},
        {"Comment", {"comment", "Text comment box"}},
        {"Best Practice", {"best_practice", "Best practice node template"}},
        {"Snapshot Sequencer", {"snapshot_sequencer", "Snapshot sequencer for parameter automation"}},
        
        // Analysis
        {"Scope", {"scope", "Oscilloscope display"}},
        {"Debug", {"debug", "Debug value display"}},
        {"Input Debug", {"input_debug", "Input signal debugger"}},
        {"Frequency Graph", {"frequency_graph", "Spectrum analyzer display"}}
    };
}

// Legacy function for backwards compatibility with tooltip display
std::vector<std::pair<juce::String, const char*>> ImGuiNodeEditorComponent::getModuleDescriptions()
{
    std::vector<std::pair<juce::String, const char*>> result;
    for (const auto& entry : getModuleRegistry())
    {
        // Return {internal type, description} for compatibility
        result.push_back({entry.second.first, entry.second.second});
    }
    return result;
}

// VST Plugin Support
void ImGuiNodeEditorComponent::addPluginModules()
{
    if (synth == nullptr)
        return;
    
    auto& app = PresetCreatorApplication::getApp();
    auto& knownPluginList = app.getKnownPluginList();
    auto& formatManager = app.getPluginFormatManager();
    
    // Set the plugin format manager and known plugin list on the synth if not already set
    synth->setPluginFormatManager(&formatManager);
    synth->setKnownPluginList(&knownPluginList);
    
    // Display each known plugin as a button
    const auto& plugins = knownPluginList.getTypes();
    
    if (plugins.isEmpty())
    {
        ImGui::TextDisabled("No plugins found.");
        ImGui::TextDisabled("Use 'Scan for Plugins...' in the File menu.");
        return;
    }
    
    for (const auto& desc : plugins)
    {
        juce::String buttonLabel = desc.name;
        if (desc.manufacturerName.isNotEmpty())
        {
            buttonLabel += " (" + desc.manufacturerName + ")";
        }
        
        if (ImGui::Selectable(buttonLabel.toRawUTF8()))
        {
            auto nodeId = synth->addVstModule(formatManager, desc);
            if (nodeId.uid != 0)
            {
                const ImVec2 mouse = ImGui::GetMousePos();
                const auto logicalId = synth->getLogicalIdForNode(nodeId);
                pendingNodeScreenPositions[(int)logicalId] = mouse;
                snapshotAfterEditor = true;
                juce::Logger::writeToLog("[VST] Added plugin: " + desc.name);
            }
            else
            {
                juce::Logger::writeToLog("[VST] ERROR: Failed to add plugin: " + desc.name);
            }
        }
        
        // Show tooltip with plugin info on hover
        if (ImGui::IsItemHovered())
        {
            ImGui::BeginTooltip();
            ImGui::Text("Name: %s", desc.name.toRawUTF8());
            ImGui::Text("Manufacturer: %s", desc.manufacturerName.toRawUTF8());
            ImGui::Text("Version: %s", desc.version.toRawUTF8());
            ImGui::Text("Format: %s", desc.pluginFormatName.toRawUTF8());
            ImGui::Text("Type: %s", desc.isInstrument ? "Instrument" : "Effect");
            ImGui::Text("Inputs: %d", desc.numInputChannels);
            ImGui::Text("Outputs: %d", desc.numOutputChannels);
            ImGui::EndTooltip();
        }
    }
}

void ImGuiNodeEditorComponent::handleCollapseToMetaModule()
{
    if (!synth)
        return;
    
    juce::Logger::writeToLog("[Meta Module] Starting collapse operation...");
    
    // 1. Get selected nodes
    const int numSelected = ImNodes::NumSelectedNodes();
    if (numSelected < 2)
    {
        juce::Logger::writeToLog("[Meta Module] ERROR: Need at least 2 nodes selected");
        return;
    }
    
    std::vector<int> selectedNodeIds(numSelected);
    ImNodes::GetSelectedNodes(selectedNodeIds.data());
    
    // Convert to logical IDs
    std::set<juce::uint32> selectedLogicalIds;
    for (int nodeId : selectedNodeIds)
    {
        selectedLogicalIds.insert((juce::uint32)nodeId);
    }
    
    juce::Logger::writeToLog("[Meta Module] Selected " + juce::String(numSelected) + " nodes");
    
    // 2. Analyze boundary connections
    struct BoundaryConnection
    {
        juce::uint32 externalLogicalId;
        int externalChannel;
        juce::uint32 internalLogicalId;
        int internalChannel;
        bool isInput; // true = external -> internal, false = internal -> external
    };
    
    std::vector<BoundaryConnection> boundaries;
    auto allConnections = synth->getConnectionsInfo();
    
    for (const auto& conn : allConnections)
    {
        bool srcIsSelected = selectedLogicalIds.count(conn.srcLogicalId) > 0;
        bool dstIsSelected = selectedLogicalIds.count(conn.dstLogicalId) > 0 && !conn.dstIsOutput;
        bool dstIsOutput = conn.dstIsOutput;
        
        // Inlet: external -> selected
        if (!srcIsSelected && dstIsSelected)
        {
            BoundaryConnection bc;
            bc.externalLogicalId = conn.srcLogicalId;
            bc.externalChannel = conn.srcChan;
            bc.internalLogicalId = conn.dstLogicalId;
            bc.internalChannel = conn.dstChan;
            bc.isInput = true;
            boundaries.push_back(bc);
            juce::Logger::writeToLog("[Meta Module] Found inlet: " + juce::String(bc.externalLogicalId) + 
                                    " -> " + juce::String(bc.internalLogicalId));
        }
        // Outlet: selected -> external or output
        else if (srcIsSelected && (!dstIsSelected || dstIsOutput))
        {
            BoundaryConnection bc;
            bc.externalLogicalId = dstIsOutput ? 0 : conn.dstLogicalId;
            bc.externalChannel = conn.dstChan;
            bc.internalLogicalId = conn.srcLogicalId;
            bc.internalChannel = conn.srcChan;
            bc.isInput = false;
            boundaries.push_back(bc);
            juce::Logger::writeToLog("[Meta Module] Found outlet: " + juce::String(bc.internalLogicalId) + 
                                    " -> " + (dstIsOutput ? "OUTPUT" : juce::String(bc.externalLogicalId)));
        }
    }
    
    // Count inlets and outlets
    int numInlets = 0;
    int numOutlets = 0;
    for (const auto& bc : boundaries)
    {
        if (bc.isInput)
            numInlets++;
        else
            numOutlets++;
    }
    
    juce::Logger::writeToLog("[META] Boundary Detection: Found " + juce::String(numInlets) + " inlets and " + juce::String(numOutlets) + " outlets.");
    juce::Logger::writeToLog("[META] Found " + juce::String(boundaries.size()) + " boundary connections");
    
    if (boundaries.empty())
    {
        juce::Logger::writeToLog("[META] WARNING: No boundary connections - creating isolated meta module");
    }
    
    // 3. Create the internal graph state
    pushSnapshot(); // Make undoable
    
    // Save the state of selected nodes
    juce::MemoryBlock internalState;
    {
        // Create a temporary state containing only selected nodes
        juce::ValueTree internalRoot("ModularSynthPreset");
        internalRoot.setProperty("version", 1, nullptr);
        
        juce::ValueTree modsVT("modules");
        juce::ValueTree connsVT("connections");
        
        // Add selected modules
        std::map<juce::uint32, juce::uint32> oldToNewLogicalId;
        juce::uint32 newLogicalId = 1;
        
        for (juce::uint32 oldId : selectedLogicalIds)
        {
            oldToNewLogicalId[oldId] = newLogicalId++;
            
            auto* module = synth->getModuleForLogical(oldId);
            if (!module)
                continue;
            
            juce::String moduleType = synth->getModuleTypeForLogical(oldId);
            
            juce::ValueTree mv("module");
            mv.setProperty("logicalId", (int)oldToNewLogicalId[oldId], nullptr);
            mv.setProperty("type", moduleType, nullptr);
            
            // Save parameters
            juce::ValueTree params = module->getAPVTS().copyState();
            juce::ValueTree paramsWrapper("params");
            paramsWrapper.addChild(params, -1, nullptr);
            mv.addChild(paramsWrapper, -1, nullptr);
            
            // Save extra state
            if (auto extra = module->getExtraStateTree(); extra.isValid())
            {
                juce::ValueTree extraWrapper("extra");
                extraWrapper.addChild(extra, -1, nullptr);
                mv.addChild(extraWrapper, -1, nullptr);
            }
            
            modsVT.addChild(mv, -1, nullptr);
        }
        
        // Add inlet modules for each unique input
        std::map<std::pair<juce::uint32, int>, juce::uint32> inletMap; // (extId, extCh) -> inletLogicalId
        for (const auto& bc : boundaries)
        {
            if (bc.isInput)
            {
                auto key = std::make_pair(bc.externalLogicalId, bc.externalChannel);
                if (inletMap.find(key) == inletMap.end())
                {
                    juce::uint32 inletId = newLogicalId++;
                    inletMap[key] = inletId;
                    
                    juce::ValueTree mv("module");
                    mv.setProperty("logicalId", (int)inletId, nullptr);
                    mv.setProperty("type", "inlet", nullptr);
                    modsVT.addChild(mv, -1, nullptr);
                    
                    juce::Logger::writeToLog("[Meta Module] Created inlet node ID=" + juce::String(inletId));
                }
            }
        }
        
        // Add outlet modules for each unique output
        std::map<std::pair<juce::uint32, int>, juce::uint32> outletMap; // (intId, intCh) -> outletLogicalId
        for (const auto& bc : boundaries)
        {
            if (!bc.isInput)
            {
                auto key = std::make_pair(bc.internalLogicalId, bc.internalChannel);
                if (outletMap.find(key) == outletMap.end())
                {
                    juce::uint32 outletId = newLogicalId++;
                    outletMap[key] = outletId;
                    
                    juce::ValueTree mv("module");
                    mv.setProperty("logicalId", (int)outletId, nullptr);
                    mv.setProperty("type", "outlet", nullptr);
                    modsVT.addChild(mv, -1, nullptr);
                    
                    juce::Logger::writeToLog("[Meta Module] Created outlet node ID=" + juce::String(outletId));
                }
            }
        }
        
        // Add internal connections (between selected nodes)
        for (const auto& conn : allConnections)
        {
            bool srcIsSelected = selectedLogicalIds.count(conn.srcLogicalId) > 0;
            bool dstIsSelected = selectedLogicalIds.count(conn.dstLogicalId) > 0;
            
            if (srcIsSelected && dstIsSelected)
            {
                juce::ValueTree cv("connection");
                cv.setProperty("srcId", (int)oldToNewLogicalId[conn.srcLogicalId], nullptr);
                cv.setProperty("srcChan", conn.srcChan, nullptr);
                cv.setProperty("dstId", (int)oldToNewLogicalId[conn.dstLogicalId], nullptr);
                cv.setProperty("dstChan", conn.dstChan, nullptr);
                connsVT.addChild(cv, -1, nullptr);
            }
        }
        
        // Add connections from inlets to internal nodes
        for (const auto& bc : boundaries)
        {
            if (bc.isInput)
            {
                auto key = std::make_pair(bc.externalLogicalId, bc.externalChannel);
                juce::uint32 inletId = inletMap[key];
                
                juce::ValueTree cv("connection");
                cv.setProperty("srcId", (int)inletId, nullptr);
                cv.setProperty("srcChan", 0, nullptr); // Inlets output on channel 0
                cv.setProperty("dstId", (int)oldToNewLogicalId[bc.internalLogicalId], nullptr);
                cv.setProperty("dstChan", bc.internalChannel, nullptr);
                connsVT.addChild(cv, -1, nullptr);
            }
        }
        
        // Add connections from internal nodes to outlets
        for (const auto& bc : boundaries)
        {
            if (!bc.isInput)
            {
                auto key = std::make_pair(bc.internalLogicalId, bc.internalChannel);
                juce::uint32 outletId = outletMap[key];
                
                juce::ValueTree cv("connection");
                cv.setProperty("srcId", (int)oldToNewLogicalId[bc.internalLogicalId], nullptr);
                cv.setProperty("srcChan", bc.internalChannel, nullptr);
                cv.setProperty("dstId", (int)outletId, nullptr);
                cv.setProperty("dstChan", 0, nullptr); // Outlets input on channel 0
                connsVT.addChild(cv, -1, nullptr);
            }
        }
        
        internalRoot.addChild(modsVT, -1, nullptr);
        internalRoot.addChild(connsVT, -1, nullptr);
        
        // Serialize to memory block
        if (auto xml = internalRoot.createXml())
        {
            juce::MemoryOutputStream mos(internalState, false);
            xml->writeTo(mos);
            juce::Logger::writeToLog("[META] Generated state for sub-patch.");
        }
    }
    
    // 4. Calculate average position for the meta module
    ImVec2 avgPos(0.0f, 0.0f);
    int posCount = 0;
    for (juce::uint32 logicalId : selectedLogicalIds)
    {
        ImVec2 pos = ImNodes::GetNodeGridSpacePos((int)logicalId);
        avgPos.x += pos.x;
        avgPos.y += pos.y;
        posCount++;
    }
    if (posCount > 0)
    {
        avgPos.x /= posCount;
        avgPos.y /= posCount;
    }
    
    // 5. Delete selected nodes
    for (juce::uint32 logicalId : selectedLogicalIds)
    {
        auto nodeId = synth->getNodeIdForLogical(logicalId);
        synth->removeModule(nodeId);
    }
    
    // 6. Create meta module
    auto metaNodeId = synth->addModule("meta module");
    auto metaLogicalId = synth->getLogicalIdForNode(metaNodeId);
    pendingNodePositions[(int)metaLogicalId] = avgPos;
    
    juce::Logger::writeToLog("[META] Created new MetaModule with logical ID: " + juce::String((int)metaLogicalId));
    
    auto* metaModule = dynamic_cast<MetaModuleProcessor*>(synth->getModuleForLogical(metaLogicalId));
    if (metaModule)
    {
        // Load the internal state
        metaModule->setStateInformation(internalState.getData(), (int)internalState.getSize());
        juce::Logger::writeToLog("[META] Loaded internal state into meta module");
    }
    else
    {
        juce::Logger::writeToLog("[META] ERROR: Failed to create meta module");
        return;
    }
    
    // 7. Reconnect external connections
    // Note: This is a simplified implementation - in production, you'd need to map
    // inlet/outlet indices to meta module input/output channels properly
    for (const auto& bc : boundaries)
    {
        if (bc.isInput)
        {
            // Connect external source to meta module input
            auto extNodeId = synth->getNodeIdForLogical(bc.externalLogicalId);
            synth->connect(extNodeId, bc.externalChannel, metaNodeId, 0);
        }
        else if (bc.externalLogicalId != 0)
        {
            // Connect meta module output to external destination
            auto extNodeId = synth->getNodeIdForLogical(bc.externalLogicalId);
            synth->connect(metaNodeId, 0, extNodeId, bc.externalChannel);
        }
        else
        {
            // Connect meta module output to main output
            auto outputNodeId = synth->getOutputNodeID();
            synth->connect(metaNodeId, 0, outputNodeId, bc.externalChannel);
        }
    }
    
    graphNeedsRebuild = true;
    synth->commitChanges();
    
    juce::Logger::writeToLog("[META] Reconnected external cables. Collapse complete!");
}

void ImGuiNodeEditorComponent::loadPresetFromFile(const juce::File& file)
{
    if (!file.existsAsFile() || synth == nullptr)
        return;

    // 1. Load the file content.
    juce::MemoryBlock mb;
    file.loadFileAsData(mb);

    // 2. Set the synthesizer's state. This rebuilds the audio graph.
    synth->setStateInformation(mb.getData(), (int)mb.getSize());

    // 3. Parse the XML to find the UI state.
    juce::ValueTree uiState;
    if (auto xml = juce::XmlDocument::parse(mb.toString()))
    {
        auto vt = juce::ValueTree::fromXml(*xml);
        uiState = vt.getChildWithName("NodeEditorUI");
        if (uiState.isValid())
        {
            // 4. Apply the UI state (node positions, muted status, etc.).
            // This queues the changes to be applied on the next frame.
            applyUiValueTree(uiState);
        }
    }

    // 5. Create an undo snapshot for this action.
    Snapshot s;
    synth->getStateInformation(s.synthState);
    s.uiState = uiState.isValid() ? uiState : getUiValueTree();
    undoStack.push_back(std::move(s));
    redoStack.clear();

    // 6. Update the UI status trackers.
    isPatchDirty = false;
    currentPresetFile = file.getFileName();
    
    juce::Logger::writeToLog("[Preset] Successfully loaded preset: " + file.getFullPathName());
}

void ImGuiNodeEditorComponent::mergePresetFromFile(const juce::File& file, ImVec2 dropPosition)
{
    if (!file.existsAsFile() || synth == nullptr)
        return;

    auto xml = juce::XmlDocument::parse(file);
    if (xml == nullptr) return;

    juce::ValueTree preset = juce::ValueTree::fromXml(*xml);
    auto modulesVT = preset.getChildWithName("modules");
    auto connectionsVT = preset.getChildWithName("connections");
    auto uiVT = preset.getChildWithName("NodeEditorUI");

    if (!modulesVT.isValid()) return;

    pushSnapshot(); // Create an undo state before we start merging.

    // --- THIS IS THE NEW LOGIC ---
    // 1. Find the top-most Y coordinate of all existing nodes on the canvas.
    float topMostY = FLT_MAX;
    auto currentUiState = getUiValueTree();
    bool canvasHasNodes = false;
    for (int i = 0; i < currentUiState.getNumChildren(); ++i)
    {
        auto nodePosVT = currentUiState.getChild(i);
        if (nodePosVT.hasType("node"))
        {
            canvasHasNodes = true;
            float y = (float)nodePosVT.getProperty("y");
            if (y < topMostY)
            {
                topMostY = y;
            }
        }
    }
    // If the canvas is empty, use the drop position as the reference.
    if (!canvasHasNodes)
    {
        topMostY = dropPosition.y;
    }

    // 2. Find the bounding box of the nodes within the preset we are dropping.
    float presetMinX = FLT_MAX;
    float presetMaxY = -FLT_MAX;
    if (uiVT.isValid())
    {
        for (int i = 0; i < uiVT.getNumChildren(); ++i)
        {
            auto nodePosVT = uiVT.getChild(i);
            if (nodePosVT.hasType("node"))
            {
                float x = (float)nodePosVT.getProperty("x");
                float y = (float)nodePosVT.getProperty("y");
                if (x < presetMinX) presetMinX = x;
                if (y > presetMaxY) presetMaxY = y; // We need the lowest point (max Y) of the preset group.
            }
        }
    }
    
    // 3. Calculate the necessary offsets.
    const float verticalPadding = 100.0f;
    const float yOffset = topMostY - presetMaxY - verticalPadding;
    const float xOffset = dropPosition.x - presetMinX;
    // --- END OF NEW LOGIC ---

    // This map will track how we remap old IDs from the file to new, unique IDs on the canvas.
    std::map<juce::uint32, juce::uint32> oldIdToNewId;

    // First pass: create all the new modules from the preset.
    for (int i = 0; i < modulesVT.getNumChildren(); ++i)
    {
        auto moduleNode = modulesVT.getChild(i);
        if (moduleNode.hasType("module"))
        {
            juce::uint32 oldLogicalId = (juce::uint32)(int)moduleNode.getProperty("logicalId");
            juce::String type = moduleNode.getProperty("type").toString();
            
            // Add the module without committing the graph changes yet.
            auto newNodeId = synth->addModule(type, false);
            juce::uint32 newLogicalId = synth->getLogicalIdForNode(newNodeId);

            oldIdToNewId[oldLogicalId] = newLogicalId; // Store the mapping

            // Restore the new module's parameters and extra state.
            if (auto* proc = synth->getModuleForLogical(newLogicalId))
            {
                auto paramsWrapper = moduleNode.getChildWithName("params");
                if (paramsWrapper.isValid()) proc->getAPVTS().replaceState(paramsWrapper.getChild(0));
                
                auto extraWrapper = moduleNode.getChildWithName("extra");
                if (extraWrapper.isValid()) proc->setExtraStateTree(extraWrapper.getChild(0));
            }
        }
    }

    // Second pass: recreate the internal connections between the new modules.
    if (connectionsVT.isValid())
    {
        for (int i = 0; i < connectionsVT.getNumChildren(); ++i)
        {
            auto connNode = connectionsVT.getChild(i);
            if (connNode.hasType("connection"))
            {
                juce::uint32 oldSrcId = (juce::uint32)(int)connNode.getProperty("srcId");
                int srcChan = (int)connNode.getProperty("srcChan");
                juce::uint32 oldDstId = (juce::uint32)(int)connNode.getProperty("dstId");
                int dstChan = (int)connNode.getProperty("dstChan");

                // Only connect if both source and destination are part of the preset we're merging.
                if (oldIdToNewId.count(oldSrcId) && oldIdToNewId.count(oldDstId))
                {
                    auto newSrcNodeId = synth->getNodeIdForLogical(oldIdToNewId[oldSrcId]);
                    auto newDstNodeId = synth->getNodeIdForLogical(oldIdToNewId[oldDstId]);
                    synth->connect(newSrcNodeId, srcChan, newDstNodeId, dstChan);
                }
            }
        }
    }
    
    // Third pass: Apply UI positions using our new calculated offsets.
    if (uiVT.isValid())
    {
        for (int i = 0; i < uiVT.getNumChildren(); ++i)
        {
            auto nodePosVT = uiVT.getChild(i);
            if (nodePosVT.hasType("node"))
            {
                juce::uint32 oldId = (juce::uint32)(int)nodePosVT.getProperty("id");
                if (oldIdToNewId.count(oldId)) // Check if it's one of our new nodes
                {
                    ImVec2 pos = ImVec2((float)nodePosVT.getProperty("x"), (float)nodePosVT.getProperty("y"));
                    
                    // Apply the smart offsets
                    ImVec2 newPos = ImVec2(pos.x + xOffset, pos.y + yOffset);
                    
                    pendingNodeScreenPositions[(int)oldIdToNewId[oldId]] = newPos;
                }
            }
        }
    }

    // Finally, commit all the changes to the audio graph at once.
    synth->commitChanges();
    isPatchDirty = true; // Mark the patch as edited.
    
    juce::Logger::writeToLog("[Preset] Successfully merged preset: " + file.getFullPathName() + 
                             " above existing nodes with offsets (" + juce::String(xOffset) + ", " + juce::String(yOffset) + ")");
}




================================================================================
FILE: juce\\Source\\audio\\modules\\WebcamLoaderModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/videoio.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>

/**
 * Source node that captures from a webcam and publishes frames to VideoFrameManager.
 * Outputs its own logical ID as a CV signal for routing to processing nodes.
 */
class WebcamLoaderModule : public ModuleProcessor, private juce::Thread
{
public:
    WebcamLoaderModule();
    ~WebcamLoaderModule() override;

    const juce::String getName() const override { return "webcam_loader"; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }

    // For UI: get latest frame for preview
    juce::Image getLatestFrame();

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    
    // Override to specify custom node width. Height is calculated dynamically based on video aspect ratio.
    // Width changes based on zoom level (Small=240px, Normal=480px, Large=960px).
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;
    
    std::atomic<float>* cameraIndexParam = nullptr;
    // 0 = Small (240), 1 = Normal (480), 2 = Large (960)
    std::atomic<float>* zoomLevelParam = nullptr;
    
    cv::VideoCapture videoCapture;
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
    
    juce::StringArray availableCameraNames;
};



================================================================================
FILE: juce\\Source\\audio\\modules\\WebcamLoaderModule.cpp
================================================================================


#include "WebcamLoaderModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

juce::AudioProcessorValueTreeState::ParameterLayout WebcamLoaderModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    
    params.push_back(std::make_unique<juce::AudioParameterInt>("cameraIndex", "Camera Index", 0, 3, 0));
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    
    return { params.begin(), params.end() };
}

WebcamLoaderModule::WebcamLoaderModule()
    : ModuleProcessor(BusesProperties()
                     .withOutput("Output", juce::AudioChannelSet::mono(), true)),
      juce::Thread("Webcam Loader Thread"),
      apvts(*this, nullptr, "WebcamLoaderParams", createParameterLayout())
{
    cameraIndexParam = apvts.getRawParameterValue("cameraIndex");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    
    // Enumerate available cameras with resolution info
    for (int i = 0; i < 10; ++i) // Check first 10 camera indices
    {
        cv::VideoCapture tempCap(i);
        if (tempCap.isOpened())
        {
            int width = (int)tempCap.get(cv::CAP_PROP_FRAME_WIDTH);
            int height = (int)tempCap.get(cv::CAP_PROP_FRAME_HEIGHT);
            
            juce::String cameraName = "Camera " + juce::String(i);
            if (width > 0 && height > 0)
            {
                cameraName += " (" + juce::String(width) + "x" + juce::String(height) + ")";
            }
            
            availableCameraNames.add(cameraName);
            tempCap.release();
        }
    }
    
    if (availableCameraNames.isEmpty())
    {
        availableCameraNames.add("No cameras found");
    }
    
    juce::Logger::writeToLog("[WebcamLoader] Found " + juce::String(availableCameraNames.size()) + " camera(s)");
}

WebcamLoaderModule::~WebcamLoaderModule()
{
    stopThread(5000);
    VideoFrameManager::getInstance().removeSource(getLogicalId());
}

void WebcamLoaderModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    startThread(juce::Thread::Priority::normal);
}

void WebcamLoaderModule::releaseResources()
{
    signalThreadShouldExit();
}

void WebcamLoaderModule::run()
{
    int currentCameraIndex = -1;
    
    while (!threadShouldExit())
    {
        int requestedIndex = (int)cameraIndexParam->load();
        
        // If camera changed or is not open, try to open it
        if (requestedIndex != currentCameraIndex || !videoCapture.isOpened())
        {
            if (videoCapture.isOpened())
            {
                videoCapture.release();
            }
            
            if (videoCapture.open(requestedIndex))
            {
                currentCameraIndex = requestedIndex;
                juce::Logger::writeToLog("[WebcamLoader] Opened camera " + juce::String(requestedIndex));
            }
            else
            {
                wait(500);
                continue;
            }
        }
        
        cv::Mat frame;
        if (videoCapture.read(frame))
        {
            // Publish frame to central manager using this module's logical ID
            VideoFrameManager::getInstance().setFrame(getLogicalId(), frame);
            
            // Update local preview for UI
            updateGuiFrame(frame);
        }
        else
        {
            // Lost camera connection
            videoCapture.release();
            currentCameraIndex = -1;
        }
        
        wait(33); // ~30 FPS
    }
    
    videoCapture.release();
    VideoFrameManager::getInstance().removeSource(getLogicalId());
}

void WebcamLoaderModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgraFrame;
    cv::cvtColor(frame, bgraFrame, cv::COLOR_BGR2BGRA);
    
    const juce::ScopedLock lock(imageLock);
    
    if (latestFrameForGui.isNull() || 
        latestFrameForGui.getWidth() != bgraFrame.cols || 
        latestFrameForGui.getHeight() != bgraFrame.rows)
    {
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgraFrame.cols, bgraFrame.rows, true);
    }
    
    juce::Image::BitmapData destData(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(destData.data, bgraFrame.data, bgraFrame.total() * bgraFrame.elemSize());
}

juce::Image WebcamLoaderModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void WebcamLoaderModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    buffer.clear();
    
    // Output this module's logical ID on the "Source ID" pin
    if (buffer.getNumChannels() > 0)
    {
        float sourceId = (float)getLogicalId();
        for (int sample = 0; sample < buffer.getNumSamples(); ++sample)
        {
            buffer.setSample(0, sample, sourceId);
        }
    }
}

#if defined(PRESET_CREATOR_UI)
ImVec2 WebcamLoaderModule::getCustomNodeSize() const
{
    // Return different width based on zoom level (0=240,1=480,2=960)
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    const float widths[3] { 240.0f, 480.0f, 960.0f };
    return ImVec2(widths[level], 0.0f);
}

void WebcamLoaderModule::drawParametersInNode(float itemWidth,
                                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                              const std::function<void()>& onModificationEnded)
{
    ImGui::PushItemWidth(itemWidth);
    
    // Camera selection with real device names
    int currentIndex = (int)cameraIndexParam->load();
    currentIndex = juce::jlimit(0, juce::jmax(0, availableCameraNames.size() - 1), currentIndex);
    
    const char* currentCameraName = availableCameraNames[currentIndex].toRawUTF8();
    if (ImGui::BeginCombo("Camera", currentCameraName))
    {
        for (int i = 0; i < availableCameraNames.size(); ++i)
        {
            const bool isSelected = (currentIndex == i);
            if (ImGui::Selectable(availableCameraNames[i].toRawUTF8(), isSelected))
            {
                *dynamic_cast<juce::AudioParameterInt*>(apvts.getParameter("cameraIndex")) = i;
                onModificationEnded();
            }
            if (isSelected)
                ImGui::SetItemDefaultFocus();
        }
        ImGui::EndCombo();
    }
    
    ImGui::Separator();
    
    // Zoom buttons (+ to increase, - to decrease) across 3 levels
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    float buttonWidth = (itemWidth / 2.0f) - 4.0f;
    const bool atMin = (level <= 0);
    const bool atMax = (level >= 2);

    if (atMin) ImGui::BeginDisabled();
    if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmax(0, level - 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMin) ImGui::EndDisabled();

    ImGui::SameLine();

    if (atMax) ImGui::BeginDisabled();
    if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmin(2, level + 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMax) ImGui::EndDisabled();
    
    ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "Source ID: %d", (int)getLogicalId());
    
    ImGui::PopItemWidth();
}

void WebcamLoaderModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioOutputPin("Source ID", 0);
}
#endif



================================================================================
FILE: juce\\Source\\audio\\modules\\MovementDetectorModule.h
================================================================================


// juce/Source/audio/modules/MovementDetectorModule.h

#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/video.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>

// 1. Define the real-time safe struct for this module's results.
struct MovementResult
{
    float avgMotionX = 0.0f;     // Average horizontal motion (-1 to 1)
    float avgMotionY = 0.0f;     // Average vertical motion (-1 to 1)
    float motionAmount = 0.0f;   // Magnitude of motion or area of detected movement (0 to 1)
    bool motionTrigger = false;  // A one-shot trigger on significant motion
};

/**
 * Processing node that analyzes video from a source node via the VideoFrameManager.
 * Requires a "Source ID" input connection from a Webcam or Video File Loader.
 */
class MovementDetectorModule : public ModuleProcessor, private juce::Thread
{
public:
    MovementDetectorModule();
    ~MovementDetectorModule() override;

    const juce::String getName() const override { return "movement_detector"; }
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    
    // For UI: get latest annotated frame
    juce::Image getLatestFrame();

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    // Allow custom width (Small=240, Normal=480, Large=960)
    ImVec2 getCustomNodeSize() const override { 
        int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1; 
        level = juce::jlimit(0, 2, level); 
        const float widths[3] { 240.0f, 480.0f, 960.0f }; 
        return ImVec2(widths[level], 0.0f); 
    }
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    MovementResult analyzeFrame(const cv::Mat& inputFrame);
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();

    juce::AudioProcessorValueTreeState apvts;
    std::atomic<float>* modeParam = nullptr;
    std::atomic<float>* sensitivityParam = nullptr;
    // 0=Small,1=Normal,2=Large
    std::atomic<float>* zoomLevelParam = nullptr;

    // NEW: Algorithm-specific tuning parameters
    juce::AudioParameterInt* maxFeaturesParam = nullptr;
    juce::AudioParameterInt* pyramidLevelsParam = nullptr;
    juce::AudioParameterBool* noiseReductionParam = nullptr;

    // State for Optical Flow mode
    cv::Mat prevGrayFrame;
    std::vector<cv::Point2f> prevPoints;

    // State for Background Subtraction mode
    cv::Ptr<cv::BackgroundSubtractorMOG2> pBackSub;
    
    // State for trigger generation
    int triggerSamplesRemaining = 0;
    
    // Thread-safe data transfer from video thread to audio thread
    juce::AbstractFifo fifo { 16 };
    std::vector<MovementResult> fifoBuffer;
    MovementResult lastResultForAudio;
    
    // Current source ID (read from input pin)
    std::atomic<juce::uint32> currentSourceId { 0 };
    
    // GUI preview
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
};



================================================================================
FILE: juce\\Source\\audio\\modules\\MovementDetectorModule.cpp
================================================================================


#include "MovementDetectorModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>
#include <opencv2/video.hpp>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

juce::AudioProcessorValueTreeState::ParameterLayout MovementDetectorModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    params.push_back(std::make_unique<juce::AudioParameterChoice>("mode", "Mode", juce::StringArray{"Optical Flow", "Background Subtraction"}, 0));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("sensitivity", "Sensitivity", 0.01f, 1.0f, 0.1f));
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    // NEW: tuning parameters
    params.push_back(std::make_unique<juce::AudioParameterInt>("maxFeatures", "Max Features", 20, 500, 100));
    params.push_back(std::make_unique<juce::AudioParameterInt>("pyramidLevels", "Pyramid Levels", 1, 5, 3));
    params.push_back(std::make_unique<juce::AudioParameterBool>("noiseReduction", "Noise Reduction", false));
    return { params.begin(), params.end() };
}

MovementDetectorModule::MovementDetectorModule()
    : ModuleProcessor(BusesProperties()
                     .withInput("Input", juce::AudioChannelSet::mono(), true)
                     .withOutput("Output", juce::AudioChannelSet::discreteChannels(4), true)),
      juce::Thread("Movement Detector Analysis Thread"),
      apvts(*this, nullptr, "MovementParams", createParameterLayout())
{
    modeParam = apvts.getRawParameterValue("mode");
    sensitivityParam = apvts.getRawParameterValue("sensitivity");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    // NEW: init parameter pointers
    maxFeaturesParam = dynamic_cast<juce::AudioParameterInt*>(apvts.getParameter("maxFeatures"));
    pyramidLevelsParam = dynamic_cast<juce::AudioParameterInt*>(apvts.getParameter("pyramidLevels"));
    noiseReductionParam = dynamic_cast<juce::AudioParameterBool*>(apvts.getParameter("noiseReduction"));
    pBackSub = cv::createBackgroundSubtractorMOG2();
    
    fifoBuffer.resize(16);
    fifo.setTotalSize(16);
}

MovementDetectorModule::~MovementDetectorModule()
{
    stopThread(5000);
}

void MovementDetectorModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    startThread(juce::Thread::Priority::normal);
}

void MovementDetectorModule::releaseResources()
{
    signalThreadShouldExit();
}

void MovementDetectorModule::run()
{
    // Analysis loop runs on background thread
    while (!threadShouldExit())
    {
        juce::uint32 sourceId = currentSourceId.load();
        
        if (sourceId == 0)
        {
            // No source connected
            wait(100);
            continue;
        }
        
        // Get frame from VideoFrameManager
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(sourceId);
        
        if (!frame.empty())
        {
            // Perform analysis
            MovementResult result = analyzeFrame(frame);
            
            // Push result to FIFO for audio thread
            if (fifo.getFreeSpace() >= 1)
            {
                auto writeScope = fifo.write(1);
                if (writeScope.blockSize1 > 0)
                {
                    fifoBuffer[writeScope.startIndex1] = result;
                }
            }
        }
        
        wait(33); // ~30 FPS analysis rate
    }
}

MovementResult MovementDetectorModule::analyzeFrame(const cv::Mat& inputFrame)
{
    MovementResult result;
    cv::Mat gray, displayFrame;
    
    inputFrame.copyTo(displayFrame);
    cv::cvtColor(inputFrame, gray, cv::COLOR_BGR2GRAY);
    cv::resize(gray, gray, cv::Size(320, 240));
    cv::resize(displayFrame, displayFrame, cv::Size(320, 240));

    int mode = (int)modeParam->load();

    if (mode == 0) // Optical Flow
    {
        if (prevPoints.size() < 50)
        {
            int maxFeatures = maxFeaturesParam ? maxFeaturesParam->get() : 100;
            cv::goodFeaturesToTrack(gray, prevPoints, maxFeatures, 0.3, 7);
        }

        if (!prevGrayFrame.empty() && !prevPoints.empty())
        {
            std::vector<cv::Point2f> nextPoints;
            std::vector<uchar> status;
            int levels = pyramidLevelsParam ? pyramidLevelsParam->get() : 3;
            cv::calcOpticalFlowPyrLK(prevGrayFrame, gray, prevPoints, nextPoints, status, cv::noArray(),
                                     cv::Size(15, 15), levels);

            float sumX = 0.0f, sumY = 0.0f;
            int trackedCount = 0;
            for (size_t i = 0; i < prevPoints.size(); ++i)
            {
                if (status[i])
                {
                    cv::line(displayFrame, prevPoints[i], nextPoints[i], cv::Scalar(0, 255, 0), 1);
                    cv::circle(displayFrame, nextPoints[i], 2, cv::Scalar(255, 0, 0), -1);
                    
                    sumX += nextPoints[i].x - prevPoints[i].x;
                    sumY += nextPoints[i].y - prevPoints[i].y;
                    trackedCount++;
                }
            }

            if (trackedCount > 0)
            {
                result.avgMotionX = juce::jlimit(-1.0f, 1.0f, sumX / (trackedCount * 10.0f));
                result.avgMotionY = juce::jlimit(-1.0f, 1.0f, sumY / (trackedCount * 10.0f));
                result.motionAmount = juce::jlimit(0.0f, 1.0f, std::sqrt(result.avgMotionX * result.avgMotionX + result.avgMotionY * result.avgMotionY));
                
                if (result.motionAmount > sensitivityParam->load())
                {
                    result.motionTrigger = true;
                }
            }
            prevPoints = nextPoints;
        }
        gray.copyTo(prevGrayFrame);
    }
    else // Background Subtraction
    {
        cv::Mat fgMask;
        pBackSub->apply(gray, fgMask);
        if (noiseReductionParam && noiseReductionParam->get())
        {
            cv::erode(fgMask, fgMask, cv::Mat(), cv::Point(-1, -1), 1);
            cv::dilate(fgMask, fgMask, cv::Mat(), cv::Point(-1, -1), 2);
        }
        
        cv::Moments m = cv::moments(fgMask, true);
        result.motionAmount = juce::jlimit(0.0f, 1.0f, (float)(m.m00 / (320 * 240)));
        
        if (result.motionAmount > 0.001)
        {
             result.avgMotionX = juce::jmap((float)(m.m10 / m.m00), 0.0f, 320.0f, -1.0f, 1.0f);
             result.avgMotionY = juce::jmap((float)(m.m01 / m.m00), 0.0f, 240.0f, -1.0f, 1.0f);
             
             cv::Point2f centroid(m.m10 / m.m00, m.m01 / m.m00);
             cv::circle(displayFrame, centroid, 5, cv::Scalar(0, 255, 0), -1);
             cv::circle(displayFrame, centroid, 8, cv::Scalar(255, 255, 255), 2);
        }
        
        cv::Mat fgMaskColor;
        cv::cvtColor(fgMask, fgMaskColor, cv::COLOR_GRAY2BGR);
        cv::addWeighted(displayFrame, 0.7, fgMaskColor, 0.3, 0, displayFrame);
        
        if (result.motionAmount > sensitivityParam->load())
        {
            result.motionTrigger = true;
        }
    }

    updateGuiFrame(displayFrame);
    return result;
}

void MovementDetectorModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgraFrame;
    cv::cvtColor(frame, bgraFrame, cv::COLOR_BGR2BGRA);
    
    const juce::ScopedLock lock(imageLock);
    
    if (latestFrameForGui.isNull() || 
        latestFrameForGui.getWidth() != bgraFrame.cols || 
        latestFrameForGui.getHeight() != bgraFrame.rows)
    {
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgraFrame.cols, bgraFrame.rows, true);
    }
    
    juce::Image::BitmapData destData(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(destData.data, bgraFrame.data, bgraFrame.total() * bgraFrame.elemSize());
}

juce::Image MovementDetectorModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void MovementDetectorModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    // Read Source ID from input pin
    auto inputBuffer = getBusBuffer(buffer, true, 0);
    if (inputBuffer.getNumChannels() > 0 && inputBuffer.getNumSamples() > 0)
    {
        float sourceIdFloat = inputBuffer.getSample(0, 0);
        currentSourceId.store((juce::uint32)sourceIdFloat);
    }
    
    // Get latest result from analysis thread via FIFO
    if (fifo.getNumReady() > 0)
    {
        auto readScope = fifo.read(1);
        if (readScope.blockSize1 > 0)
        {
            lastResultForAudio = fifoBuffer[readScope.startIndex1];
        }
    }
    
    // Write results to output channels
    auto outputBuffer = getBusBuffer(buffer, false, 0);
    if (outputBuffer.getNumChannels() < 4) return;
    
    outputBuffer.setSample(0, 0, lastResultForAudio.avgMotionX);
    outputBuffer.setSample(1, 0, lastResultForAudio.avgMotionY);
    outputBuffer.setSample(2, 0, lastResultForAudio.motionAmount);

    // Handle trigger
    if (lastResultForAudio.motionTrigger)
    {
        triggerSamplesRemaining = (int)(getSampleRate() * 0.01);
        lastResultForAudio.motionTrigger = false; // Clear to avoid repeating
    }

    if (triggerSamplesRemaining > 0)
    {
        outputBuffer.setSample(3, 0, 1.0f);
        triggerSamplesRemaining--;
    }
    else
    {
        outputBuffer.setSample(3, 0, 0.0f);
    }
    
    // Fill rest of buffer
    for (int channel = 0; channel < 4; ++channel)
    {
        outputBuffer.copyFrom(channel, 1, outputBuffer, channel, 0, outputBuffer.getNumSamples() - 1);
    }
}

#if defined(PRESET_CREATOR_UI)
void MovementDetectorModule::drawParametersInNode(float itemWidth,
                                                  const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                                  const std::function<void()>& onModificationEnded)
{
    ImGui::PushItemWidth(itemWidth);
    
    // Mode selection
    int mode = (int)modeParam->load();
    const char* modes[] = { "Optical Flow", "Background Subtraction" };
    if (ImGui::Combo("Mode", &mode, modes, 2))
    {
        *dynamic_cast<juce::AudioParameterChoice*>(apvts.getParameter("mode")) = mode;
        onModificationEnded();
    }
    
    // Sensitivity slider
    float sensitivity = sensitivityParam->load();
    if (ImGui::SliderFloat("Sensitivity", &sensitivity, 0.01f, 1.0f, "%.2f"))
    {
        *dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("sensitivity")) = sensitivity;
    }
    if (ImGui::IsItemDeactivatedAfterEdit())
    {
        onModificationEnded();
    }
    
    ImGui::Separator();
    // Zoom controls (-/+) Small/Normal/Large
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    float buttonWidth = (itemWidth / 2.0f) - 4.0f;
    const bool atMin = (level <= 0);
    const bool atMax = (level >= 2);
    if (atMin) ImGui::BeginDisabled();
    if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmax(0, level - 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMin) ImGui::EndDisabled();
    ImGui::SameLine();
    if (atMax) ImGui::BeginDisabled();
    if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmin(2, level + 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMax) ImGui::EndDisabled();

    // NEW: Algorithm tuning controls
    ImGui::Separator();
    if (mode == 0) // Optical Flow
    {
        ImGui::Text("Optical Flow Settings");
        if (maxFeaturesParam)
        {
            int maxF = maxFeaturesParam->get();
            if (ImGui::SliderInt("Max Features", &maxF, 20, 500)) { *maxFeaturesParam = maxF; }
            if (ImGui::IsItemDeactivatedAfterEdit()) onModificationEnded();
        }
        if (pyramidLevelsParam)
        {
            int lv = pyramidLevelsParam->get();
            if (ImGui::SliderInt("Pyramid Levels", &lv, 1, 5)) { *pyramidLevelsParam = lv; }
            if (ImGui::IsItemDeactivatedAfterEdit()) onModificationEnded();
        }
    }
    else
    {
        ImGui::Text("Background Subtraction Settings");
        if (noiseReductionParam)
        {
            bool nr = noiseReductionParam->get();
            if (ImGui::Checkbox("Noise Reduction", &nr)) { *noiseReductionParam = nr; onModificationEnded(); }
        }
    }

    // Show current source ID
    juce::uint32 sourceId = currentSourceId.load();
    if (sourceId > 0)
    {
        ImGui::TextColored(ImVec4(0.5f, 1.0f, 0.5f, 1.0f), "Connected to Source: %d", (int)sourceId);
    }
    else
    {
        ImGui::TextColored(ImVec4(1.0f, 0.5f, 0.5f, 1.0f), "No source connected");
    }
    
    ImGui::PopItemWidth();
}

void MovementDetectorModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioInputPin("Source In", 0);
    helpers.drawAudioOutputPin("Motion X", 0);
    helpers.drawAudioOutputPin("Motion Y", 1);
    helpers.drawAudioOutputPin("Amount", 2);
    helpers.drawAudioOutputPin("Trigger", 3);
}
#endif


================================================================================
FILE: juce\\Source\\audio\\modules\\HumanDetectorModule.h
================================================================================


// juce/Source/audio/modules/HumanDetectorModule.h

#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/objdetect.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>

// We can reuse the same POD struct as it fits our needs perfectly.
struct DetectionResult
{
    static constexpr int maxDetections = 1; // This module only outputs the largest detection
    int numDetections = 0;
    float x[maxDetections] = {0};
    float y[maxDetections] = {0};
    float width[maxDetections] = {0};
    float height[maxDetections] = {0};
};

/**
 * Processing node that detects humans from a video source via the VideoFrameManager.
 * Requires a "Source ID" input connection from a Webcam or Video File Loader.
 */
class HumanDetectorModule : public ModuleProcessor, private juce::Thread
{
public:
    HumanDetectorModule();
    ~HumanDetectorModule() override;

    const juce::String getName() const override { return "human_detector"; }
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    
    // For UI: get latest annotated frame
    juce::Image getLatestFrame();

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    // Allow custom width (Small=240, Normal=480, Large=960)
    ImVec2 getCustomNodeSize() const override {
        int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
        level = juce::jlimit(0, 2, level);
        const float widths[3] { 240.0f, 480.0f, 960.0f };
        return ImVec2(widths[level], 0.0f);
    }
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    DetectionResult analyzeFrame(const cv::Mat& inputFrame);
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();

    juce::AudioProcessorValueTreeState apvts;
    std::atomic<float>* modeParam = nullptr;
    std::atomic<float>* scaleFactorParam = nullptr;
    std::atomic<float>* minNeighborsParam = nullptr;
    // 0=Small,1=Normal,2=Large
    std::atomic<float>* zoomLevelParam = nullptr;

    // OpenCV objects for detection
    cv::CascadeClassifier faceCascade;
    cv::HOGDescriptor hog;
    
    // State for trigger generation
    int gateSamplesRemaining = 0;
    
    // Thread-safe data transfer from video thread to audio thread
    juce::AbstractFifo fifo { 16 };
    std::vector<DetectionResult> fifoBuffer;
    DetectionResult lastResultForAudio;
    
    // Current source ID (read from input pin)
    std::atomic<juce::uint32> currentSourceId { 0 };
    
    // GUI preview
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
};



================================================================================
FILE: juce\\Source\\audio\\modules\\HumanDetectorModule.cpp
================================================================================


#include "HumanDetectorModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>
#include <opencv2/objdetect.hpp>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

juce::AudioProcessorValueTreeState::ParameterLayout HumanDetectorModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    params.push_back(std::make_unique<juce::AudioParameterChoice>("mode", "Detection Mode", juce::StringArray{"Faces (Haar)", "Bodies (HOG)"}, 0));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("scaleFactor", "Scale Factor", 1.05f, 2.0f, 1.1f));
    params.push_back(std::make_unique<juce::AudioParameterInt>("minNeighbors", "Min Neighbors", 1, 10, 3));
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    return { params.begin(), params.end() };
}

HumanDetectorModule::HumanDetectorModule()
    : ModuleProcessor(BusesProperties()
                     .withInput("Input", juce::AudioChannelSet::mono(), true)
                     .withOutput("Output", juce::AudioChannelSet::discreteChannels(5), true)),
      juce::Thread("Human Detector Analysis Thread"),
      apvts(*this, nullptr, "HumanParams", createParameterLayout())
{
    modeParam = apvts.getRawParameterValue("mode");
    scaleFactorParam = apvts.getRawParameterValue("scaleFactor");
    minNeighborsParam = apvts.getRawParameterValue("minNeighbors");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");

    // Load Haar Cascade
    juce::File cascadeFile = juce::File::getSpecialLocation(juce::File::currentApplicationFile)
                                .getSiblingFile("haarcascade_frontalface_default.xml");
    if (cascadeFile.existsAsFile())
    {
        faceCascade.load(cascadeFile.getFullPathName().toStdString());
    }
    else
    {
        juce::Logger::writeToLog("ERROR: haarcascade_frontalface_default.xml not found!");
    }
    
    // Set up HOG detector
    hog.setSVMDetector(cv::HOGDescriptor::getDefaultPeopleDetector());
    
    fifoBuffer.resize(16);
    fifo.setTotalSize(16);
}

HumanDetectorModule::~HumanDetectorModule()
{
    stopThread(5000);
}

void HumanDetectorModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    startThread(juce::Thread::Priority::normal);
}

void HumanDetectorModule::releaseResources()
{
    signalThreadShouldExit();
}

void HumanDetectorModule::run()
{
    // Analysis loop runs on background thread
    while (!threadShouldExit())
    {
        juce::uint32 sourceId = currentSourceId.load();
        
        if (sourceId == 0)
        {
            // No source connected
            wait(100);
            continue;
        }
        
        // Get frame from VideoFrameManager
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(sourceId);
        
        if (!frame.empty())
        {
            // Perform analysis
            DetectionResult result = analyzeFrame(frame);
            
            // Push result to FIFO for audio thread
            if (fifo.getFreeSpace() >= 1)
            {
                auto writeScope = fifo.write(1);
                if (writeScope.blockSize1 > 0)
                {
                    fifoBuffer[writeScope.startIndex1] = result;
                }
            }
        }
        
        wait(33); // ~30 FPS analysis rate
    }
}

DetectionResult HumanDetectorModule::analyzeFrame(const cv::Mat& inputFrame)
{
    DetectionResult result;
    cv::Mat gray, displayFrame;
    
    inputFrame.copyTo(displayFrame);
    cv::cvtColor(inputFrame, gray, cv::COLOR_BGR2GRAY);
    cv::resize(gray, gray, cv::Size(320, 240));
    cv::resize(displayFrame, displayFrame, cv::Size(320, 240));

    std::vector<cv::Rect> detections;
    int mode = (int)modeParam->load();

    if (mode == 0) // Face Detection
    {
        faceCascade.detectMultiScale(gray, detections, scaleFactorParam->load(), (int)minNeighborsParam->load());
    }
    else // Body Detection
    {
        hog.detectMultiScale(gray, detections);
    }

    // Draw all detections (smaller ones in gray)
    for (const auto& detection : detections)
    {
        cv::rectangle(displayFrame, detection, cv::Scalar(128, 128, 128), 1);
    }

    if (!detections.empty())
    {
        // Find the largest detection
        auto largest = std::max_element(detections.begin(), detections.end(), 
            [](const cv::Rect& a, const cv::Rect& b) {
                return a.area() < b.area();
            });

        // Draw the largest detection
        cv::rectangle(displayFrame, *largest, cv::Scalar(0, 255, 0), 2);
        
        std::string label = (mode == 0) ? "Face" : "Person";
        cv::putText(displayFrame, label, cv::Point(largest->x, largest->y - 5),
                    cv::FONT_HERSHEY_SIMPLEX, 0.4, cv::Scalar(0, 255, 0), 1);

        result.numDetections = 1;
        result.x[0] = juce::jmap((float)largest->x, 0.0f, 320.0f, 0.0f, 1.0f);
        result.y[0] = juce::jmap((float)largest->y, 0.0f, 240.0f, 0.0f, 1.0f);
        result.width[0] = juce::jmap((float)largest->width, 0.0f, 320.0f, 0.0f, 1.0f);
        result.height[0] = juce::jmap((float)largest->height, 0.0f, 240.0f, 0.0f, 1.0f);
    }

    updateGuiFrame(displayFrame);
    return result;
}

void HumanDetectorModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgraFrame;
    cv::cvtColor(frame, bgraFrame, cv::COLOR_BGR2BGRA);
    
    const juce::ScopedLock lock(imageLock);
    
    if (latestFrameForGui.isNull() || 
        latestFrameForGui.getWidth() != bgraFrame.cols || 
        latestFrameForGui.getHeight() != bgraFrame.rows)
    {
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgraFrame.cols, bgraFrame.rows, true);
    }
    
    juce::Image::BitmapData destData(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(destData.data, bgraFrame.data, bgraFrame.total() * bgraFrame.elemSize());
}

juce::Image HumanDetectorModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void HumanDetectorModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    // Read Source ID from input pin
    auto inputBuffer = getBusBuffer(buffer, true, 0);
    if (inputBuffer.getNumChannels() > 0 && inputBuffer.getNumSamples() > 0)
    {
        float sourceIdFloat = inputBuffer.getSample(0, 0);
        currentSourceId.store((juce::uint32)sourceIdFloat);
    }
    
    // Get latest result from analysis thread via FIFO
    if (fifo.getNumReady() > 0)
    {
        auto readScope = fifo.read(1);
        if (readScope.blockSize1 > 0)
        {
            lastResultForAudio = fifoBuffer[readScope.startIndex1];
        }
    }
    
    // Write results to output channels
    auto outputBuffer = getBusBuffer(buffer, false, 0);
    if (outputBuffer.getNumChannels() < 5) return;
    
    if (lastResultForAudio.numDetections > 0)
    {
        outputBuffer.setSample(0, 0, lastResultForAudio.x[0]);
        outputBuffer.setSample(1, 0, lastResultForAudio.y[0]);
        outputBuffer.setSample(2, 0, lastResultForAudio.width[0]);
        outputBuffer.setSample(3, 0, lastResultForAudio.height[0]);
        gateSamplesRemaining = 2; // Keep gate high
    }

    if (gateSamplesRemaining > 0)
    {
        outputBuffer.setSample(4, 0, 1.0f);
        gateSamplesRemaining--;
    }
    else
    {
        outputBuffer.setSample(4, 0, 0.0f);
    }
    
    // Fill rest of buffer
    for (int channel = 0; channel < 5; ++channel)
    {
        outputBuffer.copyFrom(channel, 1, outputBuffer, channel, 0, outputBuffer.getNumSamples() - 1);
    }
}

#if defined(PRESET_CREATOR_UI)
void HumanDetectorModule::drawParametersInNode(float itemWidth,
                                               const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                               const std::function<void()>& onModificationEnded)
{
    ImGui::PushItemWidth(itemWidth);
    
    // Mode selection
    int mode = (int)modeParam->load();
    const char* modes[] = { "Faces (Haar)", "Bodies (HOG)" };
    if (ImGui::Combo("Mode", &mode, modes, 2))
    {
        *dynamic_cast<juce::AudioParameterChoice*>(apvts.getParameter("mode")) = mode;
        onModificationEnded();
    }
    
    // Conditional parameters for Haar mode
    if (mode == 0)
    {
        float scaleFactor = scaleFactorParam->load();
        if (ImGui::SliderFloat("Scale Factor", &scaleFactor, 1.05f, 2.0f, "%.2f"))
        {
            *dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("scaleFactor")) = scaleFactor;
        }
        if (ImGui::IsItemDeactivatedAfterEdit())
        {
            onModificationEnded();
        }
        
        int minNeighbors = (int)minNeighborsParam->load();
        if (ImGui::SliderInt("Min Neighbors", &minNeighbors, 1, 10))
        {
            *dynamic_cast<juce::AudioParameterInt*>(apvts.getParameter("minNeighbors")) = minNeighbors;
        }
        if (ImGui::IsItemDeactivatedAfterEdit())
        {
            onModificationEnded();
        }
    }
    
    ImGui::Separator();
    // Zoom controls (-/+) Small/Normal/Large
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    float buttonWidth = (itemWidth / 2.0f) - 4.0f;
    const bool atMin = (level <= 0);
    const bool atMax = (level >= 2);
    if (atMin) ImGui::BeginDisabled();
    if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmax(0, level - 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMin) ImGui::EndDisabled();
    ImGui::SameLine();
    if (atMax) ImGui::BeginDisabled();
    if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmin(2, level + 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMax) ImGui::EndDisabled();
    
    // Show current source ID
    juce::uint32 sourceId = currentSourceId.load();
    if (sourceId > 0)
    {
        ImGui::TextColored(ImVec4(0.5f, 1.0f, 0.5f, 1.0f), "Connected to Source: %d", (int)sourceId);
    }
    else
    {
        ImGui::TextColored(ImVec4(1.0f, 0.5f, 0.5f, 1.0f), "No source connected");
    }
    
    ImGui::PopItemWidth();
}

void HumanDetectorModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioInputPin("Source In", 0);
    helpers.drawAudioOutputPin("X", 0);
    helpers.drawAudioOutputPin("Y", 1);
    helpers.drawAudioOutputPin("Width", 2);
    helpers.drawAudioOutputPin("Height", 3);
    helpers.drawAudioOutputPin("Gate", 4);
}
#endif


================================================================================
FILE: juce\\Source\\audio\\modules\\PoseEstimatorModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/dnn.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>
#if defined(PRESET_CREATOR_UI)
#include <juce_gui_basics/juce_gui_basics.h>
#endif

// The MPI model detects 15 keypoints per person
constexpr int MPI_NUM_KEYPOINTS = 15;

/**
 * A real-time safe struct to hold the (x, y) coordinates of each keypoint.
 * Used to pass pose data from the processing thread to the audio thread via a lock-free FIFO.
 */
struct PoseResult
{
    float keypoints[MPI_NUM_KEYPOINTS][2] = {{0}}; // [point_index][x or y]
    int detectedPoints = 0;
    bool isValid = false;
};

/**
 * Pose Estimator Module
 * Uses OpenPose MPI model to detect human body keypoints in real-time video.
 * Connects to a video source (webcam or video file) and outputs 30 CV signals
 * (x,y coordinates for 15 body keypoints: head, shoulders, elbows, wrists, hips, knees, ankles, etc.)
 */
class PoseEstimatorModule : public ModuleProcessor, private juce::Thread
{
public:
    PoseEstimatorModule();
    ~PoseEstimatorModule() override;

    const juce::String getName() const override { return "pose_estimator"; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }

    // Persist extra state (e.g., assets path)
    juce::ValueTree getExtraStateTree() const override;
    void setExtraStateTree(const juce::ValueTree& state) override;

    // For UI: get latest frame with skeleton overlay for preview
    juce::Image getLatestFrame();

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    
    // Override to specify custom node width based on zoom level (Small/Normal/Large)
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override; // Thread entry point - processes video frames
    void updateGuiFrame(const cv::Mat& frame);
    void parsePoseOutput(const cv::Mat& netOutput, int frameWidth, int frameHeight, PoseResult& result);
        void loadModel(int modelIndex);
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;
    
        // Parameters
    std::atomic<float>* sourceIdParam = nullptr;
        // 0 = Small (240), 1 = Normal (480), 2 = Large (960)
    std::atomic<float>* zoomLevelParam = nullptr;
    std::atomic<float>* confidenceThresholdParam = nullptr;
    juce::AudioParameterBool* drawSkeletonParam = nullptr;
    // Store custom assets directory as plain string (saved via extra state)
    juce::String assetsPath;
#if defined(PRESET_CREATOR_UI)
    std::unique_ptr<juce::FileChooser> pathChooser;
#endif
        juce::AudioParameterChoice* modelChoiceParam = nullptr;
    
    // Deep Neural Network for pose estimation
    cv::dnn::Net net;
    bool modelLoaded = false;
    juce::AudioParameterChoice* qualityParam = nullptr;
        
        // Signal for the background thread to reload the model
        std::atomic<int> requestedModelIndex { -1 };
    
    // Source ID (read from input cable in audio thread, used by processing thread)
    std::atomic<juce::uint32> currentSourceId { 0 };
    
    // Lock-free FIFO for passing results from processing thread to audio thread
    PoseResult lastResultForAudio;
    juce::AbstractFifo fifo { 16 };
    std::vector<PoseResult> fifoBuffer;
    
    // UI preview
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
};

// Keypoint names for the MPI model (for UI labels and debugging)
const std::vector<std::string> MPI_KEYPOINT_NAMES = {
    "Head", "Neck", "R Shoulder", "R Elbow", "R Wrist",
    "L Shoulder", "L Elbow", "L Wrist", "R Hip", "R Knee",
    "R Ankle", "L Hip", "L Knee", "L Ankle", "Chest"
};

// Skeleton connections (pairs of keypoint indices to draw as lines)
const std::vector<std::pair<int, int>> MPI_SKELETON_PAIRS = {
    {0, 1},   // Head -> Neck
    {1, 14},  // Neck -> Chest
    {1, 2},   // Neck -> R Shoulder
    {2, 3},   // R Shoulder -> R Elbow
    {3, 4},   // R Elbow -> R Wrist
    {1, 5},   // Neck -> L Shoulder
    {5, 6},   // L Shoulder -> L Elbow
    {6, 7},   // L Elbow -> L Wrist
    {14, 8},  // Chest -> R Hip
    {8, 9},   // R Hip -> R Knee
    {9, 10},  // R Knee -> R Ankle
    {14, 11}, // Chest -> L Hip
    {11, 12}, // L Hip -> L Knee
    {12, 13}  // L Knee -> L Ankle
};



================================================================================
FILE: juce\\Source\\audio\\modules\\PoseEstimatorModule.cpp
================================================================================


#include "PoseEstimatorModule.h"
#include "../../video/VideoFrameManager.h"
#include "../graph/ModularSynthProcessor.h"
#include <opencv2/imgproc.hpp>
#include <opencv2/dnn.hpp>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

void PoseEstimatorModule::loadModel(int modelIndex)
{
    // --- THIS IS THE CORRECTED PATH LOGIC ---
    // 1. Get the directory containing the running executable.
    auto exeFile = juce::File::getSpecialLocation(juce::File::currentApplicationFile);
    auto appDir = exeFile.getParentDirectory();
    juce::Logger::writeToLog("[PoseEstimator] Executable directory: " + appDir.getFullPathName());

    // 2. Look for the 'assets' folder next to the executable (fixed path as requested).
    juce::File assetsDir = appDir.getChildFile("assets");
    juce::Logger::writeToLog("[PoseEstimator] Searching for assets in: " + assetsDir.getFullPathName());
    
    // 3. Navigate to the specific model subdirectory.
    auto poseModelsDir = assetsDir.getChildFile("openpose_models").getChildFile("pose");

    juce::String protoPath, modelPath;
    juce::String modelName;

    switch (modelIndex)
    {
        case 0: // BODY_25
            modelName = "BODY_25";
            protoPath = poseModelsDir.getChildFile("body_25/pose_deploy.prototxt").getFullPathName();
            modelPath = poseModelsDir.getChildFile("body_25/pose_iter_584000.caffemodel").getFullPathName();
            break;
        case 1: // COCO
            modelName = "COCO";
            protoPath = poseModelsDir.getChildFile("coco/pose_deploy_linevec.prototxt").getFullPathName();
            modelPath = poseModelsDir.getChildFile("coco/pose_iter_440000.caffemodel").getFullPathName();
            break;
        case 2: // MPI
            modelName = "MPI";
            protoPath = poseModelsDir.getChildFile("mpi/pose_deploy_linevec.prototxt").getFullPathName();
            modelPath = poseModelsDir.getChildFile("mpi/pose_iter_160000.caffemodel").getFullPathName();
            break;
        case 3: // MPI (Fast)
        default:
            modelName = "MPI (Fast)";
            protoPath = poseModelsDir.getChildFile("mpi/pose_deploy_linevec_faster_4_stages.prototxt").getFullPathName();
            modelPath = poseModelsDir.getChildFile("mpi/pose_iter_160000.caffemodel").getFullPathName();
            break;
    }

    juce::Logger::writeToLog("[PoseEstimator] Attempting to load " + modelName + " model...");
    juce::Logger::writeToLog("  - Prototxt: " + protoPath);
    juce::Logger::writeToLog("  - Caffemodel: " + modelPath);
    
    juce::File protoFile(protoPath);
    juce::File modelFile(modelPath);

    if (protoFile.existsAsFile() && modelFile.existsAsFile()) {
        try {
            net = cv::dnn::readNetFromCaffe(protoPath.toStdString(), modelPath.toStdString());
            modelLoaded = true;
            juce::Logger::writeToLog("[PoseEstimator] SUCCESS: Loaded model: " + modelName);
        } catch (const cv::Exception& e) {
            juce::Logger::writeToLog("[PoseEstimator] FAILED: OpenCV exception while loading model: " + juce::String(e.what()));
            modelLoaded = false;
        }
    } else {
        juce::Logger::writeToLog("[PoseEstimator] FAILED: Could not find model files at the specified paths.");
        if (!protoFile.existsAsFile()) juce::Logger::writeToLog("  - Missing file: " + protoPath);
        if (!modelFile.existsAsFile()) juce::Logger::writeToLog("  - Missing file: " + modelPath);
        modelLoaded = false;
    }
}

juce::ValueTree PoseEstimatorModule::getExtraStateTree() const
{
    juce::ValueTree state("PoseEstimatorState");
    state.setProperty("assetsPath", assetsPath, nullptr);
    return state;
}

void PoseEstimatorModule::setExtraStateTree(const juce::ValueTree& state)
{
    if (state.hasType("PoseEstimatorState"))
    {
        assetsPath = state.getProperty("assetsPath", "").toString();
        if (assetsPath.isNotEmpty())
        {
            requestedModelIndex = modelChoiceParam ? modelChoiceParam->getIndex() : 3;
        }
    }
}

// Network input size for MPI model
constexpr int POSE_NET_WIDTH = 368;
constexpr int POSE_NET_HEIGHT = 368;

juce::AudioProcessorValueTreeState::ParameterLayout PoseEstimatorModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    
    // Source ID input (which video source to connect to)
    params.push_back(std::make_unique<juce::AudioParameterFloat>(
        "sourceId", "Source ID", 0.0f, 1000.0f, 0.0f));
    
    // Model choice (BODY_25, COCO, MPI, MPI Fast)
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "model", "Model", juce::StringArray{ "BODY_25", "COCO", "MPI", "MPI (Fast)" }, 3));

    // Model quality (affects blob size)
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "quality", "Quality", juce::StringArray{ "Low (Fast)", "Medium (Default)" }, 1));
    
    // Note: assets path is stored via extra state, not as a parameter
    
    // Zoom level for UI: 0=Small(240),1=Normal(480),2=Large(960)
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    
    // Confidence threshold (0.0 - 1.0) - keypoints below this confidence will be ignored
    params.push_back(std::make_unique<juce::AudioParameterFloat>(
        "confidence", "Confidence", 0.0f, 1.0f, 0.1f));
    
    // Toggle skeleton drawing on preview
    params.push_back(std::make_unique<juce::AudioParameterBool>(
        "drawSkeleton", "Draw Skeleton", true));
    
    return { params.begin(), params.end() };
}

PoseEstimatorModule::PoseEstimatorModule()
    : ModuleProcessor(BusesProperties()
                     .withInput("Input", juce::AudioChannelSet::mono(), true)
                     .withOutput("Output", juce::AudioChannelSet::discreteChannels(30), true)), // 15 keypoints x 2 (x,y)
      juce::Thread("Pose Estimator Thread"),
      apvts(*this, nullptr, "PoseEstimatorParams", createParameterLayout())
{
    // Get parameter pointers
    sourceIdParam = apvts.getRawParameterValue("sourceId");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    qualityParam = dynamic_cast<juce::AudioParameterChoice*>(apvts.getParameter("quality"));
    modelChoiceParam = dynamic_cast<juce::AudioParameterChoice*>(apvts.getParameter("model"));
    confidenceThresholdParam = apvts.getRawParameterValue("confidence");
    drawSkeletonParam = dynamic_cast<juce::AudioParameterBool*>(apvts.getParameter("drawSkeleton"));
    
    // Initialize FIFO buffer
    fifoBuffer.resize(16);
    
    // Defer initial model load to the thread (default to current selection or MPI Fast)
    requestedModelIndex = modelChoiceParam ? modelChoiceParam->getIndex() : 3;
}

PoseEstimatorModule::~PoseEstimatorModule()
{
    stopThread(5000);
}

void PoseEstimatorModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    // Always start the processing thread; it handles model loading on demand.
    startThread(juce::Thread::Priority::normal);
}

void PoseEstimatorModule::releaseResources()
{
    signalThreadShouldExit();
    stopThread(5000);
}

void PoseEstimatorModule::run()
{
    juce::Logger::writeToLog("[PoseEstimator] Processing thread started");
    
    while (!threadShouldExit())
    {
        // Handle deferred model reload requests from UI
        int toLoad = requestedModelIndex.exchange(-1);
        if (toLoad != -1)
        {
            loadModel(toLoad);
        }
        
        if (!modelLoaded)
        {
            wait(200);
            continue;
        }

        // Get the source ID from the input cable (set by processBlock from the audio thread)
        juce::uint32 sourceId = currentSourceId.load();
        
        // Fetch frame from the VideoFrameManager
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(sourceId);
        
        if (!frame.empty())
        {
            // 1. Prepare image for the network (resize and normalize)
            // Blob size based on Quality setting (Low=224, Medium=368)
            int q = qualityParam ? qualityParam->getIndex() : 1;
            cv::Size blobSize = (q == 0) ? cv::Size(224, 224) : cv::Size(368, 368);
            cv::Mat inputBlob = cv::dnn::blobFromImage(
                frame,
                1.0 / 255.0,
                blobSize,
                cv::Scalar(0, 0, 0),
                false,
                false);

            // 2. Run the forward pass through the neural network
            net.setInput(inputBlob);
            cv::Mat netOutput = net.forward();
            
            // 3. Parse the output to extract keypoint coordinates
            PoseResult result;
            parsePoseOutput(netOutput, frame.cols, frame.rows, result);
            
            // Apply confidence threshold
            result.isValid = (result.detectedPoints > 5); // Need at least 5 keypoints for valid pose
            
            // 4. Push result to the audio thread via lock-free FIFO (UPDATED API)
            if (fifo.getFreeSpace() >= 1)
            {
                auto writeScope = fifo.write(1);
                if (writeScope.blockSize1 > 0)
                {
                    fifoBuffer[writeScope.startIndex1] = result;
                }
            }
            
            // 5. Draw the skeleton on the frame for UI preview (if enabled)
            if (drawSkeletonParam->get())
            {
                // Draw skeleton lines
                for (const auto& pair : MPI_SKELETON_PAIRS)
                {
                    int idxA = pair.first;
                    int idxB = pair.second;
                    
                    if (result.keypoints[idxA][0] >= 0 && result.keypoints[idxB][0] >= 0)
                    {
                        cv::Point ptA((int)result.keypoints[idxA][0], (int)result.keypoints[idxA][1]);
                        cv::Point ptB((int)result.keypoints[idxB][0], (int)result.keypoints[idxB][1]);
                        cv::line(frame, ptA, ptB, cv::Scalar(0, 255, 0), 3);
                    }
                }
                
                // Draw keypoint circles
                for (int i = 0; i < MPI_NUM_KEYPOINTS; ++i)
                {
                    if (result.keypoints[i][0] >= 0)
                    {
                        cv::Point pt((int)result.keypoints[i][0], (int)result.keypoints[i][1]);
                        cv::circle(frame, pt, 5, cv::Scalar(0, 0, 255), -1);
                    }
                }
            }
            
            // 6. Update the GUI preview frame
            updateGuiFrame(frame);
        }
        
        // Run at ~15 FPS (pose estimation is computationally expensive)
        wait(66);
    }
    
    juce::Logger::writeToLog("[PoseEstimator] Processing thread stopped");
}

void PoseEstimatorModule::parsePoseOutput(const cv::Mat& netOutput, int frameWidth, int frameHeight, PoseResult& result)
{
    // OpenPose output format: [1, num_keypoints, height, width]
    // Each heatmap represents the probability of a keypoint at each location
    
    int H = netOutput.size[2]; // Heatmap height
    int W = netOutput.size[3]; // Heatmap width
    
    result.detectedPoints = 0;
    float confidenceThreshold = confidenceThresholdParam->load();
    
    int numHeatmaps = netOutput.size[1];
    int count = juce::jmin(MPI_NUM_KEYPOINTS, numHeatmaps);
    for (int i = 0; i < count; ++i)
    {
        // CORRECTED: Create a Mat view from the 4D blob for OpenCV 4.x
        cv::Mat heatMap(H, W, CV_32F, (void*)netOutput.ptr<float>(0, i));
        
        // Find the location of maximum confidence
        double maxConfidence;
        cv::Point maxLoc;
        cv::minMaxLoc(heatMap, nullptr, &maxConfidence, nullptr, &maxLoc);
        
        if (maxConfidence > confidenceThreshold)
        {
            // Scale the heatmap coordinates back to the original frame size
            result.keypoints[i][0] = (float)maxLoc.x * frameWidth / W;
            result.keypoints[i][1] = (float)maxLoc.y * frameHeight / H;
            result.detectedPoints++;
        }
        else
        {
            // Mark as not detected
            result.keypoints[i][0] = -1.0f;
            result.keypoints[i][1] = -1.0f;
        }
    }
}

void PoseEstimatorModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgraFrame;
    cv::cvtColor(frame, bgraFrame, cv::COLOR_BGR2BGRA);
    
    const juce::ScopedLock lock(imageLock);
    
    if (latestFrameForGui.isNull() || 
        latestFrameForGui.getWidth() != bgraFrame.cols || 
        latestFrameForGui.getHeight() != bgraFrame.rows)
    {
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgraFrame.cols, bgraFrame.rows, true);
    }
    
    juce::Image::BitmapData destData(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(destData.data, bgraFrame.data, bgraFrame.total() * bgraFrame.elemSize());
}

juce::Image PoseEstimatorModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void PoseEstimatorModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    juce::ignoreUnused(midi);
    
    // Read Source ID from input pin (BEFORE clearing the buffer!)
    auto inputBuffer = getBusBuffer(buffer, true, 0);
    if (inputBuffer.getNumChannels() > 0 && inputBuffer.getNumSamples() > 0)
    {
        float sourceIdFloat = inputBuffer.getSample(0, 0);
        currentSourceId.store((juce::uint32)sourceIdFloat);
    }
    
    // Clear the buffer for output
    buffer.clear();
    
    // Check if there's new pose data from the processing thread (UPDATED FIFO API)
    if (fifo.getNumReady() > 0)
    {
        auto readScope = fifo.read(1);
        if (readScope.blockSize1 > 0)
        {
            lastResultForAudio = fifoBuffer[readScope.startIndex1];
        }
    }
    
    // Map keypoint coordinates to output channels
    // Channel layout: [Head X, Head Y, Neck X, Neck Y, R Shoulder X, R Shoulder Y, ...]
    for (int i = 0; i < MPI_NUM_KEYPOINTS; ++i)
    {
        int chX = i * 2;
        int chY = i * 2 + 1;
        
        if (chY < buffer.getNumChannels())
        {
            // Normalize coordinates to 0-1 range based on typical video resolution (640x480 or similar)
            // If keypoint not detected (negative value), output 0
            float x_normalized = (lastResultForAudio.keypoints[i][0] >= 0) 
                ? juce::jlimit(0.0f, 1.0f, lastResultForAudio.keypoints[i][0] / 640.0f)
                : 0.0f;
            
            float y_normalized = (lastResultForAudio.keypoints[i][1] >= 0) 
                ? juce::jlimit(0.0f, 1.0f, lastResultForAudio.keypoints[i][1] / 480.0f)
                : 0.0f;
            
            // Fill the entire buffer with the current value (DC signal)
            for (int sample = 0; sample < buffer.getNumSamples(); ++sample)
            {
                buffer.setSample(chX, sample, x_normalized);
                buffer.setSample(chY, sample, y_normalized);
            }
        }
    }
}

#if defined(PRESET_CREATOR_UI)
ImVec2 PoseEstimatorModule::getCustomNodeSize() const
{
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    const float widths[3] { 240.0f, 480.0f, 960.0f };
    return ImVec2(widths[level], 0.0f);
}

void PoseEstimatorModule::drawParametersInNode(float itemWidth,
                                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                              const std::function<void()>& onModificationEnded)
{
    ImGui::PushItemWidth(itemWidth);
    
    // Only show Model selection (as requested)
    if (modelChoiceParam)
    {
        int m = modelChoiceParam->getIndex();
        if (ImGui::Combo("Model", &m, "BODY_25 (25 pts)\0COCO (18 pts)\0MPI (15 pts)\0MPI Fast (15 pts)\0\0"))
        {
            *modelChoiceParam = m;
            requestedModelIndex = m; // signal thread to reload
            onModificationEnded();
        }
    }

    // Blob size (maps to quality tiers)
    if (qualityParam)
    {
        int blobSize = (qualityParam->getIndex() == 0) ? 224 : 368;
        if (ImGui::SliderInt("Blob Size", &blobSize, 224, 368))
        {
            int q = (blobSize <= 296) ? 0 : 1; // snap to Low/Medium
            *qualityParam = q;
            onModificationEnded();
        }
    }

    // Confidence threshold
    float confidence = confidenceThresholdParam->load();
    if (ImGui::SliderFloat("Confidence", &confidence, 0.0f, 1.0f, "%.2f"))
    {
        *dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("confidence")) = confidence;
        onModificationEnded();
    }

    // Restore Zoom (-/+) controls
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    float buttonWidth = (itemWidth / 2.0f) - 4.0f;
    const bool atMin = (level <= 0);
    const bool atMax = (level >= 2);
    if (atMin) ImGui::BeginDisabled();
    if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmax(0, level - 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMin) ImGui::EndDisabled();
    ImGui::SameLine();
    if (atMax) ImGui::BeginDisabled();
    if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmin(2, level + 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMax) ImGui::EndDisabled();
    
    // Status display
    ImGui::Separator();
    if (modelLoaded)
    {
        ImGui::TextColored(ImVec4(0.0f, 1.0f, 0.0f, 1.0f), "Model: Loaded");
        ImGui::TextColored(ImVec4(0.7f, 0.7f, 0.7f, 1.0f), "Keypoints: %d/%d", 
                          lastResultForAudio.detectedPoints, MPI_NUM_KEYPOINTS);
    }
    else
    {
        ImGui::TextColored(ImVec4(1.0f, 0.0f, 0.0f, 1.0f), "Model: NOT LOADED");
        ImGui::TextWrapped("Place model files in: assets/openpose_models/pose/mpi/");
    }
    
    ImGui::PopItemWidth();
}

void PoseEstimatorModule::drawIoPins(const NodePinHelpers& helpers)
{
    // Input: Source ID from video loader
    helpers.drawAudioInputPin("Source In", 0);
    
    // Outputs: 30 pins (15 keypoints x 2 coordinates)
    for (int i = 0; i < MPI_NUM_KEYPOINTS; ++i)
    {
        const std::string& name = MPI_KEYPOINT_NAMES[i];
        // CORRECTED: Proper string conversion for ImGui
        juce::String xLabel = juce::String(name) + " X";
        juce::String yLabel = juce::String(name) + " Y";
        helpers.drawAudioOutputPin(xLabel.toRawUTF8(), i * 2);
        helpers.drawAudioOutputPin(yLabel.toRawUTF8(), i * 2 + 1);
    }
}
#endif


================================================================================
FILE: juce\\Source\\audio\\modules\\HandTrackerModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/dnn.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>

constexpr int HAND_NUM_KEYPOINTS = 21;

struct HandResult
{
    float keypoints[HAND_NUM_KEYPOINTS][2] = {{0}}; // [index][x/y]
    int detectedPoints = 0;
};

class HandTrackerModule : public ModuleProcessor, private juce::Thread
{
public:
    HandTrackerModule();
    ~HandTrackerModule() override;

    const juce::String getName() const override { return "hand_tracker"; }
    juce::Image getLatestFrame();

    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;

    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    void parseHandOutput(const cv::Mat& netOutput, int frameWidth, int frameHeight, HandResult& result);
    void loadModel();

    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;

    std::atomic<float>* sourceIdParam = nullptr;
    std::atomic<float>* confidenceThresholdParam = nullptr;
    std::atomic<float>* zoomLevelParam = nullptr; // 0/1/2 small/normal/large

    cv::dnn::Net net;
    bool modelLoaded = false;

    std::atomic<juce::uint32> currentSourceId { 0 };

    HandResult lastResultForAudio;
    juce::AbstractFifo fifo { 16 };
    std::vector<HandResult> fifoBuffer;

    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
};




================================================================================
FILE: juce\\Source\\audio\\modules\\HandTrackerModule.cpp
================================================================================


#include "HandTrackerModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>

// Thumb/Index/Middle/Ring/Pinky chains plus wrist
static const std::vector<std::pair<int, int>> HAND_SKELETON_PAIRS = {
    {0,1},{1,2},{2,3},{3,4},      // Thumb
    {0,5},{5,6},{6,7},{7,8},      // Index
    {0,9},{9,10},{10,11},{11,12}, // Middle
    {0,13},{13,14},{14,15},{15,16}, // Ring
    {0,17},{17,18},{18,19},{19,20}  // Pinky
};

juce::AudioProcessorValueTreeState::ParameterLayout HandTrackerModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    params.push_back(std::make_unique<juce::AudioParameterFloat>("sourceId", "Source ID", 0.0f, 1000.0f, 0.0f));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("confidence", "Confidence", 0.0f, 1.0f, 0.1f));
    params.push_back(std::make_unique<juce::AudioParameterChoice>("zoomLevel", "Zoom Level", juce::StringArray{"Small","Normal","Large"}, 1));
    return { params.begin(), params.end() };
}

HandTrackerModule::HandTrackerModule()
    : ModuleProcessor(BusesProperties()
                        .withInput("Input", juce::AudioChannelSet::mono(), true)
                        .withOutput("Output", juce::AudioChannelSet::discreteChannels(HAND_NUM_KEYPOINTS * 2), true)),
      juce::Thread("Hand Tracker Thread"),
      apvts(*this, nullptr, "HandTrackerParams", createParameterLayout())
{
    sourceIdParam = apvts.getRawParameterValue("sourceId");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    confidenceThresholdParam = apvts.getRawParameterValue("confidence");
    fifoBuffer.resize(16);
}

HandTrackerModule::~HandTrackerModule()
{
    stopThread(5000);
}

void HandTrackerModule::prepareToPlay(double, int)
{
    startThread(juce::Thread::Priority::normal);
}

void HandTrackerModule::releaseResources()
{
    signalThreadShouldExit();
    stopThread(5000);
}

void HandTrackerModule::loadModel()
{
    auto appDir = juce::File::getSpecialLocation(juce::File::currentApplicationFile).getParentDirectory();
    auto assetsDir = appDir.getChildFile("assets");
    auto handDir = assetsDir.getChildFile("openpose_models").getChildFile("hand");
    auto protoPath = handDir.getChildFile("pose_deploy.prototxt").getFullPathName();
    auto modelPath = handDir.getChildFile("pose_iter_102000.caffemodel").getFullPathName();
    if (juce::File(protoPath).existsAsFile() && juce::File(modelPath).existsAsFile())
    {
        try { net = cv::dnn::readNetFromCaffe(protoPath.toStdString(), modelPath.toStdString()); modelLoaded = true; }
        catch (...) { modelLoaded = false; }
    }
}

void HandTrackerModule::run()
{
    if (!modelLoaded) loadModel();
    while (!threadShouldExit())
    {
        auto srcId = currentSourceId.load();
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(srcId);
        if (frame.empty()) { wait(50); continue; }

        cv::Mat blob = cv::dnn::blobFromImage(frame, 1.0/255.0, cv::Size(368,368), cv::Scalar(), false, false);
        net.setInput(blob);
        cv::Mat out = net.forward();
        HandResult result{};
        parseHandOutput(out, frame.cols, frame.rows, result);

        if (fifo.getFreeSpace() >= 1) { auto w = fifo.write(1); if (w.blockSize1 > 0) fifoBuffer[w.startIndex1] = result; }

        // Draw minimal skeleton
        for (const auto& p : HAND_SKELETON_PAIRS)
        {
            int a=p.first,b=p.second; if (result.keypoints[a][0] >= 0 && result.keypoints[b][0] >= 0)
                cv::line(frame, { (int)result.keypoints[a][0], (int)result.keypoints[a][1] },
                              { (int)result.keypoints[b][0], (int)result.keypoints[b][1] }, {0,255,0}, 2);
        }
        for (int i=0;i<HAND_NUM_KEYPOINTS;++i)
            if (result.keypoints[i][0] >= 0)
                cv::circle(frame, { (int)result.keypoints[i][0], (int)result.keypoints[i][1] }, 3, {0,0,255}, -1);
        updateGuiFrame(frame);
        wait(66);
    }
}

void HandTrackerModule::parseHandOutput(const cv::Mat& netOutput, int frameWidth, int frameHeight, HandResult& result)
{
    int H = netOutput.size[2];
    int W = netOutput.size[3];
    float thresh = confidenceThresholdParam ? confidenceThresholdParam->load() : 0.1f;
    result.detectedPoints = 0;
    int count = juce::jmin(HAND_NUM_KEYPOINTS, netOutput.size[1]);
    for (int i=0;i<count;++i)
    {
        cv::Mat heat(H, W, CV_32F, (void*)netOutput.ptr<float>(0,i));
        double maxVal; cv::Point maxLoc; cv::minMaxLoc(heat, nullptr, &maxVal, nullptr, &maxLoc);
        if (maxVal > thresh) { result.keypoints[i][0] = (float)maxLoc.x * frameWidth / W; result.keypoints[i][1] = (float)maxLoc.y * frameHeight / H; result.detectedPoints++; }
        else { result.keypoints[i][0] = -1.0f; result.keypoints[i][1] = -1.0f; }
    }
}

void HandTrackerModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    juce::ignoreUnused(midi);
    // Read Source ID from input pin
    auto in = getBusBuffer(buffer, true, 0);
    if (in.getNumChannels()>0 && in.getNumSamples()>0) currentSourceId.store((juce::uint32)in.getSample(0,0));
    buffer.clear();
    if (fifo.getNumReady()>0) { auto r=fifo.read(1); if (r.blockSize1>0) lastResultForAudio=fifoBuffer[r.startIndex1]; }
    for (int i=0;i<HAND_NUM_KEYPOINTS;++i)
    {
        int chX=i*2, chY=i*2+1; if (chY>=buffer.getNumChannels()) break;
        float xn = (lastResultForAudio.keypoints[i][0] >= 0) ? juce::jlimit(0.0f,1.0f,lastResultForAudio.keypoints[i][0]/640.0f) : 0.0f;
        float yn = (lastResultForAudio.keypoints[i][1] >= 0) ? juce::jlimit(0.0f,1.0f,lastResultForAudio.keypoints[i][1]/480.0f) : 0.0f;
        for (int s=0;s<buffer.getNumSamples();++s){ buffer.setSample(chX,s,xn); buffer.setSample(chY,s,yn);}    
    }
}

#if defined(PRESET_CREATOR_UI)
ImVec2 HandTrackerModule::getCustomNodeSize() const
{
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1; level = juce::jlimit(0,2,level);
    const float widths[3]{240.0f,480.0f,960.0f}; return ImVec2(widths[level],0.0f);
}

static const char* HAND_NAMES[HAND_NUM_KEYPOINTS] = {
    "Wrist",
    "Thumb1","Thumb2","Thumb3","Thumb4",
    "Index1","Index2","Index3","Index4",
    "Middle1","Middle2","Middle3","Middle4",
    "Ring1","Ring2","Ring3","Ring4",
    "Pinky1","Pinky2","Pinky3","Pinky4"
};

void HandTrackerModule::drawParametersInNode(float itemWidth,
                                             const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                             const std::function<void()>& onModificationEnded)
{
    ImGui::PushItemWidth(itemWidth);
    // Confidence
    float conf = confidenceThresholdParam ? confidenceThresholdParam->load() : 0.1f;
    if (ImGui::SliderFloat("Confidence", &conf, 0.0f, 1.0f, "%.2f")) {
        *dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("confidence")) = conf; onModificationEnded();
    }
    // Zoom -/+
    int level = zoomLevelParam ? (int)zoomLevelParam->load() : 1; level = juce::jlimit(0,2,level);
    float bw = (itemWidth/2.0f)-4.0f; bool atMin=(level<=0), atMax=(level>=2);
    if(atMin) ImGui::BeginDisabled(); if(ImGui::Button("-", ImVec2(bw,0))){ int nl=juce::jmax(0,level-1); if(auto* p=apvts.getParameter("zoomLevel")) p->setValueNotifyingHost((float)nl/2.0f); onModificationEnded(); }
    if(atMin) ImGui::EndDisabled(); ImGui::SameLine(); if(atMax) ImGui::BeginDisabled(); if(ImGui::Button("+", ImVec2(bw,0))){ int nl=juce::jmin(2,level+1); if(auto* p=apvts.getParameter("zoomLevel")) p->setValueNotifyingHost((float)nl/2.0f); onModificationEnded(); }
    if(atMax) ImGui::EndDisabled();
    ImGui::PopItemWidth();
}

void HandTrackerModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioInputPin("Source In", 0);
    for (int i=0;i<HAND_NUM_KEYPOINTS;++i)
    {
        juce::String x = juce::String(HAND_NAMES[i]) + " X";
        juce::String y = juce::String(HAND_NAMES[i]) + " Y";
        helpers.drawAudioOutputPin(x.toRawUTF8(), i*2);
        helpers.drawAudioOutputPin(y.toRawUTF8(), i*2+1);
    }
}

#endif

void HandTrackerModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgra; cv::cvtColor(frame, bgra, cv::COLOR_BGR2BGRA);
    const juce::ScopedLock lock(imageLock);
    if (latestFrameForGui.isNull() || latestFrameForGui.getWidth()!=bgra.cols || latestFrameForGui.getHeight()!=bgra.rows)
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgra.cols, bgra.rows, true);
    juce::Image::BitmapData dest(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(dest.data, bgra.data, bgra.total()*bgra.elemSize());
}

juce::Image HandTrackerModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}




================================================================================
FILE: juce\\Source\\audio\\modules\\FaceTrackerModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/dnn.hpp>
#include <opencv2/objdetect.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>

constexpr int FACE_NUM_KEYPOINTS = 70;

struct FaceResult
{
    float keypoints[FACE_NUM_KEYPOINTS][2] = {{0}};
    int detectedPoints = 0;
};

class FaceTrackerModule : public ModuleProcessor, private juce::Thread
{
public:
    FaceTrackerModule();
    ~FaceTrackerModule() override;

    const juce::String getName() const override { return "face_tracker"; }
    juce::Image getLatestFrame();

    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;

    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    void parseFaceOutput(const cv::Mat& netOutput, const cv::Rect& faceBox, FaceResult& result);
    void loadModel();

    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;

    std::atomic<float>* sourceIdParam = nullptr;
    std::atomic<float>* confidenceThresholdParam = nullptr;
    std::atomic<float>* zoomLevelParam = nullptr;

    cv::CascadeClassifier faceCascade;
    cv::dnn::Net net;
    bool modelLoaded = false;

    std::atomic<juce::uint32> currentSourceId { 0 };

    FaceResult lastResultForAudio;
    juce::AbstractFifo fifo { 16 };
    std::vector<FaceResult> fifoBuffer;

    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
};




================================================================================
FILE: juce\\Source\\audio\\modules\\FaceTrackerModule.cpp
================================================================================


#include "FaceTrackerModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>

juce::AudioProcessorValueTreeState::ParameterLayout FaceTrackerModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    params.push_back(std::make_unique<juce::AudioParameterFloat>("sourceId", "Source ID", 0.0f, 1000.0f, 0.0f));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("confidence", "Confidence", 0.0f, 1.0f, 0.1f));
    params.push_back(std::make_unique<juce::AudioParameterChoice>("zoomLevel", "Zoom Level", juce::StringArray{"Small","Normal","Large"}, 1));
    return { params.begin(), params.end() };
}

FaceTrackerModule::FaceTrackerModule()
    : ModuleProcessor(BusesProperties()
                        .withInput("Input", juce::AudioChannelSet::mono(), true)
                        .withOutput("Output", juce::AudioChannelSet::discreteChannels(FACE_NUM_KEYPOINTS * 2), true)),
      juce::Thread("Face Tracker Thread"),
      apvts(*this, nullptr, "FaceTrackerParams", createParameterLayout())
{
    sourceIdParam = apvts.getRawParameterValue("sourceId");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    confidenceThresholdParam = apvts.getRawParameterValue("confidence");
    fifoBuffer.resize(16);
}

FaceTrackerModule::~FaceTrackerModule()
{
    stopThread(5000);
}

void FaceTrackerModule::prepareToPlay(double, int)
{
    startThread(juce::Thread::Priority::normal);
}

void FaceTrackerModule::releaseResources()
{
    signalThreadShouldExit();
    stopThread(5000);
}

void FaceTrackerModule::loadModel()
{
    auto appDir = juce::File::getSpecialLocation(juce::File::currentApplicationFile).getParentDirectory();
    auto assetsDir = appDir.getChildFile("assets");
    auto faceDir = assetsDir.getChildFile("openpose_models").getChildFile("face");
    auto haarPath = faceDir.getChildFile("haarcascade_frontalface_alt.xml").getFullPathName();
    auto protoPath = faceDir.getChildFile("pose_deploy.prototxt").getFullPathName();
    auto modelPath = faceDir.getChildFile("pose_iter_116000.caffemodel").getFullPathName();
    bool ok = faceCascade.load(haarPath.toStdString());
    if (ok && juce::File(protoPath).existsAsFile() && juce::File(modelPath).existsAsFile())
    {
        try { net = cv::dnn::readNetFromCaffe(protoPath.toStdString(), modelPath.toStdString()); modelLoaded = true; }
        catch (...) { modelLoaded = false; }
    }
}

void FaceTrackerModule::run()
{
    if (!modelLoaded) loadModel();
    while (!threadShouldExit())
    {
        auto srcId = currentSourceId.load();
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(srcId);
        if (frame.empty()) { wait(50); continue; }

        cv::Mat gray; cv::cvtColor(frame, gray, cv::COLOR_BGR2GRAY);
        std::vector<cv::Rect> faces; faceCascade.detectMultiScale(gray, faces);
        FaceResult result{};
        if (!faces.empty())
        {
            cv::Rect box = faces[0];
            cv::Mat roi = frame(box);
            cv::Mat blob = cv::dnn::blobFromImage(roi, 1.0/255.0, cv::Size(368,368), cv::Scalar(), false, false);
            net.setInput(blob);
            cv::Mat out = net.forward();
            parseFaceOutput(out, box, result);
            // Draw box
            cv::rectangle(frame, box, {0,255,0}, 2);
            for (int i=0;i<FACE_NUM_KEYPOINTS;++i)
                if (result.keypoints[i][0] >= 0)
                    cv::circle(frame, { (int)result.keypoints[i][0], (int)result.keypoints[i][1] }, 2, {0,0,255}, -1);
        }
        if (fifo.getFreeSpace()>=1){ auto w=fifo.write(1); if (w.blockSize1>0) fifoBuffer[w.startIndex1]=result; }
        updateGuiFrame(frame);
        wait(66);
    }
}

void FaceTrackerModule::parseFaceOutput(const cv::Mat& netOutput, const cv::Rect& faceBox, FaceResult& result)
{
    int H=netOutput.size[2], W=netOutput.size[3];
    float thresh = confidenceThresholdParam ? confidenceThresholdParam->load() : 0.1f;
    result.detectedPoints=0; int count=juce::jmin(FACE_NUM_KEYPOINTS, netOutput.size[1]);
    for (int i=0;i<count;++i)
    {
        cv::Mat heat(H,W,CV_32F,(void*)netOutput.ptr<float>(0,i));
        double mv; cv::Point ml; cv::minMaxLoc(heat,nullptr,&mv,nullptr,&ml);
        if (mv>thresh){ result.keypoints[i][0]=(float)faceBox.x + (float)ml.x*faceBox.width/W; result.keypoints[i][1]=(float)faceBox.y + (float)ml.y*faceBox.height/H; result.detectedPoints++; }
        else { result.keypoints[i][0]=-1.0f; result.keypoints[i][1]=-1.0f; }
    }
}

void FaceTrackerModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    juce::ignoreUnused(midi);
    auto in=getBusBuffer(buffer,true,0); if(in.getNumChannels()>0 && in.getNumSamples()>0) currentSourceId.store((juce::uint32)in.getSample(0,0));
    buffer.clear(); if(fifo.getNumReady()>0){auto r=fifo.read(1); if(r.blockSize1>0) lastResultForAudio=fifoBuffer[r.startIndex1];}
    for(int i=0;i<FACE_NUM_KEYPOINTS;++i){int chX=i*2, chY=i*2+1; if(chY>=buffer.getNumChannels()) break; float xn=(lastResultForAudio.keypoints[i][0]>=0)?juce::jlimit(0.0f,1.0f,lastResultForAudio.keypoints[i][0]/640.0f):0.0f; float yn=(lastResultForAudio.keypoints[i][1]>=0)?juce::jlimit(0.0f,1.0f,lastResultForAudio.keypoints[i][1]/480.0f):0.0f; for(int s=0;s<buffer.getNumSamples();++s){buffer.setSample(chX,s,xn); buffer.setSample(chY,s,yn);} }
}

#if defined(PRESET_CREATOR_UI)
ImVec2 FaceTrackerModule::getCustomNodeSize() const
{ int level=zoomLevelParam?(int)zoomLevelParam->load():1; level=juce::jlimit(0,2,level); const float widths[3]{240.0f,480.0f,960.0f}; return ImVec2(widths[level],0.0f);} 

void FaceTrackerModule::drawParametersInNode(float itemWidth,
                                             const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                             const std::function<void()>& onModificationEnded)
{
    ImGui::PushItemWidth(itemWidth);
    float conf=confidenceThresholdParam?confidenceThresholdParam->load():0.1f;
    if (ImGui::SliderFloat("Confidence", &conf, 0.0f, 1.0f, "%.2f")) { *dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("confidence"))=conf; onModificationEnded(); }
    int level=zoomLevelParam?(int)zoomLevelParam->load():1; level=juce::jlimit(0,2,level); float bw=(itemWidth/2.0f)-4.0f; bool atMin=(level<=0), atMax=(level>=2);
    if(atMin) ImGui::BeginDisabled(); if(ImGui::Button("-", ImVec2(bw,0))){ int nl=juce::jmax(0,level-1); if(auto* p=apvts.getParameter("zoomLevel")) p->setValueNotifyingHost((float)nl/2.0f); onModificationEnded(); }
    if(atMin) ImGui::EndDisabled(); ImGui::SameLine(); if(atMax) ImGui::BeginDisabled(); if(ImGui::Button("+", ImVec2(bw,0))){ int nl=juce::jmin(2,level+1); if(auto* p=apvts.getParameter("zoomLevel")) p->setValueNotifyingHost((float)nl/2.0f); onModificationEnded(); }
    if(atMax) ImGui::EndDisabled();
    ImGui::PopItemWidth();
}

void FaceTrackerModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioInputPin("Source In", 0);
    for(int i=0;i<FACE_NUM_KEYPOINTS;++i)
    { juce::String base = juce::String("Pt ") + juce::String(i+1); helpers.drawAudioOutputPin((base+" X").toRawUTF8(), i*2); helpers.drawAudioOutputPin((base+" Y").toRawUTF8(), i*2+1);}    
}

#endif

void FaceTrackerModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgra; cv::cvtColor(frame, bgra, cv::COLOR_BGR2BGRA); const juce::ScopedLock lock(imageLock);
    if (latestFrameForGui.isNull() || latestFrameForGui.getWidth()!=bgra.cols || latestFrameForGui.getHeight()!=bgra.rows)
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgra.cols, bgra.rows, true);
    juce::Image::BitmapData dest(latestFrameForGui, juce::Image::BitmapData::writeOnly); memcpy(dest.data, bgra.data, bgra.total()*bgra.elemSize());
}

juce::Image FaceTrackerModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}




================================================================================
FILE: juce\\Source\\audio\\modules\\ObjectDetectorModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/dnn.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>
#if defined(PRESET_CREATOR_UI)
#include <juce_gui_basics/juce_gui_basics.h>
#endif

// A real-time safe struct to hold the bounding box of the detected object.
struct ObjectDetectionResult
{
    float x = 0.0f;     // normalized center X (0..1)
    float y = 0.0f;     // normalized center Y (0..1)
    float width = 0.0f; // normalized width (0..1)
    float height = 0.0f;// normalized height (0..1)
    bool detected = false;
};

class ObjectDetectorModule : public ModuleProcessor, private juce::Thread
{
public:
    ObjectDetectorModule();
    ~ObjectDetectorModule() override;

    const juce::String getName() const override { return "object_detector"; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }
    juce::Image getLatestFrame();

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    void loadModel();
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;
    
    // Parameters
    std::atomic<float>* sourceIdParam = nullptr;
    std::atomic<float>* zoomLevelParam = nullptr; // 0=Small,1=Normal,2=Large
    juce::AudioParameterChoice* targetClassParam = nullptr;
    std::atomic<float>* confidenceThresholdParam = nullptr;
    
    // DNN
    cv::dnn::Net net;
    bool modelLoaded = false;
    std::vector<std::string> classNames;
    
    // UI-selected target class (independent of AudioParameterChoice list)
    std::atomic<int> selectedClassId { 0 };

    // Source ID (set by audio thread)
    std::atomic<juce::uint32> currentSourceId { 0 };
    
    // FIFO for communication
    ObjectDetectionResult lastResultForAudio;
    juce::AbstractFifo fifo { 16 };
    std::vector<ObjectDetectionResult> fifoBuffer;
    
    // UI preview
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
};




================================================================================
FILE: juce\\Source\\audio\\modules\\ObjectDetectorModule.cpp
================================================================================


#include "ObjectDetectorModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>
#include <opencv2/dnn.hpp>
#include <fstream>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

// YOLOv3 default input size
static constexpr int YOLO_INPUT_SIZE = 416;
// Embedded COCO-80 labels used if coco.names is missing
static const char* kCoco80[] = {
    "person","bicycle","car","motorbike","aeroplane","bus","train","truck","boat","traffic light",
    "fire hydrant","stop sign","parking meter","bench","bird","cat","dog","horse","sheep","cow",
    "elephant","bear","zebra","giraffe","backpack","umbrella","handbag","tie","suitcase","frisbee",
    "skis","snowboard","sports ball","kite","baseball bat","baseball glove","skateboard","surfboard","tennis racket","bottle",
    "wine glass","cup","fork","knife","spoon","bowl","banana","apple","sandwich","orange",
    "broccoli","carrot","hot dog","pizza","donut","cake","chair","sofa","pottedplant","bed",
    "diningtable","toilet","tvmonitor","laptop","mouse","remote","keyboard","cell phone","microwave","oven",
    "toaster","sink","refrigerator","book","clock","vase","scissors","teddy bear","hair drier","toothbrush"
};

juce::AudioProcessorValueTreeState::ParameterLayout ObjectDetectorModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    
    params.push_back(std::make_unique<juce::AudioParameterFloat>(
        "sourceId", "Source ID", 0.0f, 1000.0f, 0.0f));
    
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "targetClass", "Target Class", juce::StringArray{ "person" }, 0));
    
    params.push_back(std::make_unique<juce::AudioParameterFloat>(
        "confidence", "Confidence", 0.0f, 1.0f, 0.5f));
    
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    
    return { params.begin(), params.end() };
}

ObjectDetectorModule::ObjectDetectorModule()
    : ModuleProcessor(BusesProperties()
                      .withInput("Input", juce::AudioChannelSet::mono(), true)
                      .withOutput("Output", juce::AudioChannelSet::discreteChannels(5), true)),
      juce::Thread("Object Detector Thread"),
      apvts(*this, nullptr, "ObjectDetectorParams", createParameterLayout())
{
    sourceIdParam = apvts.getRawParameterValue("sourceId");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    targetClassParam = dynamic_cast<juce::AudioParameterChoice*>(apvts.getParameter("targetClass"));
    confidenceThresholdParam = apvts.getRawParameterValue("confidence");
    
    fifoBuffer.resize(16);
    
    loadModel();
}

ObjectDetectorModule::~ObjectDetectorModule()
{
    stopThread(5000);
}

void ObjectDetectorModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::ignoreUnused(sampleRate, samplesPerBlock);
    startThread(juce::Thread::Priority::normal);
}

void ObjectDetectorModule::releaseResources()
{
    signalThreadShouldExit();
    stopThread(5000);
}

void ObjectDetectorModule::loadModel()
{
    // Find assets next to executable
    auto exeFile = juce::File::getSpecialLocation(juce::File::currentApplicationFile);
    auto appDir = exeFile.getParentDirectory();
    juce::File assetsDir = appDir.getChildFile("assets");
    
    juce::File weights = assetsDir.getChildFile("yolov3.weights");
    juce::File cfg     = assetsDir.getChildFile("yolov3.cfg");
    // Fallback to tiny if standard is missing
    if (!weights.existsAsFile() || !cfg.existsAsFile())
    {
        juce::File wTiny = assetsDir.getChildFile("yolov3-tiny.weights");
        juce::File cTiny = assetsDir.getChildFile("yolov3-tiny.cfg");
        if (wTiny.existsAsFile() && cTiny.existsAsFile())
        {
            weights = wTiny; cfg = cTiny;
            juce::Logger::writeToLog("[ObjectDetector] Using YOLOv3-tiny assets.");
        }
    }
    juce::File names = assetsDir.getChildFile("coco.names");
 
    juce::Logger::writeToLog("[ObjectDetector] Assets directory: " + assetsDir.getFullPathName());
    
    if (weights.existsAsFile() && cfg.existsAsFile())
    {
        try
        {
            net = cv::dnn::readNetFromDarknet(cfg.getFullPathName().toStdString(), weights.getFullPathName().toStdString());
            net.setPreferableBackend(cv::dnn::DNN_BACKEND_OPENCV);
            net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);
            
            // Load class names if available
            classNames.clear();
            if (names.existsAsFile())
            {
                std::ifstream ifs(names.getFullPathName().toStdString().c_str());
                std::string line;
                while (std::getline(ifs, line))
                    if (!line.empty()) classNames.push_back(line);
            }
            if (classNames.empty())
            {
                classNames.assign(std::begin(kCoco80), std::end(kCoco80));
                juce::Logger::writeToLog("[ObjectDetector] coco.names missing; using embedded COCO-80 labels.");
            }
            
            // Note: UI combo is populated from classNames directly
            
            modelLoaded = true;
            juce::Logger::writeToLog("[ObjectDetector] YOLOv3 model loaded successfully");
        }
        catch (const cv::Exception& e)
        {
            juce::Logger::writeToLog("[ObjectDetector] OpenCV exception: " + juce::String(e.what()));
            modelLoaded = false;
        }
    }
    else
    {
        juce::Logger::writeToLog("[ObjectDetector] FAILED: Could not find YOLO model files in " + assetsDir.getFullPathName());
        modelLoaded = false;
    }
}

void ObjectDetectorModule::run()
{
    while (!threadShouldExit())
    {
        if (!modelLoaded)
        {
            wait(200);
            continue;
        }
        
        juce::uint32 sourceId = currentSourceId.load();
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(sourceId);
        
        if (!frame.empty())
        {
            // Prepare input blob
            cv::Mat blob = cv::dnn::blobFromImage(
                frame,
                1.0 / 255.0,
                cv::Size(YOLO_INPUT_SIZE, YOLO_INPUT_SIZE),
                cv::Scalar(),
                true,
                false);
            net.setInput(blob);
            
            // Forward through YOLO
            std::vector<cv::Mat> outs;
            net.forward(outs, net.getUnconnectedOutLayersNames());
            
            std::vector<int> classIds;
            std::vector<float> confidences;
            std::vector<cv::Rect> boxes;
            
            int targetClassId = juce::jlimit(0, (int)juce::jmax<size_t>(1, classNames.size()) - 1, selectedClassId.load());
            float confThreshold = confidenceThresholdParam ? confidenceThresholdParam->load() : 0.5f;
            
            for (const auto& out : outs)
            {
                const float* data = reinterpret_cast<const float*>(out.data);
                for (int i = 0; i < out.rows; ++i, data += out.cols)
                {
                    float score;
                    int classId = -1;
                    // Scores start at index 5
                    cv::Mat scores(1, out.cols - 5, CV_32F, (void*)(data + 5));
                    cv::Point classIdPoint;
                    double maxClassScore;
                    cv::minMaxLoc(scores, nullptr, &maxClassScore, nullptr, &classIdPoint);
                    score = static_cast<float>(maxClassScore);
                    classId = classIdPoint.x;
                    
                    if (score > confThreshold && classId == targetClassId)
                    {
                        int centerX = static_cast<int>(data[0] * frame.cols);
                        int centerY = static_cast<int>(data[1] * frame.rows);
                        int width   = static_cast<int>(data[2] * frame.cols);
                        int height  = static_cast<int>(data[3] * frame.rows);
                        int left    = centerX - width / 2;
                        int top     = centerY - height / 2;
                        classIds.push_back(classId);
                        confidences.push_back(score);
                        boxes.emplace_back(left, top, width, height);
                    }
                }
            }
            
            std::vector<int> indices;
            cv::dnn::NMSBoxes(boxes, confidences, confThreshold, 0.4f, indices);
            
            ObjectDetectionResult result;
            if (!indices.empty())
            {
                int bestIdx = indices[0];
                const cv::Rect& box = boxes[bestIdx];
                result.detected = true;
                result.x = juce::jlimit(0.0f, 1.0f, (float)(box.x + box.width * 0.5f) / (float)frame.cols);
                result.y = juce::jlimit(0.0f, 1.0f, (float)(box.y + box.height * 0.5f) / (float)frame.rows);
                result.width  = juce::jlimit(0.0f, 1.0f, (float)box.width / (float)frame.cols);
                result.height = juce::jlimit(0.0f, 1.0f, (float)box.height / (float)frame.rows);
                
                // Draw bbox and label
                cv::rectangle(frame, box, cv::Scalar(0, 255, 0), 2);
                std::string label;
                if (!classNames.empty() && targetClassId >= 0 && targetClassId < (int)classNames.size())
                    label = classNames[(size_t)targetClassId];
                else
                    label = "target";
                cv::putText(frame, label, box.tl() + cv::Point(0, -5), cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(0, 255, 0), 2);
            }
            
            if (fifo.getFreeSpace() >= 1)
            {
                auto writeScope = fifo.write(1);
                if (writeScope.blockSize1 > 0)
                    fifoBuffer[writeScope.startIndex1] = result;
            }
            
            updateGuiFrame(frame);
        }
        
        // YOLO is heavy; ~10 FPS
        wait(100);
    }
}

void ObjectDetectorModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgraFrame;
    cv::cvtColor(frame, bgraFrame, cv::COLOR_BGR2BGRA);
    
    const juce::ScopedLock lock(imageLock);
    if (latestFrameForGui.isNull() ||
        latestFrameForGui.getWidth() != bgraFrame.cols ||
        latestFrameForGui.getHeight() != bgraFrame.rows)
    {
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgraFrame.cols, bgraFrame.rows, true);
    }
    juce::Image::BitmapData destData(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(destData.data, bgraFrame.data, bgraFrame.total() * bgraFrame.elemSize());
}

juce::Image ObjectDetectorModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void ObjectDetectorModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    juce::ignoreUnused(midi);
    
    // Read Source ID from input pin
    auto inputBuffer = getBusBuffer(buffer, true, 0);
    if (inputBuffer.getNumChannels() > 0 && inputBuffer.getNumSamples() > 0)
    {
        float sourceIdFloat = inputBuffer.getSample(0, 0);
        currentSourceId.store((juce::uint32)sourceIdFloat);
    }
    
    buffer.clear();
    
    if (fifo.getNumReady() > 0)
    {
        auto readScope = fifo.read(1);
        if (readScope.blockSize1 > 0)
            lastResultForAudio = fifoBuffer[readScope.startIndex1];
    }
    
    // Output channels: 0:X, 1:Y, 2:W, 3:H, 4:Gate
    const float values[5]
    {
        lastResultForAudio.x,
        lastResultForAudio.y,
        lastResultForAudio.width,
        lastResultForAudio.height,
        lastResultForAudio.detected ? 1.0f : 0.0f
    };
    
    for (int ch = 0; ch < juce::jmin(5, buffer.getNumChannels()); ++ch)
    {
        for (int s = 0; s < buffer.getNumSamples(); ++s)
            buffer.setSample(ch, s, values[ch]);
    }
}

#if defined(PRESET_CREATOR_UI)
ImVec2 ObjectDetectorModule::getCustomNodeSize() const
{
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    const float widths[3] { 240.0f, 480.0f, 960.0f };
    return ImVec2(widths[level], 0.0f);
}

void ObjectDetectorModule::drawParametersInNode(float itemWidth,
                                                const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                                const std::function<void()>& onModificationEnded)
{
    juce::ignoreUnused(isParamModulated);
    ImGui::PushItemWidth(itemWidth);
    
    if (targetClassParam)
    {
        int idx = juce::jlimit(0, (int)juce::jmax<size_t>(1, classNames.size()) - 1, selectedClassId.load());
        const char* currentLabel = (!classNames.empty() && juce::isPositiveAndBelow(idx, (int)classNames.size()))
            ? classNames[(size_t)idx].c_str() : "person";

        // Optional quick filter
        static char filterBuf[64] = {0};
        ImGui::InputText("##class_filter", filterBuf, sizeof(filterBuf));
        ImGui::SameLine();
        if (ImGui::Button("Clear")) { filterBuf[0] = '\0'; }

        if (ImGui::BeginCombo("Target Class", currentLabel))
        {
            const juce::String filter = juce::String(filterBuf).toLowerCase();
            for (int i = 0; i < (int)classNames.size(); ++i)
            {
                const juce::String name = juce::String(classNames[(size_t)i]);
                if (filter.isNotEmpty() && !name.toLowerCase().contains(filter))
                    continue;
                bool selected = (idx == i);
                if (ImGui::Selectable(name.toRawUTF8(), selected))
                {
                    idx = i;
                    selectedClassId.store(idx);
                    onModificationEnded();
                }
                if (selected) ImGui::SetItemDefaultFocus();
            }
            ImGui::EndCombo();
        }
    }
    
    float confidence = confidenceThresholdParam ? confidenceThresholdParam->load() : 0.5f;
    if (ImGui::SliderFloat("Confidence", &confidence, 0.0f, 1.0f, "%.2f"))
    {
        if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("confidence")))
            *p = confidence;
        onModificationEnded();
    }
    
    // Zoom controls
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    float buttonWidth = (itemWidth / 2.0f) - 4.0f;
    const bool atMin = (level <= 0);
    const bool atMax = (level >= 2);
    if (atMin) ImGui::BeginDisabled();
    if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmax(0, level - 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMin) ImGui::EndDisabled();
    ImGui::SameLine();
    if (atMax) ImGui::BeginDisabled();
    if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmin(2, level + 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMax) ImGui::EndDisabled();
    
    ImGui::Separator();
    if (modelLoaded)
    {
        ImGui::TextColored(ImVec4(0.0f, 1.0f, 0.0f, 1.0f), "Model: Loaded");
        ImGui::Text("Classes: %d", (int)classNames.size());
    }
    else
    {
        ImGui::TextColored(ImVec4(1.0f, 0.0f, 0.0f, 1.0f), "Model: NOT LOADED");
        ImGui::TextWrapped("Place files in assets/: yolov3.cfg, yolov3.weights, coco.names");
    }
    
    ImGui::PopItemWidth();
}

void ObjectDetectorModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioInputPin("Source In", 0);
    helpers.drawAudioOutputPin("X", 0);
    helpers.drawAudioOutputPin("Y", 1);
    helpers.drawAudioOutputPin("Width", 2);
    helpers.drawAudioOutputPin("Height", 3);
    helpers.drawAudioOutputPin("Gate", 4);
}
#endif




================================================================================
FILE: juce\\Source\\audio\\modules\\ColorTrackerModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>
#if defined(PRESET_CREATOR_UI)
#include <juce_gui_basics/juce_gui_basics.h>
#endif

// A struct to hold the state and results for a single tracked color.
struct TrackedColor
{
    juce::String name;
    juce::Colour displayColour; // representative color for UI swatch
    cv::Scalar hsvLower { 0, 100, 100 };
    cv::Scalar hsvUpper { 10, 255, 255 };
    float tolerance { 1.0f }; // 1.0 = default window; <1 shrink, >1 expand
};

// x, y, area for each color
using ColorResult = std::vector<std::tuple<float, float, float>>;

class ColorTrackerModule : public ModuleProcessor, private juce::Thread
{
public:
    ColorTrackerModule();
    ~ColorTrackerModule() override;

    const juce::String getName() const override { return "color_tracker"; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }
    juce::Image getLatestFrame();

    // UI integration helpers
    void addColorAt(int x, int y);
    bool isPickerActive() const { return isColorPickerActive.load(); }
    void exitPickerMode() { isColorPickerActive.store(false); }

    // Dynamic outputs: 3 per color
    std::vector<DynamicPinInfo> getDynamicOutputPins() const override;

    // Persist tracked colors across sessions
    juce::ValueTree getExtraStateTree() const override;
    void setExtraStateTree(const juce::ValueTree& state) override;

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;
    
    std::atomic<float>* sourceIdParam = nullptr;
    std::atomic<float>* zoomLevelParam = nullptr; // 0=Small,1=Normal,2=Large
    
    // Thread-safe color list
    std::vector<TrackedColor> trackedColors;
    mutable juce::CriticalSection colorListLock;
    
    // Source ID (set by audio thread)
    std::atomic<juce::uint32> currentSourceId { 0 };
    
    // FIFO for communication
    ColorResult lastResultForAudio;
    juce::AbstractFifo fifo { 16 };
    std::vector<ColorResult> fifoBuffer;
    
    // UI interaction
    std::atomic<bool> isColorPickerActive { false };
    // -1 means add a new color; 0+ means update that tracked color index
    std::atomic<int> pickerTargetIndex { -1 };
    std::atomic<int> pickerMouseX { -1 }, pickerMouseY { -1 };
    std::atomic<bool> addColorRequested { false };

    // UI preview
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;

    // Cached last BGR frame for operations while source is paused/no new frames
    cv::Mat lastFrameBgr;
    juce::CriticalSection frameLock;
};




================================================================================
FILE: juce\\Source\\audio\\modules\\ColorTrackerModule.cpp
================================================================================


#include "ColorTrackerModule.h"
#include "../graph/ModularSynthProcessor.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

juce::AudioProcessorValueTreeState::ParameterLayout ColorTrackerModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    params.push_back(std::make_unique<juce::AudioParameterFloat>(
        "sourceId", "Source ID", 0.0f, 1000.0f, 0.0f));
    params.push_back(std::make_unique<juce::AudioParameterChoice>(
        "zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    return { params.begin(), params.end() };
}

ColorTrackerModule::ColorTrackerModule()
    : ModuleProcessor(BusesProperties()
                      .withInput("Input", juce::AudioChannelSet::mono(), true)
                      .withOutput("Output", juce::AudioChannelSet::discreteChannels(24), true)), // up to 8 colors x 3
      juce::Thread("Color Tracker Thread"),
      apvts(*this, nullptr, "ColorTrackerParams", createParameterLayout())
{
    sourceIdParam = apvts.getRawParameterValue("sourceId");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    fifoBuffer.resize(16);
}

ColorTrackerModule::~ColorTrackerModule()
{
    stopThread(5000);
}

void ColorTrackerModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::ignoreUnused(sampleRate, samplesPerBlock);
    startThread(juce::Thread::Priority::normal);
}

void ColorTrackerModule::releaseResources()
{
    signalThreadShouldExit();
    stopThread(5000);
}

void ColorTrackerModule::run()
{
    while (!threadShouldExit())
    {
        juce::uint32 sourceId = currentSourceId.load();
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(sourceId);
        if (!frame.empty())
        {
        cv::Mat hsv;
        if (!frame.empty())
        {
            // Cache last good frame for paused/no-signal scenarios
            {
                const juce::ScopedLock lk(frameLock);
                frame.copyTo(lastFrameBgr);
            }
        }
        else
        {
            // Use cached frame when no fresh frames are available (e.g., transport paused)
            const juce::ScopedLock lk(frameLock);
            if (!lastFrameBgr.empty())
                frame = lastFrameBgr.clone();
        }

        if (!frame.empty())
            cv::cvtColor(frame, hsv, cv::COLOR_BGR2HSV);

            // NOTE: No queued color-pick path here anymore; add/update is handled synchronously by addColorAt()

            ColorResult result;
            {
                const juce::ScopedLock lock(colorListLock);
                for (auto& tc : trackedColors)
                {
                    if (frame.empty() || hsv.empty())
                    {
                        result.emplace_back(0.5f, 0.5f, 0.0f);
                        continue;
                    }
                    // Compute tolerance-adjusted bounds
                    double centerH = 0.5 * ((double)tc.hsvLower[0] + (double)tc.hsvUpper[0]);
                    double centerS = 0.5 * ((double)tc.hsvLower[1] + (double)tc.hsvUpper[1]);
                    double centerV = 0.5 * ((double)tc.hsvLower[2] + (double)tc.hsvUpper[2]);
                    double deltaH  = 0.5 * ((double)tc.hsvUpper[0] - (double)tc.hsvLower[0]);
                    double deltaS  = 0.5 * ((double)tc.hsvUpper[1] - (double)tc.hsvLower[1]);
                    double deltaV  = 0.5 * ((double)tc.hsvUpper[2] - (double)tc.hsvLower[2]);
                    double scale   = juce::jlimit(0.1, 5.0, (double)tc.tolerance);
                    double lowH  = juce::jlimit(0.0, 179.0, centerH - deltaH * scale);
                    double highH = juce::jlimit(0.0, 179.0, centerH + deltaH * scale);
                    double lowS  = juce::jlimit(0.0, 255.0, centerS - deltaS * scale);
                    double highS = juce::jlimit(0.0, 255.0, centerS + deltaS * scale);
                    double lowV  = juce::jlimit(0.0, 255.0, centerV - deltaV * scale);
                    double highV = juce::jlimit(0.0, 255.0, centerV + deltaV * scale);

                    cv::Scalar lower(lowH, lowS, lowV);
                    cv::Scalar upper(highH, highS, highV);

                    cv::Mat mask;
                    cv::inRange(hsv, lower, upper, mask);
                    
                    // Morphological cleanup
                    cv::erode(mask, mask, cv::Mat(), cv::Point(-1,-1), 1);
                    cv::dilate(mask, mask, cv::Mat(), cv::Point(-1,-1), 1);
                    
                    std::vector<std::vector<cv::Point>> contours;
                    cv::findContours(mask, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE);
                    
                    if (!contours.empty())
                    {
                        size_t best = 0;
                        double maxArea = 0.0;
                        for (size_t i = 0; i < contours.size(); ++i)
                        {
                            double a = cv::contourArea(contours[i]);
                            if (a > maxArea) { maxArea = a; best = i; }
                        }
                        const auto& c = contours[best];
                        cv::Moments m = cv::moments(c);
                        float cx = (m.m00 > 0.0) ? (float)(m.m10 / m.m00) / (float)frame.cols : 0.5f;
                        float cy = (m.m00 > 0.0) ? (float)(m.m01 / m.m00) / (float)frame.rows : 0.5f;
                        float area = juce::jlimit(0.0f, 1.0f, (float)(maxArea / (frame.cols * frame.rows)));
                        result.emplace_back(cx, cy, area);
                        
                        // Draw
                        cv::Rect bbox = cv::boundingRect(c);
                        cv::rectangle(frame, bbox, cv::Scalar(0, 255, 255), 2);
                        cv::putText(frame, tc.name.toStdString(), bbox.tl() + cv::Point(0, -5), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255,255,255), 1);
                    }
                    else
                    {
                        result.emplace_back(0.5f, 0.5f, 0.0f);
                    }
                }
            }

            if (fifo.getFreeSpace() >= 1)
            {
                auto writeScope = fifo.write(1);
                if (writeScope.blockSize1 > 0)
                    fifoBuffer[writeScope.startIndex1] = result;
            }
            
            if (!frame.empty())
                updateGuiFrame(frame);
        }
        
        wait(33);
    }
}

void ColorTrackerModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgraFrame;
    cv::cvtColor(frame, bgraFrame, cv::COLOR_BGR2BGRA);
    const juce::ScopedLock lock(imageLock);
    if (latestFrameForGui.isNull() || latestFrameForGui.getWidth() != bgraFrame.cols || latestFrameForGui.getHeight() != bgraFrame.rows)
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgraFrame.cols, bgraFrame.rows, true);
    juce::Image::BitmapData dest(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(dest.data, bgraFrame.data, bgraFrame.total() * bgraFrame.elemSize());
}

juce::Image ColorTrackerModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void ColorTrackerModule::addColorAt(int x, int y)
{
    // Synchronous immediate update only (no background queuing)
    bool appliedSync = false;

    cv::Mat frameCopy;
    {
        const juce::ScopedLock lk(frameLock);
        if (!lastFrameBgr.empty())
            frameCopy = lastFrameBgr.clone();
    }
    if (!frameCopy.empty())
    {
        const int mx = juce::jlimit(0, frameCopy.cols - 1, x);
        const int my = juce::jlimit(0, frameCopy.rows - 1, y);
        cv::Rect roi(std::max(0, mx - 2), std::max(0, my - 2), 5, 5);
        roi &= cv::Rect(0, 0, frameCopy.cols, frameCopy.rows);
        if (roi.area() > 0)
        {
            cv::Scalar avgBgr = cv::mean(frameCopy(roi));
            cv::Vec3b bgr8((uchar)avgBgr[0], (uchar)avgBgr[1], (uchar)avgBgr[2]);
            cv::Mat onePix(1,1,CV_8UC3);
            onePix.at<cv::Vec3b>(0,0) = bgr8;
            cv::Mat onePixHsv;
            cv::cvtColor(onePix, onePixHsv, cv::COLOR_BGR2HSV);
            cv::Vec3b avgHsv = onePixHsv.at<cv::Vec3b>(0,0);
            int avgHue = (int)avgHsv[0];
            int avgSat = (int)avgHsv[1];
            int avgVal = (int)avgHsv[2];

            const juce::ScopedLock lock(colorListLock);
            int targetIdx = pickerTargetIndex.load();
            if (targetIdx < 0 || targetIdx >= (int)trackedColors.size())
            {
                TrackedColor tc;
                tc.name = juce::String("Color ") + juce::String((int)trackedColors.size() + 1);
                tc.hsvLower = cv::Scalar(
                    juce::jlimit(0, 179, avgHue - 10),
                    juce::jlimit(0, 255, avgSat - 40),
                    juce::jlimit(0, 255, avgVal - 40));
                tc.hsvUpper = cv::Scalar(
                    juce::jlimit(0, 179, avgHue + 10),
                    juce::jlimit(0, 255, avgSat + 40),
                    juce::jlimit(0, 255, avgVal + 40));
                tc.displayColour = juce::Colour((juce::uint8)bgr8[2], (juce::uint8)bgr8[1], (juce::uint8)bgr8[0]);
                trackedColors.push_back(tc);
            }
            else
            {
                auto& tc = trackedColors[(size_t)targetIdx];
                tc.hsvLower = cv::Scalar(
                    juce::jlimit(0, 179, avgHue - 10),
                    juce::jlimit(0, 255, avgSat - 40),
                    juce::jlimit(0, 255, avgVal - 40));
                tc.hsvUpper = cv::Scalar(
                    juce::jlimit(0, 179, avgHue + 10),
                    juce::jlimit(0, 255, avgSat + 40),
                    juce::jlimit(0, 255, avgVal + 40));
                tc.displayColour = juce::Colour((juce::uint8)bgr8[2], (juce::uint8)bgr8[1], (juce::uint8)bgr8[0]);
                appliedSync = true;
            }

            // Push the same frame to GUI immediately for instant visual feedback
            updateGuiFrame(frameCopy);
        }
    }

    // Finalize picker state; never queue async to avoid duplicates
    addColorRequested.store(false);
    pickerMouseX.store(-1);
    pickerMouseY.store(-1);
    isColorPickerActive.store(false);
}

juce::ValueTree ColorTrackerModule::getExtraStateTree() const
{
    juce::ValueTree state("ColorTrackerState");
    const juce::ScopedLock lock(colorListLock);
    for (const auto& tc : trackedColors)
    {
        juce::ValueTree node("TrackedColor");
        node.setProperty("name", tc.name, nullptr);
        node.setProperty("displayColour", tc.displayColour.toString(), nullptr);
        // Persist HSV windows (indexed fields for stability)
        node.setProperty("hsvLower0", (int)tc.hsvLower[0], nullptr);
        node.setProperty("hsvLower1", (int)tc.hsvLower[1], nullptr);
        node.setProperty("hsvLower2", (int)tc.hsvLower[2], nullptr);
        node.setProperty("hsvUpper0", (int)tc.hsvUpper[0], nullptr);
        node.setProperty("hsvUpper1", (int)tc.hsvUpper[1], nullptr);
        node.setProperty("hsvUpper2", (int)tc.hsvUpper[2], nullptr);
        node.setProperty("tolerance", tc.tolerance, nullptr);
        state.addChild(node, -1, nullptr);
    }
    return state;
}

void ColorTrackerModule::setExtraStateTree(const juce::ValueTree& state)
{
    if (!state.hasType("ColorTrackerState")) return;
    const juce::ScopedLock lock(colorListLock);
    trackedColors.clear();
    for (int i = 0; i < state.getNumChildren(); ++i)
    {
        auto node = state.getChild(i);
        if (!node.hasType("TrackedColor")) continue;
        TrackedColor tc;
        tc.name = node.getProperty("name", juce::String("Color ") + juce::String(i)).toString();
        tc.displayColour = juce::Colour::fromString(node.getProperty("displayColour", "ff000000").toString());
        int hL = (int)node.getProperty("hsvLower0", 0);
        int sL = (int)node.getProperty("hsvLower1", 100);
        int vL = (int)node.getProperty("hsvLower2", 100);
        int hU = (int)node.getProperty("hsvUpper0", 10);
        int sU = (int)node.getProperty("hsvUpper1", 255);
        int vU = (int)node.getProperty("hsvUpper2", 255);
        tc.hsvLower = cv::Scalar(hL, sL, vL);
        tc.hsvUpper = cv::Scalar(hU, sU, vU);
        tc.tolerance = (float)(double)node.getProperty("tolerance", 1.0);
        trackedColors.push_back(tc);
    }
    // UI will re-query pins on next frame; no explicit rebuild signal required
}

void ColorTrackerModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    juce::ignoreUnused(midi);
    auto inputBuffer = getBusBuffer(buffer, true, 0);
    if (inputBuffer.getNumChannels() > 0 && inputBuffer.getNumSamples() > 0)
        currentSourceId.store((juce::uint32)inputBuffer.getSample(0, 0));

    buffer.clear();
    if (fifo.getNumReady() > 0)
    {
        auto readScope = fifo.read(1);
        if (readScope.blockSize1 > 0)
            lastResultForAudio = fifoBuffer[readScope.startIndex1];
    }

    // Map each tracked color to 3 outputs: X, Y, Area
    for (size_t i = 0; i < lastResultForAudio.size(); ++i)
    {
        int chX = (int)i * 3 + 0;
        int chY = (int)i * 3 + 1;
        int chA = (int)i * 3 + 2;
        if (chA < buffer.getNumChannels())
        {
            const auto& tpl = lastResultForAudio[i];
            float vx = std::get<0>(tpl);
            float vy = std::get<1>(tpl);
            float va = std::get<2>(tpl);
            for (int s = 0; s < buffer.getNumSamples(); ++s)
            {
                buffer.setSample(chX, s, vx);
                buffer.setSample(chY, s, vy);
                buffer.setSample(chA, s, va);
            }
        }
    }
}

std::vector<DynamicPinInfo> ColorTrackerModule::getDynamicOutputPins() const
{
    std::vector<DynamicPinInfo> pins;
    const juce::ScopedLock lock(colorListLock);
    for (size_t i = 0; i < trackedColors.size(); ++i)
    {
        pins.emplace_back(trackedColors[i].name + " X", (int)(i * 3 + 0), PinDataType::CV);
        pins.emplace_back(trackedColors[i].name + " Y", (int)(i * 3 + 1), PinDataType::CV);
        pins.emplace_back(trackedColors[i].name + " Area", (int)(i * 3 + 2), PinDataType::CV);
    }
    return pins;
}

#if defined(PRESET_CREATOR_UI)
ImVec2 ColorTrackerModule::getCustomNodeSize() const
{
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    const float widths[3] { 240.0f, 480.0f, 960.0f };
    return ImVec2(widths[level], 0.0f);
}

void ColorTrackerModule::drawParametersInNode(float itemWidth,
                                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                              const std::function<void()>& onModificationEnded)
{
    juce::ignoreUnused(isParamModulated, onModificationEnded);
    ImGui::PushItemWidth(itemWidth);

    if (ImGui::Button("Add Color...", ImVec2(itemWidth, 0)))
    {
        pickerTargetIndex.store(-1);
        isColorPickerActive.store(true);
    }

    if (isColorPickerActive.load())
    {
        ImGui::TextColored(ImVec4(1.f,1.f,0.f,1.f), "Click on the video preview to pick a color");
    }

    // Zoom controls (-/+) like PoseEstimator
    {
        int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
        level = juce::jlimit(0, 2, level);
        float buttonWidth = (itemWidth / 2.0f) - 4.0f;
        const bool atMin = (level <= 0);
        const bool atMax = (level >= 2);
        if (atMin) ImGui::BeginDisabled();
        if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
        {
            int newLevel = juce::jmax(0, level - 1);
            if (auto* p = apvts.getParameter("zoomLevel"))
                p->setValueNotifyingHost((float)newLevel / 2.0f);
        }
        if (atMin) ImGui::EndDisabled();
        ImGui::SameLine();
        if (atMax) ImGui::BeginDisabled();
        if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
        {
            int newLevel = juce::jmin(2, level + 1);
            if (auto* p = apvts.getParameter("zoomLevel"))
                p->setValueNotifyingHost((float)newLevel / 2.0f);
        }
        if (atMax) ImGui::EndDisabled();
    }

    // Render tracked color list with swatch, tolerance, and remove
    {
        const juce::ScopedLock lock(colorListLock);
        for (size_t i = 0; i < trackedColors.size(); )
        {
            ImGui::Separator();
            const auto& tc = trackedColors[i];
            ImVec4 imc(tc.displayColour.getFloatRed(), tc.displayColour.getFloatGreen(), tc.displayColour.getFloatBlue(), 1.0f);
            if (ImGui::ColorButton((tc.name + "##swatch" + juce::String((int)i)).toRawUTF8(), imc, ImGuiColorEditFlags_NoTooltip, ImVec2(20,20)))
            {
                pickerTargetIndex.store((int)i);
                isColorPickerActive.store(true);
            }
            ImGui::SameLine();
            ImGui::TextUnformatted((tc.name + "##label" + juce::String((int)i)).toRawUTF8());
            ImGui::SameLine();
            ImGui::SetNextItemWidth(120.0f);
            float tol = (float)tc.tolerance;
            if (ImGui::SliderFloat((juce::String("Tol##") + juce::String((int)i)).toRawUTF8(), &tol, 0.1f, 5.0f, "%.2fx"))
            {
                const_cast<TrackedColor&>(tc).tolerance = tol;
            }
            ImGui::SameLine();
            if (ImGui::SmallButton((juce::String("Remove##") + juce::String((int)i)).toRawUTF8()))
            {
                trackedColors.erase(trackedColors.begin() + (long long)i);
                continue; // don't increment i when erased
            }
            ++i;
        }
    }

    ImGui::PopItemWidth();
}

void ColorTrackerModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioInputPin("Source In", 0);
    // Outputs are dynamic; editor queries via getDynamicOutputPins
}
#endif




================================================================================
FILE: juce\\Source\\audio\\modules\\ContourDetectorModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/video.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>
#if defined(PRESET_CREATOR_UI)
#include <juce_gui_basics/juce_gui_basics.h>
#endif

struct ContourResult
{
    float area = 0.0f;
    float complexity = 0.0f;
    float aspectRatio = 0.0f;
};

class ContourDetectorModule : public ModuleProcessor, private juce::Thread
{
public:
    ContourDetectorModule();
    ~ContourDetectorModule() override;

    const juce::String getName() const override { return "contour_detector"; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }
    juce::Image getLatestFrame();

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;
    
    std::atomic<float>* sourceIdParam = nullptr;
    std::atomic<float>* thresholdParam = nullptr;
    juce::AudioParameterBool* noiseReductionParam = nullptr;
    std::atomic<float>* zoomLevelParam = nullptr;
    
    cv::Ptr<cv::BackgroundSubtractor> backSub;
    
    std::atomic<juce::uint32> currentSourceId { 0 };
    ContourResult lastResultForAudio;
    juce::AbstractFifo fifo { 16 };
    std::vector<ContourResult> fifoBuffer;
    
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
};




================================================================================
FILE: juce\\Source\\audio\\modules\\ContourDetectorModule.cpp
================================================================================


#include "ContourDetectorModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

juce::AudioProcessorValueTreeState::ParameterLayout ContourDetectorModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    params.push_back(std::make_unique<juce::AudioParameterFloat>("sourceId", "Source ID", 0.0f, 1000.0f, 0.0f));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("threshold", "Threshold", 0.0f, 255.0f, 128.0f));
    params.push_back(std::make_unique<juce::AudioParameterBool>("noiseReduction", "Noise Reduction", true));
    params.push_back(std::make_unique<juce::AudioParameterChoice>("zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    return { params.begin(), params.end() };
}

ContourDetectorModule::ContourDetectorModule()
    : ModuleProcessor(BusesProperties()
                      .withInput("Input", juce::AudioChannelSet::mono(), true)
                      .withOutput("Output", juce::AudioChannelSet::discreteChannels(3), true)),
      juce::Thread("Contour Detector Thread"),
      apvts(*this, nullptr, "ContourDetectorParams", createParameterLayout())
{
    sourceIdParam = apvts.getRawParameterValue("sourceId");
    thresholdParam = apvts.getRawParameterValue("threshold");
    noiseReductionParam = dynamic_cast<juce::AudioParameterBool*>(apvts.getParameter("noiseReduction"));
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    fifoBuffer.resize(16);
    backSub = cv::createBackgroundSubtractorMOG2();
}

ContourDetectorModule::~ContourDetectorModule()
{
    stopThread(5000);
}

void ContourDetectorModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::ignoreUnused(sampleRate, samplesPerBlock);
    startThread(juce::Thread::Priority::normal);
}

void ContourDetectorModule::releaseResources()
{
    signalThreadShouldExit();
    stopThread(5000);
}

void ContourDetectorModule::run()
{
    while (!threadShouldExit())
    {
        juce::uint32 sourceId = currentSourceId.load();
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(sourceId);
        if (!frame.empty())
        {
            cv::Mat fgMask;
            backSub->apply(frame, fgMask);
            cv::threshold(fgMask, fgMask, thresholdParam ? thresholdParam->load() : 128.0f, 255, cv::THRESH_BINARY);
            if (noiseReductionParam && noiseReductionParam->get())
            {
                cv::erode(fgMask, fgMask, cv::Mat(), cv::Point(-1,-1), 2);
                cv::dilate(fgMask, fgMask, cv::Mat(), cv::Point(-1,-1), 2);
            }

            std::vector<std::vector<cv::Point>> contours;
            cv::findContours(fgMask, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE);

            ContourResult result;
            if (!contours.empty())
            {
                double maxArea = 0.0;
                int maxIdx = -1;
                for (int i = 0; i < (int)contours.size(); ++i)
                {
                    double a = cv::contourArea(contours[i]);
                    if (a > maxArea) { maxArea = a; maxIdx = i; }
                }
                if (maxIdx >= 0)
                {
                    const auto& c = contours[(size_t)maxIdx];
                    result.area = juce::jlimit(0.0f, 1.0f, (float)(maxArea / (frame.cols * frame.rows)));
                    std::vector<cv::Point> approx;
                    cv::approxPolyDP(c, approx, 0.02 * cv::arcLength(c, true), true);
                    result.complexity = juce::jmap((float)approx.size(), 3.0f, 50.0f, 0.0f, 1.0f);
                    cv::Rect bbox = cv::boundingRect(c);
                    result.aspectRatio = bbox.height > 0 ? (float)bbox.width / (float)bbox.height : 0.0f;
                    // Draw
                    cv::drawContours(frame, contours, maxIdx, cv::Scalar(0,255,0), 2);
                    cv::rectangle(frame, bbox, cv::Scalar(255,0,0), 2);
                }
            }

            if (fifo.getFreeSpace() >= 1)
            {
                auto writeScope = fifo.write(1);
                if (writeScope.blockSize1 > 0)
                    fifoBuffer[writeScope.startIndex1] = result;
            }

            updateGuiFrame(frame);
        }
        
        wait(40);
    }
}

void ContourDetectorModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgra;
    cv::cvtColor(frame, bgra, cv::COLOR_BGR2BGRA);
    const juce::ScopedLock lock(imageLock);
    if (latestFrameForGui.isNull() || latestFrameForGui.getWidth() != bgra.cols || latestFrameForGui.getHeight() != bgra.rows)
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgra.cols, bgra.rows, true);
    juce::Image::BitmapData dest(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(dest.data, bgra.data, bgra.total() * bgra.elemSize());
}

juce::Image ContourDetectorModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void ContourDetectorModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    juce::ignoreUnused(midi);
    auto inputBuffer = getBusBuffer(buffer, true, 0);
    if (inputBuffer.getNumChannels() > 0 && inputBuffer.getNumSamples() > 0)
        currentSourceId.store((juce::uint32)inputBuffer.getSample(0, 0));

    buffer.clear();
    if (fifo.getNumReady() > 0)
    {
        auto readScope = fifo.read(1);
        if (readScope.blockSize1 > 0)
            lastResultForAudio = fifoBuffer[readScope.startIndex1];
    }

    const float values[3] { lastResultForAudio.area, lastResultForAudio.complexity, lastResultForAudio.aspectRatio };
    for (int ch = 0; ch < juce::jmin(3, buffer.getNumChannels()); ++ch)
        for (int s = 0; s < buffer.getNumSamples(); ++s)
            buffer.setSample(ch, s, values[ch]);
}

#if defined(PRESET_CREATOR_UI)
ImVec2 ContourDetectorModule::getCustomNodeSize() const
{
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    const float widths[3] { 240.0f, 480.0f, 960.0f };
    return ImVec2(widths[level], 0.0f);
}

void ContourDetectorModule::drawParametersInNode(float itemWidth,
                                                 const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                                 const std::function<void()>& onModificationEnded)
{
    juce::ignoreUnused(isParamModulated);
    ImGui::PushItemWidth(itemWidth);

    float th = thresholdParam ? thresholdParam->load() : 128.0f;
    if (ImGui::SliderFloat("Threshold", &th, 0.0f, 255.0f, "%.0f"))
    {
        if (auto* p = dynamic_cast<juce::AudioParameterFloat*>(apvts.getParameter("threshold")))
            *p = th;
        onModificationEnded();
    }
    bool nr = noiseReductionParam ? noiseReductionParam->get() : true;
    if (ImGui::Checkbox("Noise Reduction", &nr))
    {
        if (noiseReductionParam) *noiseReductionParam = nr;
        onModificationEnded();
    }

    // Zoom controls
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    float buttonWidth = (itemWidth / 2.0f) - 4.0f;
    const bool atMin = (level <= 0);
    const bool atMax = (level >= 2);
    if (atMin) ImGui::BeginDisabled();
    if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmax(0, level - 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMin) ImGui::EndDisabled();
    ImGui::SameLine();
    if (atMax) ImGui::BeginDisabled();
    if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmin(2, level + 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMax) ImGui::EndDisabled();

    ImGui::PopItemWidth();
}

void ContourDetectorModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioInputPin("Source In", 0);
    helpers.drawAudioOutputPin("Area", 0);
    helpers.drawAudioOutputPin("Complexity", 1);
    helpers.drawAudioOutputPin("Aspect Ratio", 2);
}
#endif




================================================================================
FILE: juce\\Source\\audio\\modules\\SemanticSegmentationModule.h
================================================================================


#pragma once

#include "ModuleProcessor.h"
#include <opencv2/core.hpp>
#include <opencv2/dnn.hpp>
#include <juce_core/juce_core.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_graphics/juce_graphics.h>
#if defined(PRESET_CREATOR_UI)
#include <juce_gui_basics/juce_gui_basics.h>
#endif

struct SegmentationResult
{
    float area = 0.0f;
    float centerX = 0.5f;
    float centerY = 0.5f;
    bool detected = false;
};

class SemanticSegmentationModule : public ModuleProcessor, private juce::Thread
{
public:
    SemanticSegmentationModule();
    ~SemanticSegmentationModule() override;

    const juce::String getName() const override { return "semantic_segmentation"; }
    
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi) override;
    
    juce::AudioProcessorValueTreeState& getAPVTS() override { return apvts; }
    juce::Image getLatestFrame();

#if defined(PRESET_CREATOR_UI)
    void drawParametersInNode(float itemWidth,
                              const std::function<bool(const juce::String& paramId)>& isParamModulated,
                              const std::function<void()>& onModificationEnded) override;
    void drawIoPins(const NodePinHelpers& helpers) override;
    ImVec2 getCustomNodeSize() const override;
#endif

private:
    void run() override;
    void updateGuiFrame(const cv::Mat& frame);
    void loadModel();
    
    static juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts;
    
    std::atomic<float>* sourceIdParam = nullptr;
    std::atomic<float>* zoomLevelParam = nullptr;
    juce::AudioParameterChoice* targetClassParam = nullptr;
    
    cv::dnn::Net net;
    bool modelLoaded = false;
    std::vector<std::string> classNames;
    std::vector<cv::Vec3b> classColors;
    
    std::atomic<juce::uint32> currentSourceId { 0 };
    SegmentationResult lastResultForAudio;
    juce::AbstractFifo fifo { 16 };
    std::vector<SegmentationResult> fifoBuffer;
    
    juce::Image latestFrameForGui;
    juce::CriticalSection imageLock;
};




================================================================================
FILE: juce\\Source\\audio\\modules\\SemanticSegmentationModule.cpp
================================================================================


#include "SemanticSegmentationModule.h"
#include "../../video/VideoFrameManager.h"
#include <opencv2/imgproc.hpp>
#include <fstream>

#if defined(PRESET_CREATOR_UI)
#include <imgui.h>
#endif

static constexpr int ENET_W = 1024;
static constexpr int ENET_H = 512;

juce::AudioProcessorValueTreeState::ParameterLayout SemanticSegmentationModule::createParameterLayout()
{
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;
    params.push_back(std::make_unique<juce::AudioParameterFloat>("sourceId", "Source ID", 0.0f, 1000.0f, 0.0f));
    params.push_back(std::make_unique<juce::AudioParameterChoice>("targetClass", "Target Class", juce::StringArray{ "person" }, 0));
    params.push_back(std::make_unique<juce::AudioParameterChoice>("zoomLevel", "Zoom Level", juce::StringArray{ "Small", "Normal", "Large" }, 1));
    return { params.begin(), params.end() };
}

SemanticSegmentationModule::SemanticSegmentationModule()
    : ModuleProcessor(BusesProperties()
                      .withInput("Input", juce::AudioChannelSet::mono(), true)
                      .withOutput("Output", juce::AudioChannelSet::discreteChannels(4), true)),
      juce::Thread("Semantic Segmentation Thread"),
      apvts(*this, nullptr, "SemanticSegmentationParams", createParameterLayout())
{
    sourceIdParam = apvts.getRawParameterValue("sourceId");
    zoomLevelParam = apvts.getRawParameterValue("zoomLevel");
    targetClassParam = dynamic_cast<juce::AudioParameterChoice*>(apvts.getParameter("targetClass"));
    fifoBuffer.resize(16);
    loadModel();
}

SemanticSegmentationModule::~SemanticSegmentationModule()
{
    stopThread(5000);
}

void SemanticSegmentationModule::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::ignoreUnused(sampleRate, samplesPerBlock);
    startThread(juce::Thread::Priority::normal);
}

void SemanticSegmentationModule::releaseResources()
{
    signalThreadShouldExit();
    stopThread(5000);
}

void SemanticSegmentationModule::loadModel()
{
    auto exeFile = juce::File::getSpecialLocation(juce::File::currentApplicationFile);
    auto appDir = exeFile.getParentDirectory();
    juce::File assetsDir = appDir.getChildFile("assets");

    // Try ENet Cityscapes first, then DeepLabV3 fallback
    juce::File enetOnnx  = assetsDir.getChildFile("enet-cityscapes-pytorch.onnx");
    juce::File enetNames = assetsDir.getChildFile("enet-classes.txt");
    juce::File dlOnnx    = assetsDir.getChildFile("deeplabv3.onnx");
    juce::File dlNames   = assetsDir.getChildFile("deeplabv3-classes.txt");

    juce::File chosenOnnx;
    juce::File chosenNames;

    if (enetOnnx.existsAsFile()) { chosenOnnx = enetOnnx; chosenNames = enetNames; }
    else if (dlOnnx.existsAsFile()) { chosenOnnx = dlOnnx; chosenNames = dlNames; }

    if (! chosenOnnx.existsAsFile())
    {
        juce::Logger::writeToLog("[Segmentation] No ONNX model found in assets (expected enet-cityscapes-pytorch.onnx or deeplabv3.onnx)");
        modelLoaded = false;
        return;
    }

    try
    {
        net = cv::dnn::readNet(chosenOnnx.getFullPathName().toStdString());
        net.setPreferableBackend(cv::dnn::DNN_BACKEND_OPENCV);
        net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);

        classNames.clear();
        if (chosenNames.existsAsFile())
        {
            std::ifstream ifs(chosenNames.getFullPathName().toStdString().c_str());
            std::string line;
            while (std::getline(ifs, line)) if (!line.empty()) classNames.push_back(line);
        }
        else
        {
            for (int i = 0; i < 256; ++i) classNames.push_back("class_" + std::to_string(i));
        }

        classColors.resize(classNames.size());
        for (size_t i = 0; i < classColors.size(); ++i)
            classColors[i] = cv::Vec3b((uchar)(i*53%255), (uchar)(i*97%255), (uchar)(i*193%255));
        modelLoaded = true;
        juce::Logger::writeToLog("[Segmentation] Loaded ONNX: " + chosenOnnx.getFileName());
    }
    catch (const cv::Exception& e)
    {
        juce::Logger::writeToLog("[Segmentation] OpenCV exception: " + juce::String(e.what()));
        modelLoaded = false;
    }
}

void SemanticSegmentationModule::run()
{
    while (!threadShouldExit())
    {
        cv::Mat frame = VideoFrameManager::getInstance().getFrame(currentSourceId.load());
        if (!frame.empty())
        {
            if (modelLoaded)
            {
                cv::Mat blob = cv::dnn::blobFromImage(frame, 1.0, cv::Size(ENET_W, ENET_H), cv::Scalar(), true, false);
                net.setInput(blob);
                cv::Mat out = net.forward(); // shape: 1 x C x H x W

                if (out.dims == 4)
                {
                    int C = out.size[1];
                    int H = out.size[2];
                    int W = out.size[3];

                    // Argmax across channels per pixel
                    cv::Mat classId(H, W, CV_8S);
                    for (int y = 0; y < H; ++y)
                    {
                        for (int x = 0; x < W; ++x)
                        {
                            int bestClass = 0;
                            float bestScore = -1e9f;
                            for (int c = 0; c < C; ++c)
                            {
                                float score = out.ptr<float>(0, c, y)[x];
                                if (score > bestScore) { bestScore = score; bestClass = c; }
                            }
                            classId.at<signed char>(y, x) = (signed char)bestClass;
                        }
                    }

                    // Target mask
                    int target = targetClassParam ? targetClassParam->getIndex() : 0;
                    cv::Mat mask(H, W, CV_8U);
                    for (int y = 0; y < H; ++y)
                        for (int x = 0; x < W; ++x)
                            mask.at<unsigned char>(y, x) = (unsigned char)(classId.at<signed char>(y, x) == target ? 255 : 0);

                    SegmentationResult result;
                    int pix = cv::countNonZero(mask);
                    if (pix > 0)
                    {
                        result.detected = true;
                        result.area = (float)pix / (float)(H * W);
                        cv::Moments m = cv::moments(mask, true);
                        result.centerX = (float)(m.m10 / m.m00) / (float)W;
                        result.centerY = (float)(m.m01 / m.m00) / (float)H;
                    }

                    if (fifo.getFreeSpace() >= 1)
                    {
                        auto writeScope = fifo.write(1);
                        if (writeScope.blockSize1 > 0)
                            fifoBuffer[writeScope.startIndex1] = result;
                    }

                    // Colorize for preview
                    cv::Mat color(H, W, CV_8UC3);
                    for (int y = 0; y < H; ++y)
                    {
                        for (int x = 0; x < W; ++x)
                        {
                            int cid = (int)classId.at<signed char>(y, x);
                            cv::Vec3b col = (cid >= 0 && cid < (int)classColors.size()) ? classColors[(size_t)cid] : cv::Vec3b(0,0,0);
                            color.at<cv::Vec3b>(y, x) = col;
                        }
                    }
                    cv::resize(color, color, frame.size(), 0, 0, cv::INTER_NEAREST);
                    cv::addWeighted(frame, 1.0, color, 0.4, 0.0, frame);
                }
            }

            // Always update preview with the latest frame (with or without overlay)
            updateGuiFrame(frame);
        }

        wait(100);
    }
}

void SemanticSegmentationModule::updateGuiFrame(const cv::Mat& frame)
{
    cv::Mat bgra;
    cv::cvtColor(frame, bgra, cv::COLOR_BGR2BGRA);
    const juce::ScopedLock lock(imageLock);
    if (latestFrameForGui.isNull() || latestFrameForGui.getWidth() != bgra.cols || latestFrameForGui.getHeight() != bgra.rows)
        latestFrameForGui = juce::Image(juce::Image::ARGB, bgra.cols, bgra.rows, true);
    juce::Image::BitmapData dest(latestFrameForGui, juce::Image::BitmapData::writeOnly);
    memcpy(dest.data, bgra.data, bgra.total() * bgra.elemSize());
}

juce::Image SemanticSegmentationModule::getLatestFrame()
{
    const juce::ScopedLock lock(imageLock);
    return latestFrameForGui.createCopy();
}

void SemanticSegmentationModule::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midi)
{
    juce::ignoreUnused(midi);
    auto inputBuffer = getBusBuffer(buffer, true, 0);
    if (inputBuffer.getNumChannels() > 0 && inputBuffer.getNumSamples() > 0)
        currentSourceId.store((juce::uint32)inputBuffer.getSample(0, 0));

    buffer.clear();
    if (fifo.getNumReady() > 0)
    {
        auto readScope = fifo.read(1);
        if (readScope.blockSize1 > 0)
            lastResultForAudio = fifoBuffer[readScope.startIndex1];
    }

    const float values[4] { lastResultForAudio.area, lastResultForAudio.centerX, lastResultForAudio.centerY, lastResultForAudio.detected ? 1.0f : 0.0f };
    for (int ch = 0; ch < juce::jmin(4, buffer.getNumChannels()); ++ch)
        for (int s = 0; s < buffer.getNumSamples(); ++s)
            buffer.setSample(ch, s, values[ch]);
}

#if defined(PRESET_CREATOR_UI)
ImVec2 SemanticSegmentationModule::getCustomNodeSize() const
{
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    const float widths[3] { 240.0f, 480.0f, 960.0f };
    return ImVec2(widths[level], 0.0f);
}

void SemanticSegmentationModule::drawParametersInNode(float itemWidth,
                                                      const std::function<bool(const juce::String& paramId)>& isParamModulated,
                                                      const std::function<void()>& onModificationEnded)
{
    juce::ignoreUnused(isParamModulated);
    ImGui::PushItemWidth(itemWidth);

    // Target class dropdown (populated from classNames if available)
    if (targetClassParam)
    {
        int currentIndex = targetClassParam->getIndex();
        const char* preview = (!classNames.empty() && juce::isPositiveAndBelow(currentIndex, (int)classNames.size()))
                                ? classNames[(size_t)currentIndex].c_str()
                                : "person";

        if (ImGui::BeginCombo("Target Class", preview))
        {
            if (classNames.empty())
            {
                const bool isSelected = (currentIndex == 0);
                if (ImGui::Selectable("person", isSelected))
                {
                    *targetClassParam = 0;
                    onModificationEnded();
                }
                if (isSelected) ImGui::SetItemDefaultFocus();
            }
            else
            {
                for (int i = 0; i < (int)classNames.size(); ++i)
                {
                    const bool isSelected = (currentIndex == i);
                    if (ImGui::Selectable(classNames[(size_t)i].c_str(), isSelected))
                    {
                        *targetClassParam = i;
                        onModificationEnded();
                    }
                    if (isSelected) ImGui::SetItemDefaultFocus();
                }
            }
            ImGui::EndCombo();
        }
    }

    // Zoom (-/+) controls, consistent with PoseEstimatorModule
    ImGui::Separator();
    int level = zoomLevelParam ? (int) zoomLevelParam->load() : 1;
    level = juce::jlimit(0, 2, level);
    float buttonWidth = (itemWidth / 2.0f) - 4.0f;
    const bool atMin = (level <= 0);
    const bool atMax = (level >= 2);
    if (atMin) ImGui::BeginDisabled();
    if (ImGui::Button("-", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmax(0, level - 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMin) ImGui::EndDisabled();
    ImGui::SameLine();
    if (atMax) ImGui::BeginDisabled();
    if (ImGui::Button("+", ImVec2(buttonWidth, 0)))
    {
        int newLevel = juce::jmin(2, level + 1);
        if (auto* p = apvts.getParameter("zoomLevel"))
            p->setValueNotifyingHost((float)newLevel / 2.0f);
        onModificationEnded();
    }
    if (atMax) ImGui::EndDisabled();

    ImGui::PopItemWidth();
}

void SemanticSegmentationModule::drawIoPins(const NodePinHelpers& helpers)
{
    helpers.drawAudioInputPin("Source In", 0);
    helpers.drawAudioOutputPin("Area", 0);
    helpers.drawAudioOutputPin("Center X", 1);
    helpers.drawAudioOutputPin("Center Y", 2);
    helpers.drawAudioOutputPin("Gate", 3);
}
#endif




================================================================================
FILE: juce\\CMakeLists.txt
================================================================================


cmake_minimum_required(VERSION 3.22)
project(ColliderAudioEngine VERSION 0.1.0)

# --- TTS Integration (Piper) ---

# 1. Set paths to pre-built Piper and ONNX Runtime
set(PIPER_DIR "${CMAKE_SOURCE_DIR}/../vendor/piper/piper" CACHE PATH "Path to Piper TTS")
set(ONNXRUNTIME_DIR "${CMAKE_SOURCE_DIR}/../vendor/onnxruntime" CACHE PATH "Path to ONNX Runtime")

if(NOT EXISTS "${PIPER_DIR}")
    message(WARNING "Piper TTS not found at ${PIPER_DIR}. TTS features will be limited.")
endif()

if(NOT EXISTS "${ONNXRUNTIME_DIR}")
    message(WARNING "ONNX Runtime not found at ${ONNXRUNTIME_DIR}. TTS features will be limited.")
endif()

# 2. Add SoundTouch library
set(SOUNDTOUCH_SOURCE_DIR "${CMAKE_SOURCE_DIR}/../soundtouch/source")
add_library(soundtouch STATIC
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/AAFilter.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/BPMDetect.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/FIFOSampleBuffer.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/FIRFilter.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/InterpolateCubic.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/InterpolateLinear.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/InterpolateShannon.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/PeakFinder.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/RateTransposer.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/SoundTouch.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/TDStretch.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/cpu_detect_x86.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/mmx_optimized.cpp
    ${SOUNDTOUCH_SOURCE_DIR}/SoundTouch/sse_optimized.cpp
)
target_include_directories(soundtouch PUBLIC 
    ${CMAKE_SOURCE_DIR}/../soundtouch/include
    ${CMAKE_SOURCE_DIR}/../soundtouch/source/SoundTouch
)

set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

include(FetchContent)

# ==============================================================================
# Third-Party Dependencies (Fetch Only)
# ==============================================================================

FetchContent_Declare(JUCE
    GIT_REPOSITORY https://github.com/juce-framework/JUCE.git
    GIT_TAG 7.0.9
)
set(JUCE_BUILD_EXAMPLES OFF CACHE BOOL "" FORCE)
set(JUCE_BUILD_EXTRAS OFF CACHE BOOL "" FORCE)
FetchContent_MakeAvailable(JUCE)

FetchContent_Declare(imgui_fc
    GIT_REPOSITORY https://github.com/ocornut/imgui.git
    GIT_TAG v1.92.0
)
FetchContent_MakeAvailable(imgui_fc)

# imnodes uses find_package(imgui) in its CMake; build as sources instead
FetchContent_Declare(imnodes_fc
    GIT_REPOSITORY https://github.com/Nelarius/imnodes.git
    GIT_TAG b2ec254ce576ac3d42dfb7aef61deadbff8e7211
)
FetchContent_GetProperties(imnodes_fc)
if(NOT imnodes_fc_POPULATED)
  FetchContent_Populate(imnodes_fc)
endif()

# imgui_juce backend (dedicated JUCE bridge for ImGui)
FetchContent_Declare(imgui_juce_fc
    GIT_REPOSITORY https://github.com/Krasjet/imgui_juce.git
    GIT_TAG master
)
FetchContent_MakeAvailable(imgui_juce_fc)

# --------------------------------------------------------------
# Box2D (2D physics engine for physics-based audio module)
# --------------------------------------------------------------
FetchContent_Declare(box2d_fc
    GIT_REPOSITORY https://github.com/erincatto/box2d.git
    GIT_TAG v2.4.1
)
set(BOX2D_BUILD_UNIT_TESTS OFF CACHE BOOL "" FORCE)
set(BOX2D_BUILD_TESTBED OFF CACHE BOOL "" FORCE)
set(BOX2D_BUILD_DOCS OFF CACHE BOOL "" FORCE)
FetchContent_MakeAvailable(box2d_fc)

# --------------------------------------------------------------
# GLM (OpenGL Mathematics library for 3D vector/matrix math)
# --------------------------------------------------------------
FetchContent_Declare(
  glm
  GIT_REPOSITORY https://github.com/g-truc/glm.git
  GIT_TAG        1.0.1 # Latest stable version
)
FetchContent_MakeAvailable(glm)

# --------------------------------------------------------------
# nlohmann/json (required by tinygltf)
# --------------------------------------------------------------
FetchContent_Declare(
  nlohmann_json
  GIT_REPOSITORY https://github.com/nlohmann/json.git
  GIT_TAG        v3.11.3 # A recent stable version
)
FetchContent_MakeAvailable(nlohmann_json)

# --------------------------------------------------------------
# tinygltf (glTF 2.0 file loader for animation system)
# --------------------------------------------------------------
FetchContent_Declare(
  tinygltf
  GIT_REPOSITORY https://github.com/syoyo/tinygltf.git
  GIT_TAG        v2.8.20 # A recent stable version
)
FetchContent_MakeAvailable(tinygltf)

# --------------------------------------------------------------
# ufbx (FBX file loader for animation system)
# --------------------------------------------------------------
FetchContent_Declare(
  ufbx
  GIT_REPOSITORY https://github.com/ufbx/ufbx.git
  GIT_TAG        v0.10.0 # A recent stable version of ufbx
)
FetchContent_MakeAvailable(ufbx)

# Get the path to the downloaded ufbx source code
FetchContent_GetProperties(ufbx SOURCE_DIR ufbx_SOURCE_DIR)

# Create a dedicated static library target for ufbx (single-header library needs separate compilation unit)
add_library(ufbx_static STATIC ${ufbx_SOURCE_DIR}/ufbx.c)
target_include_directories(ufbx_static PUBLIC ${ufbx_SOURCE_DIR})

# --------------------------------------------------------------
# OpenCV (Computer Vision Library - used for Preset Creator UI)
# --------------------------------------------------------------

# Add /FS flag for MSVC BEFORE declaring OpenCV to fix parallel compilation PDB access issues
if(MSVC)
    # Save current flags
    set(SAVED_CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS}")
    set(SAVED_CMAKE_C_FLAGS "${CMAKE_C_FLAGS}")
    
    # Add /FS flag to init variables (used by subprojects)
    set(CMAKE_CXX_FLAGS_INIT "${CMAKE_CXX_FLAGS_INIT} /FS" CACHE STRING "" FORCE)
    set(CMAKE_C_FLAGS_INIT "${CMAKE_C_FLAGS_INIT} /FS" CACHE STRING "" FORCE)
    
    # Also add to current flags
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /FS")
    set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} /FS")
endif()

FetchContent_Declare(
  opencv
  GIT_REPOSITORY https://github.com/opencv/opencv.git
  GIT_TAG        4.9.0 # Pin to a specific, stable version
)

# Configure the OpenCV build
# Disable features we don't need to speed up the build and reduce size
set(BUILD_SHARED_LIBS OFF CACHE BOOL "" FORCE) # Build as a static library
set(BUILD_opencv_apps OFF CACHE BOOL "" FORCE)
set(BUILD_TESTS OFF CACHE BOOL "" FORCE)
set(BUILD_PERF_TESTS OFF CACHE BOOL "" FORCE)
set(BUILD_EXAMPLES OFF CACHE BOOL "" FORCE)
set(WITH_CUDA ON CACHE BOOL "" FORCE)
set(OPENCV_DNN_CUDA ON CACHE BOOL "" FORCE)
set(CUDA_TOOLKIT_ROOT_DIR "C:/CUDA128" CACHE PATH "" FORCE)
set(CUDA_ARCH_BIN "10.0" CACHE STRING "" FORCE)
set(CUDA_ARCH_PTX "10.0" CACHE STRING "" FORCE)
set(BUILD_opencv_world ON CACHE BOOL "" FORCE) # Combine into a single library
set(ENABLE_PRECOMPILED_HEADERS OFF CACHE BOOL "" FORCE) # Disable PCH to avoid PDB issues

# === EXPLICITLY ENABLE MODULES FOR ADVANCED FEATURES ===
# These modules are required for computer vision features:
# - dnn: Deep Neural Networks (for Pose Estimation / YOLO / Object Detection)
# - tracking: Object tracking algorithms
# - features2d: Feature detection and matching
# - video: Dense optical flow and motion analysis
set(BUILD_opencv_dnn ON CACHE BOOL "" FORCE)
set(BUILD_opencv_tracking ON CACHE BOOL "" FORCE)
set(BUILD_opencv_features2d ON CACHE BOOL "" FORCE)
set(BUILD_opencv_video ON CACHE BOOL "" FORCE)
set(OPENCV_DNN_CAFFE ON CACHE BOOL "" FORCE)  # Enable Caffe model support for DNN

# === CRITICAL FIX ===
# Force OpenCV to use the dynamic runtime library (/MD), matching JUCE's default.
# This prevents runtime library mismatch errors (LNK2005, LNK2038).
set(BUILD_WITH_STATIC_CRT OFF CACHE BOOL "" FORCE)

FetchContent_MakeAvailable(opencv)

# Get the OpenCV build directory for generated headers
FetchContent_GetProperties(opencv)
if(NOT opencv_POPULATED)
    FetchContent_Populate(opencv)
endif()
set(OPENCV_BUILD_DIR "${CMAKE_BINARY_DIR}/_deps/opencv-build")

# ==============================================================================
# AUTO-GENERATE opencv_modules.hpp
# ==============================================================================
# OpenCV's build system should generate this file, but sometimes it doesn't
# create it during the initial configuration. This ensures it always exists.
set(OPENCV_MODULES_HPP "${OPENCV_BUILD_DIR}/opencv2/opencv_modules.hpp")
if(NOT EXISTS "${OPENCV_MODULES_HPP}")
    message(STATUS "Generating missing opencv_modules.hpp...")
    file(MAKE_DIRECTORY "${OPENCV_BUILD_DIR}/opencv2")
    file(WRITE "${OPENCV_MODULES_HPP}"
"/*
 * This file is auto-generated. Do not edit!
 */

#ifndef OPENCV_MODULES_HPP
#define OPENCV_MODULES_HPP

#define HAVE_OPENCV_CALIB3D
#define HAVE_OPENCV_CORE
#define HAVE_OPENCV_DNN
#define HAVE_OPENCV_FEATURES2D
#define HAVE_OPENCV_FLANN
#define HAVE_OPENCV_GAPI
#define HAVE_OPENCV_HIGHGUI
#define HAVE_OPENCV_IMGCODECS
#define HAVE_OPENCV_IMGPROC
#define HAVE_OPENCV_ML
#define HAVE_OPENCV_OBJDETECT
#define HAVE_OPENCV_PHOTO
#define HAVE_OPENCV_STITCHING
#define HAVE_OPENCV_VIDEO
#define HAVE_OPENCV_VIDEOIO
#define HAVE_OPENCV_WORLD

#endif
")
    message(STATUS "Generated opencv_modules.hpp at ${OPENCV_MODULES_HPP}")
endif()
# ==============================================================================

# Restore flags after OpenCV if needed
if(MSVC)
    set(CMAKE_CXX_FLAGS "${SAVED_CMAKE_CXX_FLAGS} /FS")
    set(CMAKE_C_FLAGS "${SAVED_CMAKE_C_FLAGS} /FS")
endif()

# --------------------------------------------------------------
# Rubber Band (optional, real-time timestretcher/pitch-shifter)
# --------------------------------------------------------------
set(USE_RUBBERBAND ON CACHE BOOL "Enable Rubber Band time/pitch processing")
if (USE_RUBBERBAND)
  FetchContent_Declare(rubberband_fc
    GIT_REPOSITORY https://github.com/breakfastquay/rubberband.git
    GIT_TAG v3.3.0
  )
  FetchContent_MakeAvailable(rubberband_fc)
  # Build from single-file amalgamation to avoid external link issues
  # Use official amalgamated single-file build (works cross-platform)
  add_library(rubberband_single STATIC
    ${rubberband_fc_SOURCE_DIR}/single/RubberBandSingle.cpp
  )
  target_include_directories(rubberband_single PUBLIC
    ${rubberband_fc_SOURCE_DIR}
    ${rubberband_fc_SOURCE_DIR}/single
  )
  target_compile_definitions(rubberband_single PUBLIC
    NOMINMAX
    _USE_MATH_DEFINES
    RUBBERBAND_USE_R3=1
    RUBBERBAND_BUILD_FFT=KISSFFT
    RUBBERBAND_BUILD_RESAMPLER=NONE
  )
  set(RUBBERBAND_TARGET rubberband_single)
  set(RUBBERBAND_INCLUDE_DIR "${rubberband_fc_SOURCE_DIR}")
endif()

# ==============================================================================
# Main Engine App Target (Unchanged)
# ==============================================================================
juce_add_gui_app(ColliderApp
    PRODUCT_NAME "Collider Audio Engine"
    VERSION "0.1.0"
    COMPANY_NAME "Collider"
)

target_sources(ColliderApp PRIVATE
    Source/main.cpp
    Source/app/MainApplication.cpp
    Source/app/MainApplication.h
    Source/ui/MainComponent.cpp
    Source/ui/MainComponent.h
    Source/ui/TestHarnessComponent.cpp
    Source/ui/TestHarnessComponent.h
    Source/ui/VisualiserComponent.cpp
    Source/ui/VisualiserComponent.h
    Source/ui/DebugInfo.h
    Source/audio/AudioEngine.h
    Source/audio/AudioEngine.cpp
    Source/audio/MidiDeviceManager.h
    Source/audio/MidiDeviceManager.cpp
    Source/audio/voices/SampleVoiceProcessor.h
    Source/audio/voices/SampleVoiceProcessor.cpp
    Source/audio/voices/SynthVoiceProcessor.h
    Source/audio/voices/SynthVoiceProcessor.cpp
    Source/audio/voices/NoiseVoiceProcessor.h
    Source/audio/voices/NoiseVoiceProcessor.cpp
    Source/audio/voices/ModularVoice.h
    Source/audio/graph/VoiceProcessor.h
    Source/audio/graph/VoiceProcessor.cpp
    Source/audio/graph/ModularSynthProcessor.h
    Source/audio/graph/ModularSynthProcessor.cpp
    Source/audio/fx/FXChain.h
    Source/audio/fx/GainProcessor.h
    Source/audio/fx/GainProcessor.cpp
    Source/audio/assets/SampleBank.h
    Source/audio/assets/SampleBank.cpp
    Source/audio/modules/ModuleProcessor.h
    Source/audio/modules/ModuleProcessor.cpp
    Source/audio/modules/AudioInputModuleProcessor.h
    Source/audio/modules/AudioInputModuleProcessor.cpp
    Source/audio/modules/VCOModuleProcessor.h
    Source/audio/modules/VCOModuleProcessor.cpp
    Source/audio/modules/VCFModuleProcessor.h
    Source/audio/modules/VCFModuleProcessor.cpp
    Source/audio/modules/VCAModuleProcessor.h
    Source/audio/modules/VCAModuleProcessor.cpp
    Source/audio/modules/NoiseModuleProcessor.h
    Source/audio/modules/NoiseModuleProcessor.cpp
    Source/audio/modules/LFOModuleProcessor.h
    Source/audio/modules/LFOModuleProcessor.cpp
    Source/audio/modules/ADSRModuleProcessor.h
    Source/audio/modules/ADSRModuleProcessor.cpp
    Source/audio/modules/MixerModuleProcessor.h
    Source/audio/modules/MixerModuleProcessor.cpp
    Source/audio/modules/CVMixerModuleProcessor.h
    Source/audio/modules/CVMixerModuleProcessor.cpp
    Source/audio/modules/DelayModuleProcessor.h
    Source/audio/modules/DelayModuleProcessor.cpp
    Source/audio/modules/ReverbModuleProcessor.h
    Source/audio/modules/ReverbModuleProcessor.cpp
    Source/audio/modules/SAndHModuleProcessor.h
    Source/audio/modules/SAndHModuleProcessor.cpp
    Source/audio/modules/AttenuverterModuleProcessor.h
    Source/audio/modules/AttenuverterModuleProcessor.cpp
    Source/audio/modules/ScopeModuleProcessor.h
    Source/audio/modules/ScopeModuleProcessor.cpp
    Source/audio/modules/StepSequencerModuleProcessor.h
    Source/audio/modules/StepSequencerModuleProcessor.cpp
    Source/audio/modules/MultiSequencerModuleProcessor.h
    Source/audio/modules/MultiSequencerModuleProcessor.cpp
    Source/audio/modules/LagProcessorModuleProcessor.h
    Source/audio/modules/LagProcessorModuleProcessor.cpp
    Source/audio/modules/DeCrackleModuleProcessor.h
    Source/audio/modules/DeCrackleModuleProcessor.cpp
    Source/audio/modules/GraphicEQModuleProcessor.h
    Source/audio/modules/GraphicEQModuleProcessor.cpp
    Source/audio/modules/FrequencyGraphModuleProcessor.h
    Source/audio/modules/FrequencyGraphModuleProcessor.cpp
    Source/audio/modules/ChorusModuleProcessor.h
    Source/audio/modules/ChorusModuleProcessor.cpp
    Source/audio/modules/PhaserModuleProcessor.h
    Source/audio/modules/PhaserModuleProcessor.cpp
    Source/audio/modules/CompressorModuleProcessor.h
    Source/audio/modules/CompressorModuleProcessor.cpp
    Source/audio/modules/RecordModuleProcessor.h
    Source/audio/modules/RecordModuleProcessor.cpp
    Source/audio/modules/CommentModuleProcessor.h
    Source/audio/modules/CommentModuleProcessor.cpp
    Source/audio/modules/LimiterModuleProcessor.h
    Source/audio/modules/LimiterModuleProcessor.cpp
    Source/audio/modules/GateModuleProcessor.h
    Source/audio/modules/GateModuleProcessor.cpp
    Source/audio/modules/DriveModuleProcessor.h
    Source/audio/modules/DriveModuleProcessor.cpp
    Source/audio/modules/MathModuleProcessor.h
    Source/audio/modules/MathModuleProcessor.cpp
    Source/audio/modules/MapRangeModuleProcessor.h
    Source/audio/modules/MapRangeModuleProcessor.cpp
    Source/audio/modules/ComparatorModuleProcessor.h
    Source/audio/modules/ComparatorModuleProcessor.cpp
    Source/audio/modules/RandomModuleProcessor.h
    Source/audio/modules/RandomModuleProcessor.cpp
    Source/audio/modules/RateModuleProcessor.h
    Source/audio/modules/RateModuleProcessor.cpp
    Source/audio/modules/QuantizerModuleProcessor.h
    Source/audio/modules/QuantizerModuleProcessor.cpp
    Source/audio/modules/SequentialSwitchModuleProcessor.h
    Source/audio/modules/SequentialSwitchModuleProcessor.cpp
    Source/audio/modules/LogicModuleProcessor.h
    Source/audio/modules/LogicModuleProcessor.cpp
    Source/audio/modules/ClockDividerModuleProcessor.h
    Source/audio/modules/ClockDividerModuleProcessor.cpp
    Source/audio/modules/WaveshaperModuleProcessor.h
    Source/audio/modules/WaveshaperModuleProcessor.cpp
    Source/audio/modules/MultiBandShaperModuleProcessor.h
    Source/audio/modules/MultiBandShaperModuleProcessor.cpp
    Source/audio/modules/GranulatorModuleProcessor.h
    Source/audio/modules/GranulatorModuleProcessor.cpp
    Source/audio/modules/HarmonicShaperModuleProcessor.h
    Source/audio/modules/HarmonicShaperModuleProcessor.cpp
    Source/audio/modules/ValueModuleProcessor.h
    Source/audio/modules/ValueModuleProcessor.cpp
    Source/audio/modules/TimePitchModuleProcessor.h
    Source/audio/modules/TimePitchModuleProcessor.cpp
    Source/audio/modules/MIDIPlayerModuleProcessor.h
    Source/audio/modules/MIDIPlayerModuleProcessor.cpp
        Source/audio/modules/TrackMixerModuleProcessor.h
        Source/audio/modules/TrackMixerModuleProcessor.cpp
    Source/audio/modules/PolyVCOModuleProcessor.h
    Source/audio/modules/PolyVCOModuleProcessor.cpp
        Source/audio/modules/DebugModuleProcessor.h
        Source/audio/modules/DebugModuleProcessor.cpp
        Source/audio/modules/CommentModuleProcessor.h
        Source/audio/modules/CommentModuleProcessor.cpp
        Source/audio/modules/InputDebugModuleProcessor.h
        Source/audio/modules/InputDebugModuleProcessor.cpp
    Source/audio/modules/TTSPerformerModuleProcessor.h
    Source/audio/modules/TTSPerformerModuleProcessor.cpp
    Source/audio/modules/TimingData.h
    Source/audio/modules/SampleLoaderModuleProcessor.h
    Source/audio/modules/SampleLoaderModuleProcessor.cpp
    Source/audio/modules/FunctionGeneratorModuleProcessor.h
    Source/audio/modules/FunctionGeneratorModuleProcessor.cpp
    Source/audio/modules/BestPracticeNodeProcessor.h
    Source/audio/modules/BestPracticeNodeProcessor.cpp
    Source/audio/modules/VocalTractFilterModuleProcessor.h
    Source/audio/modules/VocalTractFilterModuleProcessor.cpp
    Source/audio/modules/VstHostModuleProcessor.h
    Source/audio/modules/VstHostModuleProcessor.cpp
    Source/audio/modules/ShapingOscillatorModuleProcessor.h
    Source/audio/modules/ShapingOscillatorModuleProcessor.cpp
    Source/audio/modules/InletModuleProcessor.h
    Source/audio/modules/InletModuleProcessor.cpp
    Source/audio/modules/OutletModuleProcessor.h
    Source/audio/modules/OutletModuleProcessor.cpp
    Source/audio/modules/MetaModuleProcessor.h
    Source/audio/modules/MetaModuleProcessor.cpp
    Source/audio/modules/SnapshotSequencerModuleProcessor.h
    Source/audio/modules/SnapshotSequencerModuleProcessor.cpp
    Source/audio/modules/MIDICVModuleProcessor.h
    Source/audio/modules/MIDICVModuleProcessor.cpp
    Source/audio/modules/MIDIFadersModuleProcessor.h
    Source/audio/modules/MIDIFadersModuleProcessor.cpp
    Source/audio/modules/MIDIKnobsModuleProcessor.h
    Source/audio/modules/MIDIKnobsModuleProcessor.cpp
    Source/audio/modules/MIDIButtonsModuleProcessor.h
    Source/audio/modules/MIDIButtonsModuleProcessor.cpp
    Source/audio/modules/MIDIJogWheelModuleProcessor.h
    Source/audio/modules/MIDIJogWheelModuleProcessor.cpp
    Source/audio/modules/MIDIPadModuleProcessor.h
    Source/audio/modules/MIDIPadModuleProcessor.cpp
    Source/audio/modules/MidiLoggerModuleProcessor.h
    Source/audio/modules/MidiLoggerModuleProcessor.cpp
    Source/audio/modules/TempoClockModuleProcessor.h
    Source/audio/modules/TempoClockModuleProcessor.cpp
    Source/audio/modules/PhysicsModuleProcessor.h
    Source/audio/modules/PhysicsModuleProcessor.cpp
    Source/audio/modules/StrokeSequencerModuleProcessor.h
    Source/audio/modules/StrokeSequencerModuleProcessor.cpp
    Source/audio/modules/TapTempo.h
    Source/audio/modules/TapTempo.cpp
    Source/audio/modules/BPMMonitorModuleProcessor.h
    Source/audio/modules/BPMMonitorModuleProcessor.cpp
    Source/audio/modules/AnimationModuleProcessor.h
    Source/audio/modules/AnimationModuleProcessor.cpp
    Source/video/VideoFrameManager.h
    Source/audio/modules/WebcamLoaderModule.h
    Source/audio/modules/WebcamLoaderModule.cpp
    Source/audio/modules/VideoFileLoaderModule.h
    Source/audio/modules/VideoFileLoaderModule.cpp
    Source/audio/modules/MovementDetectorModule.h
    Source/audio/modules/MovementDetectorModule.cpp
    Source/audio/modules/HumanDetectorModule.h
    Source/audio/modules/HumanDetectorModule.cpp
    Source/audio/modules/PoseEstimatorModule.h
    Source/audio/modules/PoseEstimatorModule.cpp
    Source/audio/modules/HandTrackerModule.h
    Source/audio/modules/HandTrackerModule.cpp
    Source/audio/modules/FaceTrackerModule.h
    Source/audio/modules/FaceTrackerModule.cpp
    Source/audio/modules/ObjectDetectorModule.h
    Source/audio/modules/ObjectDetectorModule.cpp
    Source/audio/modules/ColorTrackerModule.h
    Source/audio/modules/ColorTrackerModule.cpp
    Source/audio/modules/ContourDetectorModule.h
    Source/audio/modules/ContourDetectorModule.cpp
    Source/audio/modules/SemanticSegmentationModule.h
    Source/audio/modules/SemanticSegmentationModule.cpp
    Source/animation/AnimationData.h
    Source/animation/RawAnimationData.h
    Source/animation/RawAnimationData.cpp
    Source/animation/AnimationBinder.h
    Source/animation/AnimationBinder.cpp
    Source/animation/Animator.h
    Source/animation/Animator.cpp
    Source/animation/AnimationFileLoader.h
    Source/animation/AnimationFileLoader.cpp
    Source/animation/GltfLoader.h
    Source/animation/GltfLoader.cpp
    Source/animation/FbxLoader.h
    Source/animation/FbxLoader.cpp
    Source/animation/AnimationRenderer.h
    Source/animation/AnimationRenderer.cpp
    Source/ipc/IpcServer.cpp
    Source/ipc/IpcServer.h
    Source/ipc/OscClient.h
    Source/ipc/CommandBus.cpp
    Source/ipc/CommandBus.h
    Source/audio/utils/VoiceDeletionUtils.h
    Source/audio/dsp/TimePitchProcessor.h
    Source/utils/RtLogger.h
    Source/utils/RtLogger.cpp
)

target_compile_definitions(ColliderApp PRIVATE
    JUCE_APPLICATION_NAME_STRING="$<TARGET_PROPERTY:ColliderApp,PRODUCT_NAME>"
    JUCE_APPLICATION_VERSION_STRING="$<TARGET_PROPERTY:ColliderApp,VERSION>"
    JUCE_WEB_BROWSER=0 JUCE_USE_CURL=0
    JUCE_PLUGINHOST_VST3=1
    $<$<BOOL:${USE_RUBBERBAND}>:USE_RUBBERBAND=1>
    $<$<NOT:$<BOOL:${USE_RUBBERBAND}>>:USE_RUBBERBAND=0>
)

target_link_libraries(ColliderApp PRIVATE
    juce::juce_gui_extra
    juce::juce_opengl
    juce::juce_audio_processors
    juce::juce_audio_utils
    juce::juce_audio_formats
    juce::juce_dsp
    juce::juce_osc
    soundtouch
    box2d
    glm::glm
    tinygltf
    ufbx_static
    opencv_world
    $<$<BOOL:${USE_RUBBERBAND}>:${RUBBERBAND_TARGET}>
    # Piper TTS libraries (pre-built)
    ${ONNXRUNTIME_DIR}/lib/onnxruntime.lib
)

# Add include directories for ColliderApp
target_include_directories(ColliderApp PRIVATE
    ${PIPER_DIR}
    ${ONNXRUNTIME_DIR}/include
    ${CMAKE_SOURCE_DIR}/../vendor/openvino_toolkit_windows_2025.3.0.19807.44526285f24_x86_64/samples/cpp/thirdparty/nlohmann_json/single_include
    ${CMAKE_SOURCE_DIR}/../soundtouch/include
    ${CMAKE_SOURCE_DIR}/../soundtouch/source/SoundTouch
    ${ufbx_SOURCE_DIR}
    # OpenCV include directories - source and generated headers
    ${opencv_SOURCE_DIR}/include
    ${opencv_SOURCE_DIR}/modules/core/include
    ${opencv_SOURCE_DIR}/modules/imgproc/include
    ${opencv_SOURCE_DIR}/modules/imgcodecs/include
    ${opencv_SOURCE_DIR}/modules/videoio/include
    ${opencv_SOURCE_DIR}/modules/highgui/include
    ${opencv_SOURCE_DIR}/modules/video/include
    ${opencv_SOURCE_DIR}/modules/objdetect/include
    ${opencv_SOURCE_DIR}/modules/features2d/include
    ${opencv_SOURCE_DIR}/modules/calib3d/include
    ${opencv_SOURCE_DIR}/modules/dnn/include              # For DNN headers (dnn.hpp)
    ${OPENCV_BUILD_DIR}
    ${OPENCV_BUILD_DIR}/modules/world
    $<$<BOOL:${USE_RUBBERBAND}>:${RUBBERBAND_INCLUDE_DIR}>
)

# ==============================================================================
# Preset Creator App Target (Final Corrected Version)
# ==============================================================================

juce_add_gui_app(PresetCreatorApp
    PRODUCT_NAME "Preset Creator"
    VERSION "0.1.0"
    COMPANY_NAME "Collider"
)

target_sources(PresetCreatorApp PRIVATE
    # Your application sources
    Source/preset_creator/PresetCreatorMain.cpp
    Source/preset_creator/PinDatabase.h
    Source/preset_creator/PinDatabase.cpp
    Source/preset_creator/ImGuiNodeEditorComponent.h
    Source/preset_creator/ImGuiNodeEditorComponent.cpp
    Source/preset_creator/PresetCreatorComponent.h
    Source/preset_creator/PresetCreatorComponent.cpp
    Source/preset_creator/ControllerPresetManager.h
    Source/preset_creator/ControllerPresetManager.cpp

    # Add ImGui, imnodes, and the backend DIRECTLY as source files
    ${imgui_fc_SOURCE_DIR}/imgui.cpp
    ${imgui_fc_SOURCE_DIR}/imgui_draw.cpp
    ${imgui_fc_SOURCE_DIR}/imgui_tables.cpp
    ${imgui_fc_SOURCE_DIR}/imgui_widgets.cpp
    ${imgui_fc_SOURCE_DIR}/backends/imgui_impl_opengl2.cpp
    ${imnodes_fc_SOURCE_DIR}/imnodes.cpp

    # Your other reused engine modules
    Source/audio/MidiDeviceManager.h
    Source/audio/MidiDeviceManager.cpp
    Source/audio/graph/ModularSynthProcessor.h
    Source/audio/graph/ModularSynthProcessor.cpp
    Source/audio/modules/ModuleProcessor.h
    Source/audio/modules/ModuleProcessor.cpp
    Source/audio/modules/AudioInputModuleProcessor.h
    Source/audio/modules/AudioInputModuleProcessor.cpp
    Source/audio/modules/VCOModuleProcessor.h
    Source/audio/modules/VCOModuleProcessor.cpp
    Source/audio/modules/VCFModuleProcessor.h
    Source/audio/modules/VCFModuleProcessor.cpp
    Source/audio/modules/VCAModuleProcessor.h
    Source/audio/modules/VCAModuleProcessor.cpp
    Source/audio/modules/NoiseModuleProcessor.h
    Source/audio/modules/NoiseModuleProcessor.cpp
    Source/audio/modules/LFOModuleProcessor.h
    Source/audio/modules/LFOModuleProcessor.cpp
    Source/audio/modules/ADSRModuleProcessor.h
    Source/audio/modules/ADSRModuleProcessor.cpp
    Source/audio/modules/MixerModuleProcessor.h
    Source/audio/modules/MixerModuleProcessor.cpp
    Source/audio/modules/CVMixerModuleProcessor.h
    Source/audio/modules/CVMixerModuleProcessor.cpp
    Source/audio/modules/DelayModuleProcessor.h
    Source/audio/modules/DelayModuleProcessor.cpp
    Source/audio/modules/ReverbModuleProcessor.h
    Source/audio/modules/ReverbModuleProcessor.cpp
    Source/audio/modules/SAndHModuleProcessor.h
    Source/audio/modules/SAndHModuleProcessor.cpp
    Source/audio/modules/AttenuverterModuleProcessor.h
    Source/audio/modules/AttenuverterModuleProcessor.cpp
    Source/audio/modules/ScopeModuleProcessor.h
    Source/audio/modules/ScopeModuleProcessor.cpp
    Source/audio/modules/StepSequencerModuleProcessor.h
    Source/audio/modules/StepSequencerModuleProcessor.cpp
    Source/audio/modules/MathModuleProcessor.h
    Source/audio/modules/MathModuleProcessor.cpp
    Source/audio/modules/MapRangeModuleProcessor.h
    Source/audio/modules/MapRangeModuleProcessor.cpp
    Source/audio/modules/ComparatorModuleProcessor.h
    Source/audio/modules/ComparatorModuleProcessor.cpp
    Source/audio/modules/RandomModuleProcessor.h
    Source/audio/modules/RandomModuleProcessor.cpp
    Source/audio/modules/RateModuleProcessor.h
    Source/audio/modules/RateModuleProcessor.cpp
    Source/audio/modules/QuantizerModuleProcessor.h
    Source/audio/modules/QuantizerModuleProcessor.cpp
    Source/audio/modules/SequentialSwitchModuleProcessor.h
    Source/audio/modules/SequentialSwitchModuleProcessor.cpp
    Source/audio/modules/LogicModuleProcessor.h
    Source/audio/modules/LogicModuleProcessor.cpp
    Source/audio/modules/ClockDividerModuleProcessor.h
    Source/audio/modules/ClockDividerModuleProcessor.cpp
    Source/audio/modules/WaveshaperModuleProcessor.h
    Source/audio/modules/WaveshaperModuleProcessor.cpp
    Source/audio/modules/MultiBandShaperModuleProcessor.h
    Source/audio/modules/MultiBandShaperModuleProcessor.cpp
    Source/audio/modules/GranulatorModuleProcessor.h
    Source/audio/modules/GranulatorModuleProcessor.cpp
    Source/audio/modules/HarmonicShaperModuleProcessor.h
    Source/audio/modules/HarmonicShaperModuleProcessor.cpp
    Source/audio/modules/ValueModuleProcessor.h
    Source/audio/modules/ValueModuleProcessor.cpp
        Source/audio/modules/DebugModuleProcessor.h
        Source/audio/modules/DebugModuleProcessor.cpp
        Source/audio/modules/CommentModuleProcessor.h
        Source/audio/modules/CommentModuleProcessor.cpp
        Source/audio/modules/InputDebugModuleProcessor.h
        Source/audio/modules/InputDebugModuleProcessor.cpp
    Source/audio/modules/TimePitchModuleProcessor.h
    Source/audio/modules/TimePitchModuleProcessor.cpp
    Source/audio/modules/MIDIPlayerModuleProcessor.h
    Source/audio/modules/MIDIPlayerModuleProcessor.cpp
        Source/audio/modules/TrackMixerModuleProcessor.h
        Source/audio/modules/TrackMixerModuleProcessor.cpp
    Source/audio/modules/PolyVCOModuleProcessor.h
    Source/audio/modules/PolyVCOModuleProcessor.cpp
    
    Source/audio/modules/TTSPerformerModuleProcessor.h
    Source/audio/modules/TTSPerformerModuleProcessor.cpp
    Source/audio/modules/TimingData.h
    Source/audio/modules/SampleLoaderModuleProcessor.h
    Source/audio/modules/SampleLoaderModuleProcessor.cpp
    Source/audio/modules/FunctionGeneratorModuleProcessor.h
    Source/audio/modules/FunctionGeneratorModuleProcessor.cpp
    Source/audio/modules/BestPracticeNodeProcessor.h
    Source/audio/modules/BestPracticeNodeProcessor.cpp
    Source/audio/modules/ShapingOscillatorModuleProcessor.h
    Source/audio/modules/ShapingOscillatorModuleProcessor.cpp
    Source/audio/voices/SampleVoiceProcessor.h
    Source/audio/voices/SampleVoiceProcessor.cpp
    Source/audio/graph/VoiceProcessor.h
    Source/audio/graph/VoiceProcessor.cpp
    Source/audio/assets/SampleBank.h
    Source/audio/assets/SampleBank.cpp
    Source/utils/RtLogger.h
    Source/utils/RtLogger.cpp
    Source/audio/modules/VocalTractFilterModuleProcessor.h
    Source/audio/modules/VocalTractFilterModuleProcessor.cpp
    Source/audio/modules/VstHostModuleProcessor.h
    Source/audio/modules/VstHostModuleProcessor.cpp
    Source/audio/modules/MultiSequencerModuleProcessor.h
    Source/audio/modules/MultiSequencerModuleProcessor.cpp
    Source/audio/modules/LagProcessorModuleProcessor.h
    Source/audio/modules/LagProcessorModuleProcessor.cpp
    Source/audio/modules/DeCrackleModuleProcessor.h
    Source/audio/modules/DeCrackleModuleProcessor.cpp
    Source/audio/modules/GraphicEQModuleProcessor.h
    Source/audio/modules/GraphicEQModuleProcessor.cpp
    Source/audio/modules/FrequencyGraphModuleProcessor.h
    Source/audio/modules/FrequencyGraphModuleProcessor.cpp
    Source/audio/modules/ChorusModuleProcessor.h
    Source/audio/modules/ChorusModuleProcessor.cpp
    Source/audio/modules/PhaserModuleProcessor.h
    Source/audio/modules/PhaserModuleProcessor.cpp
    Source/audio/modules/CompressorModuleProcessor.h
    Source/audio/modules/CompressorModuleProcessor.cpp
    Source/audio/modules/RecordModuleProcessor.h
    Source/audio/modules/RecordModuleProcessor.cpp
    Source/audio/modules/CommentModuleProcessor.h
    Source/audio/modules/CommentModuleProcessor.cpp
    Source/audio/modules/LimiterModuleProcessor.h
    Source/audio/modules/LimiterModuleProcessor.cpp
    Source/audio/modules/GateModuleProcessor.h
    Source/audio/modules/GateModuleProcessor.cpp
    Source/audio/modules/DriveModuleProcessor.h
    Source/audio/modules/DriveModuleProcessor.cpp
    Source/audio/modules/InletModuleProcessor.h
    Source/audio/modules/InletModuleProcessor.cpp
    Source/audio/modules/OutletModuleProcessor.h
    Source/audio/modules/OutletModuleProcessor.cpp
    Source/audio/modules/MetaModuleProcessor.h
    Source/audio/modules/MetaModuleProcessor.cpp
    Source/audio/modules/SnapshotSequencerModuleProcessor.h
    Source/audio/modules/SnapshotSequencerModuleProcessor.cpp
    Source/audio/modules/MIDICVModuleProcessor.h
    Source/audio/modules/MIDICVModuleProcessor.cpp
    Source/audio/modules/MIDIFadersModuleProcessor.h
    Source/audio/modules/MIDIFadersModuleProcessor.cpp
    Source/audio/modules/MIDIKnobsModuleProcessor.h
    Source/audio/modules/MIDIKnobsModuleProcessor.cpp
    Source/audio/modules/MIDIButtonsModuleProcessor.h
    Source/audio/modules/MIDIButtonsModuleProcessor.cpp
    Source/audio/modules/MIDIJogWheelModuleProcessor.h
    Source/audio/modules/MIDIJogWheelModuleProcessor.cpp
    Source/audio/modules/MIDIPadModuleProcessor.h
    Source/audio/modules/MIDIPadModuleProcessor.cpp
    Source/audio/modules/MidiLoggerModuleProcessor.h
    Source/audio/modules/MidiLoggerModuleProcessor.cpp
    Source/audio/modules/TempoClockModuleProcessor.h
    Source/audio/modules/TempoClockModuleProcessor.cpp
    Source/audio/modules/PhysicsModuleProcessor.h
    Source/audio/modules/PhysicsModuleProcessor.cpp
    Source/audio/modules/StrokeSequencerModuleProcessor.h
    Source/audio/modules/StrokeSequencerModuleProcessor.cpp
    Source/audio/modules/TapTempo.h
    Source/audio/modules/TapTempo.cpp
    Source/audio/modules/BPMMonitorModuleProcessor.h
    Source/audio/modules/BPMMonitorModuleProcessor.cpp
    Source/audio/modules/AnimationModuleProcessor.h
    Source/audio/modules/AnimationModuleProcessor.cpp
    Source/video/VideoFrameManager.h
    Source/audio/modules/WebcamLoaderModule.h
    Source/audio/modules/WebcamLoaderModule.cpp
    Source/audio/modules/VideoFileLoaderModule.h
    Source/audio/modules/VideoFileLoaderModule.cpp
    Source/audio/modules/MovementDetectorModule.h
    Source/audio/modules/MovementDetectorModule.cpp
    Source/audio/modules/HumanDetectorModule.h
    Source/audio/modules/HumanDetectorModule.cpp
    Source/audio/modules/PoseEstimatorModule.h
    Source/audio/modules/PoseEstimatorModule.cpp
    Source/audio/modules/HandTrackerModule.h
    Source/audio/modules/HandTrackerModule.cpp
    Source/audio/modules/FaceTrackerModule.h
    Source/audio/modules/FaceTrackerModule.cpp
    Source/audio/modules/ObjectDetectorModule.h
    Source/audio/modules/ObjectDetectorModule.cpp
    Source/audio/modules/ColorTrackerModule.h
    Source/audio/modules/ColorTrackerModule.cpp
    Source/audio/modules/ContourDetectorModule.h
    Source/audio/modules/ContourDetectorModule.cpp
    Source/audio/modules/SemanticSegmentationModule.h
    Source/audio/modules/SemanticSegmentationModule.cpp
    Source/animation/AnimationData.h
    Source/animation/RawAnimationData.h
    Source/animation/RawAnimationData.cpp
    Source/animation/AnimationBinder.h
    Source/animation/AnimationBinder.cpp
    Source/animation/Animator.h
    Source/animation/Animator.cpp
    Source/animation/AnimationFileLoader.h
    Source/animation/AnimationFileLoader.cpp
    Source/animation/GltfLoader.h
    Source/animation/GltfLoader.cpp
    Source/animation/FbxLoader.h
    Source/animation/FbxLoader.cpp
    Source/animation/AnimationRenderer.h
    Source/animation/AnimationRenderer.cpp
)

# This target now needs to know where to find all the headers
target_include_directories(PresetCreatorApp PRIVATE
    ${imgui_fc_SOURCE_DIR}
    ${imgui_fc_SOURCE_DIR}/backends
    ${imnodes_fc_SOURCE_DIR}
    ${imgui_juce_fc_SOURCE_DIR}
    ${PIPER_DIR}
    ${ONNXRUNTIME_DIR}/include
    ${CMAKE_SOURCE_DIR}/../vendor/openvino_toolkit_windows_2025.3.0.19807.44526285f24_x86_64/samples/cpp/thirdparty/nlohmann_json/single_include
    ${CMAKE_SOURCE_DIR}/../soundtouch/include
    ${CMAKE_SOURCE_DIR}/../soundtouch/source/SoundTouch
    ${ufbx_SOURCE_DIR}
    # OpenCV include directories - source and generated headers
    ${opencv_SOURCE_DIR}/include
    ${opencv_SOURCE_DIR}/modules/core/include
    ${opencv_SOURCE_DIR}/modules/imgproc/include
    ${opencv_SOURCE_DIR}/modules/imgcodecs/include
    ${opencv_SOURCE_DIR}/modules/videoio/include
    ${opencv_SOURCE_DIR}/modules/highgui/include
    ${opencv_SOURCE_DIR}/modules/video/include
    ${opencv_SOURCE_DIR}/modules/objdetect/include
    ${opencv_SOURCE_DIR}/modules/features2d/include
    ${opencv_SOURCE_DIR}/modules/calib3d/include
    ${opencv_SOURCE_DIR}/modules/dnn/include              # For DNN headers (dnn.hpp)
    ${OPENCV_BUILD_DIR}
    ${OPENCV_BUILD_DIR}/modules/world
    $<$<BOOL:${USE_RUBBERBAND}>:${RUBBERBAND_INCLUDE_DIR}>
)

# This target also needs the compile definitions
target_compile_definitions(PresetCreatorApp PRIVATE
    JUCE_APPLICATION_NAME_STRING="$<TARGET_PROPERTY:PresetCreatorApp,PRODUCT_NAME>"
    JUCE_APPLICATION_VERSION_STRING="$<TARGET_PROPERTY:PresetCreatorApp,VERSION>"
    JUCE_WEB_BROWSER=0 JUCE_USE_CURL=0
    JUCE_PLUGINHOST_VST3=1
    IMGUI_IMPL_JUCE_BEZEL=0
    IMGUI_DEFINE_MATH_OPERATORS
    IMNODES_NAMESPACE=ImNodes
    IMNODES_STATIC_DEFINE
    PRESET_CREATOR_UI=1
    $<$<BOOL:${USE_RUBBERBAND}>:USE_RUBBERBAND=1>
    $<$<NOT:$<BOOL:${USE_RUBBERBAND}>>:USE_RUBBERBAND=0>
)

target_link_libraries(PresetCreatorApp PRIVATE
    juce::juce_gui_extra
    juce::juce_opengl
    juce::juce_audio_devices
    juce::juce_audio_processors
    juce::juce_audio_utils
    juce::juce_audio_formats
    juce::juce_dsp
    imgui_impl_juce
    soundtouch
    box2d
    glm::glm
    tinygltf
    ufbx_static
    opencv_world
    $<$<BOOL:${USE_RUBBERBAND}>:${RUBBERBAND_TARGET}>
    # Piper TTS libraries (pre-built)
    ${ONNXRUNTIME_DIR}/lib/onnxruntime.lib
)

if(WIN32)
    # Copy Piper executable and DLLs to output directories
    add_custom_command(
        TARGET ColliderApp POST_BUILD
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${PIPER_DIR}/piper.exe"
                "$<TARGET_FILE_DIR:ColliderApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${PIPER_DIR}/piper_phonemize.dll"
                "$<TARGET_FILE_DIR:ColliderApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${PIPER_DIR}/espeak-ng.dll"
                "$<TARGET_FILE_DIR:ColliderApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${ONNXRUNTIME_DIR}/lib/onnxruntime.dll"
                "$<TARGET_FILE_DIR:ColliderApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${ONNXRUNTIME_DIR}/lib/onnxruntime_providers_shared.dll"
                "$<TARGET_FILE_DIR:ColliderApp>"
        # Copy OpenCV FFmpeg video backend DLL (relative to build tree)
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${CMAKE_BINARY_DIR}/bin/$<CONFIG>/opencv_videoio_ffmpeg490_64.dll"
                "$<TARGET_FILE_DIR:ColliderApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_directory
                "${PIPER_DIR}/espeak-ng-data"
                "$<TARGET_FILE_DIR:ColliderApp>/espeak-ng-data"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${opencv_SOURCE_DIR}/data/haarcascades/haarcascade_frontalface_default.xml"
                "$<TARGET_FILE_DIR:ColliderApp>"
        COMMENT "Copying Piper TTS and OpenCV data files to ColliderApp output directory"
    )
    add_custom_command(
        TARGET PresetCreatorApp POST_BUILD
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${PIPER_DIR}/piper.exe"
                "$<TARGET_FILE_DIR:PresetCreatorApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${PIPER_DIR}/piper_phonemize.dll"
                "$<TARGET_FILE_DIR:PresetCreatorApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${PIPER_DIR}/espeak-ng.dll"
                "$<TARGET_FILE_DIR:PresetCreatorApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${ONNXRUNTIME_DIR}/lib/onnxruntime.dll"
                "$<TARGET_FILE_DIR:PresetCreatorApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${ONNXRUNTIME_DIR}/lib/onnxruntime_providers_shared.dll"
                "$<TARGET_FILE_DIR:PresetCreatorApp>"
        # Copy OpenCV FFmpeg video backend DLL (relative to build tree)
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${CMAKE_BINARY_DIR}/bin/$<CONFIG>/opencv_videoio_ffmpeg490_64.dll"
                "$<TARGET_FILE_DIR:PresetCreatorApp>"
        COMMAND ${CMAKE_COMMAND} -E copy_directory
                "${PIPER_DIR}/espeak-ng-data"
                "$<TARGET_FILE_DIR:PresetCreatorApp>/espeak-ng-data"
        # NEW (Corrected): Copy the entire assets folder
        COMMAND ${CMAKE_COMMAND} -E copy_directory
                "${CMAKE_SOURCE_DIR}/assets"
                "$<TARGET_FILE_DIR:PresetCreatorApp>/assets"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
                "${opencv_SOURCE_DIR}/data/haarcascades/haarcascade_frontalface_default.xml"
                "$<TARGET_FILE_DIR:PresetCreatorApp>"
        COMMENT "Copying Piper TTS, OpenPose, and other runtime assets to PresetCreatorApp output directory"
    )
endif()

